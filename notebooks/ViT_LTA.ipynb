{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59966,"status":"ok","timestamp":1700019226730,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"5L2E08WC64nn","outputId":"ebb06723-67eb-429a-83d7-8c53ee93e0c4"},"outputs":[],"source":["%pip install -U lightning\n","%pip install -U wandb\n","%pip install -U transformers"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1700021083588,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"58CGWGCwYAdC","outputId":"bf87d8f4-7565-46ae-f085-26cfc2af5dff"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manhlt250102\u001b[0m (\u001b[33mmy_computer_vision_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1700021083588,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"pOZvJlf4NAbQ"},"outputs":[],"source":["from typing import Any\n","from lightning import LightningDataModule, LightningModule, Trainer\n","from torch.utils.data import DataLoader, random_split, Dataset\n","from sklearn.model_selection import train_test_split\n","from lightning.pytorch.callbacks import ModelSummary, EarlyStopping\n","from lightning.pytorch.loggers import WandbLogger\n","from torchvision import transforms\n","from transformers import ViTForImageClassification, BitForImageClassification, ViTHybridForImageClassification\n","from torchvision.datasets import MNIST, ImageNet, CIFAR100\n","from torchvision.models import vit_b_16, vit_b_32, vit_l_16, vit_l_32, vit_h_14\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","\n","def patchify(batch: torch.Tensor, patch_size: tuple = (16, 16)):\n","    \"\"\"\n","    Patchify the batch of images\n","\n","    Shape:\n","        batch: (b, h, w, c)\n","        output: (b, nh, nw, ph, pw, c)\n","    \"\"\"\n","    b, h, w, c = batch.shape # (n, 224, 224, 3)\n","    ph, pw = patch_size # (16, 16)\n","    nh, nw = h // ph, w // pw # (14, 14)\n","\n","    patches = torch.zeros(b, nh*nw, ph*pw*c).to(batch.device) # (n, nh*nw, ph*pw*c) = (n, 196, 768)\n","\n","    for idx, image in enumerate(batch):\n","        for i in range(nh):\n","            for j in range(nw):\n","                patch = image[i*ph: (i+1)*ph, j*pw: (j+1)*pw, :]\n","                patches[idx, i*nh + j] = patch.flatten()\n","    return patches # (n, nh*nw, ph*pw*c) = (n, 196, 768)\n","\n","def get_mlp(in_features, hidden_units, out_features):\n","    \"\"\"\n","    Returns a MLP head\n","    \"\"\"\n","    dims = [in_features] + hidden_units + [out_features]\n","    layers = []\n","    for dim1, dim2 in zip(dims[:-2], dims[1:-1]):\n","        layers.append(nn.Linear(dim1, dim2))\n","        layers.append(nn.ReLU())\n","    layers.append(nn.Linear(dims[-2], dims[-1]))\n","    return nn.Sequential(*layers)\n","\n","def get_positional_embeddings(sequence_length, d):\n","    result = torch.ones(sequence_length, d)\n","    for i in range(sequence_length):\n","        for j in range(d):\n","            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n","    return result # (s, d)\n","\n","class ImgDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        label = self.labels[idx]\n","\n","        if image.shape[0] == 1 or len(image.shape) == 2:\n","            image = image.repeat(3, 1, 1)\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","class MyDataModule(LightningDataModule):\n","    def __init__(self, dataset_to_down, img_size: tuple, data_dir: str = './data', batch_size: int = 64):\n","        super().__init__()\n","        self.dataset_to_down = dataset_to_down\n","        self.data_dir = data_dir\n","        self.batch_size = batch_size\n","        self.transform = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.Resize(img_size),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.255]),\n","        ])\n","\n","    def prepare_data(self):\n","        print(\"Downloading dataset...\")\n","        self.train_dataset = self.dataset_to_down(root=\"data/\", train=True, transform=None, download=True)\n","        self.test_dataset = self.dataset_to_down(root=\"data/\", train=False, transform=None, download=True)\n","\n","    def n_classes(self):\n","        return np.unique(self.train_dataset.targets).reshape(-1).shape[0]\n","\n","    def setup(self, stage=None):\n","        train_images, val_images, train_labels, val_labels = train_test_split(self.train_dataset.data, self.train_dataset.targets, test_size=0.2, random_state=42)\n","        test_images, test_labels = self.test_dataset.data, self.test_dataset.targets\n","        if stage == 'fit' or stage is None:\n","            self.train_ds = ImgDataset(train_images, train_labels, transform=self.transform)\n","            self.val_ds = ImgDataset(val_images, val_labels, transform=self.transform)\n","        if stage == 'test' or stage is None:\n","            self.test_ds = ImgDataset(test_images, test_labels, transform=self.transform)\n","\n","    def train_dataloader(self):\n","        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=0)\n","\n","    def val_dataloader(self):\n","        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False, num_workers=0)\n","\n","    def test_dataloader(self):\n","        return DataLoader(self.test_ds, batch_size=self.batch_size, shuffle=False, num_workers=0)\n","\n","class ViT(nn.Module):\n","    def __init__(\n","        self,\n","        nhead: int = 4,\n","        dim_feedforward: int = 1024,\n","        blocks: int = 4,\n","        mlp_head_units: list = [1024, 512],\n","        n_classes: int = 1,\n","        img_size: tuple = (224, 224),\n","        patch_size: tuple = (16, 16),\n","        n_channels: int = 3,\n","        d_model: int = 512,\n","    ):\n","        super().__init__()\n","        \"\"\"\n","        Args:\n","            img_size: Size of the image\n","            patch_size: Size of the patch\n","            n_channels: Number of image channels\n","            d_model: The number of features in the transformer encoder\n","            nhead: The number of heads in the multiheadattention models\n","            dim_feedforward: The dimension of the feedforward network model in the encoder\n","            blocks: The number of sub-encoder-layers in the encoder\n","            mlp_head_units: The hidden units of mlp_head\n","            n_classes: The number of output classes\n","        \"\"\"\n","        # self.img2seq = Img2Seq(img_size, patch_size, n_channels, d_model)\n","        # self.patch_size = patch_size # (16, 16)\n","        # nh, nw = img_size[0] // patch_size[0], img_size[1] // patch_size[1] # (14, 14)\n","        # n_tokens = nh * nw # 196\n","        # token_dim = patch_size[0] * patch_size[1] * n_channels # 768\n","        # self.first_linear = nn.Linear(token_dim, d_model) # (768, 512)\n","        # self.cls_token = nn.Parameter(torch.randn(1, d_model)) # (1, 512)\n","        # self.pos_emb = nn.Parameter(get_positional_embeddings(n_tokens, d_model)) # (196, 512)\n","\n","        self.patch_emb = nn.Conv2d(n_channels, d_model, kernel_size=patch_size, stride=patch_size) # (3, 512, (16, 16), (16, 16))\n","\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model, nhead, dim_feedforward, activation=\"gelu\", batch_first=True\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer, blocks\n","        )\n","        self.mlp = get_mlp(d_model, mlp_head_units, n_classes) # (512, [1024, 512], n_classes)\n","\n","        # self.classifer = nn.Sigmoid() if n_classes == 1 else nn.Softmax()\n","\n","    def forward(self, batch):\n","        \"\"\"\n","        Shape:\n","            input: (b, c, h, w)\n","            output: (b, n_classes)\n","        \"\"\"\n","        # batch = torch.permute(batch, (0, 2, 3, 1)) # (b, h, w, c) = (b, 224, 224, 3)\n","        # batch = patchify(batch, self.patch_size) # (b, nh*nw, ph*pw*c) = (b, 196, 768)\n","        # b = batch.shape[0]\n","        # batch = self.first_linear(batch) # (b, nh*nw, d_model) = (b, 196, 512)\n","        # cls = self.cls_token.expand([b, -1, -1]) # (b, 1, d_model) = (b, 1, 512)\n","        # emb = batch + self.pos_emb # (b, nh*nw, d_model) = (b, 196, 512)\n","        # batch = torch.cat([cls, emb], axis=1) # (b, nh*nw+1, d_model) = (b, 197, 512)\n","\n","        batch = self.patch_emb(batch) # (b, d_model, nh, nw) = (b, 512, 14, 14)\n","        batch = batch.flatten(2).transpose(1, 2) # (b, nh*nw, d_model) = (b, 196, 512)\n","\n","        batch = self.transformer_encoder(batch) # (b, s, d)\n","        batch = batch[:, 0, :] # (b, d)\n","        output = self.mlp(batch) # (b, n_classes)\n","        # output = self.classifer(batch) # (b, n_classes)\n","        return output\n","\n","class ViTModule(LightningModule):\n","    def __init__(self, learning_rate: float = 1e-4,\n","                 nhead: int = 4,\n","                 dim_feedforward: int = 1024,\n","                 blocks: int = 4,\n","                 mlp_head_units: list = [1024, 512],\n","                 n_classes: int = 1,\n","                 img_size: tuple = (224, 224),\n","                 patch_size: tuple = (16, 16),\n","                 n_channels: int = 3,\n","                 d_model: int = 512) -> None:\n","        '''\n","        Args:\n","            img_size: Size of the image\n","            patch_size: Size of the patch\n","            n_channels: Number of image channels\n","            d_model: The number of features in the transformer encoder\n","            nhead: The number of heads in the multiheadattention models\n","            dim_feedforward: The dimension of the feedforward network model in the encoder\n","            blocks: The number of sub-encoder-layers in the encoder\n","            mlp_head_units: The hidden units of mlp_head\n","            n_classes: The number of output classes\n","\n","        Shape:\n","            input: (b, c, h, w)\n","            output: (b, n_classes)\n","        '''\n","        super().__init__()\n","        self.learing_rate = learning_rate\n","        self.patch_size = patch_size # (16, 16)\n","        nh, nw = img_size[0] // patch_size[0], img_size[1] // patch_size[1] # (14, 14)\n","        n_tokens = nh * nw # 196\n","        token_dim = patch_size[0] * patch_size[1] * n_channels # 768\n","        self.first_linear = nn.Linear(token_dim, d_model) # (768, 512)\n","        self.cls_token = nn.Parameter(torch.randn(1, d_model)) # (1, 512)\n","        self.pos_emb = nn.Parameter(get_positional_embeddings(n_tokens, d_model)) # (196, 512)\n","\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model, nhead, dim_feedforward, activation=\"gelu\", batch_first=True\n","        )\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer, blocks\n","        )\n","        self.mlp = get_mlp(d_model, mlp_head_units, n_classes) # (512, [1024, 512], n_classes)\n","\n","        self.classifer = nn.Sigmoid() if n_classes == 1 else nn.Softmax()\n","        # self.criteria = nn.CrossEntropyLoss()\n","\n","        self.train_accuracy = []\n","        self.val_accuracy = []\n","        self.test_accuracy = []\n","        self.train_loss = []\n","        self.val_loss = []\n","        self.test_loss = []\n","\n","    def forward(self, batch: torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Shape:\n","            input: (b, c, h, w)\n","            output: (b, n_classes)\n","        \"\"\"\n","        # batch = self.img2seq(batch) # (b, s, d)\n","        batch = torch.permute(batch, (0, 2, 3, 1)) # (b, h, w, c) = (b, 224, 224, 3)\n","        batch = patchify(batch, self.patch_size) # (b, nh*nw, ph*pw*c) = (b, 196, 768)\n","        b = batch.shape[0]\n","        batch = self.first_linear(batch) # (b, nh*nw, d_model) = (b, 196, 512)\n","        cls = self.cls_token.expand([b, -1, -1]) # (b, 1, d_model) = (b, 1, 512)\n","        emb = batch + self.pos_emb # (b, nh*nw, d_model) = (b, 196, 512)\n","        batch = torch.cat([cls, emb], axis=1) # (b, nh*nw+1, d_model) = (b, 197, 512)\n","\n","        batch = self.transformer_encoder(batch) # (b, s, d)\n","        batch = batch[:, 0, :] # (b, d)\n","        batch = self.mlp(batch) # (b, n_classes)\n","        output = self.classifer(batch) # (b, n_classes)\n","        return output\n","\n","    def training_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = nn.functional.cross_entropy(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('train_accuracy', accuracy, prog_bar=True)\n","        self.log('train_loss', loss, prog_bar=True)\n","        self.train_accuracy.append(accuracy)\n","        self.train_loss.append(loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = nn.functional.cross_entropy(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('val_accuracy', accuracy, prog_bar=True)\n","        self.log('val_loss', loss, prog_bar=True)\n","        self.val_accuracy.append(accuracy)\n","        self.val_loss.append(loss)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = nn.functional.cross_entropy(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('test_accuracy', accuracy, prog_bar=True)\n","        self.log('test_loss', loss, prog_bar=True)\n","        self.test_accuracy.append(accuracy)\n","        self.test_loss.append(loss)\n","        return loss\n","\n","    def on_train_epoch_end(self) -> None:\n","        self.log('train_accuracy_epoch', torch.stack(self.train_accuracy).mean())\n","        self.log('train_loss_epoch', torch.stack(self.train_loss).mean())\n","        self.train_accuracy = []\n","        self.train_loss = []\n","\n","    def on_validation_epoch_end(self) -> None:\n","        self.log('val_accuracy_epoch', torch.stack(self.val_accuracy).mean())\n","        self.log('val_loss_epoch', torch.stack(self.val_loss).mean())\n","        self.val_accuracy = []\n","        self.val_loss = []\n","\n","    def on_test_epoch_end(self) -> None:\n","        self.log('test_accuracy_epoch', torch.stack(self.test_accuracy).mean())\n","        self.log('test_loss_epoch', torch.stack(self.test_loss).mean())\n","        self.test_accuracy = []\n","        self.test_loss = []\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=self.learing_rate)\n","\n","class ViTPretrainedModule(LightningModule):\n","    def __init__(self, model, learning_rate: float, source: str = 'pytorch', n_classes: int = None, *args: Any, **kwargs: Any) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.source = source\n","        self.learing_rate = learning_rate\n","        self.model = model\n","        if n_classes is not None and source == 'pytorch':\n","            self.model.heads = nn.Linear(self.model.heads.head.in_features, n_classes)\n","        self.criteria = nn.CrossEntropyLoss()\n","\n","        self.train_accuracy = []\n","        self.val_accuracy = []\n","        self.test_accuracy = []\n","        self.train_loss = []\n","        self.val_loss = []\n","        self.test_loss = []\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.model(x).logits if self.source == 'huggingface' else self.model(x)\n","\n","    def training_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = self.criteria(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('train_accuracy', accuracy, prog_bar=True)\n","        self.log('train_loss', loss, prog_bar=True)\n","        self.train_accuracy.append(accuracy)\n","        self.train_loss.append(loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = self.criteria(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('val_accuracy', accuracy, prog_bar=True)\n","        self.log('val_loss', loss, prog_bar=True)\n","        self.val_accuracy.append(accuracy)\n","        self.val_loss.append(loss)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = self.criteria(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('test_accuracy', accuracy, prog_bar=True)\n","        self.log('test_loss', loss, prog_bar=True)\n","        self.test_accuracy.append(accuracy)\n","        self.test_loss.append(loss)\n","        return loss\n","\n","    def on_train_epoch_end(self) -> None:\n","        self.log('train_accuracy_epoch', torch.stack(self.train_accuracy).mean())\n","        self.log('train_loss_epoch', torch.stack(self.train_loss).mean())\n","        self.train_accuracy = []\n","        self.train_loss = []\n","\n","    def on_validation_epoch_end(self) -> None:\n","        self.log('val_accuracy_epoch', torch.stack(self.val_accuracy).mean())\n","        self.log('val_loss_epoch', torch.stack(self.val_loss).mean())\n","        self.val_accuracy = []\n","        self.val_loss = []\n","\n","    def on_test_epoch_end(self) -> None:\n","        self.log('test_accuracy_epoch', torch.stack(self.test_accuracy).mean())\n","        self.log('test_loss_epoch', torch.stack(self.test_loss).mean())\n","        self.test_accuracy = []\n","        self.test_loss = []\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=self.learing_rate)\n","\n","class LinearModule(LightningModule):\n","    def __init__(self, img_size: tuple = (224, 224), n_channels: int = 3, n_classes: int = 10, learning_rate: float = 1e-4, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.learing_rate = learning_rate\n","        self.model = nn.Linear(img_size[0] * img_size[1] * n_channels, n_classes)\n","        self.criteria = nn.CrossEntropyLoss()\n","\n","        self.train_accuracy = []\n","        self.val_accuracy = []\n","        self.test_accuracy = []\n","        self.train_loss = []\n","        self.val_loss = []\n","        self.test_loss = []\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        '''\n","        Shape:\n","            input: (b, c, h, w)\n","            output: (b, n_classes) = (b, 10)\n","        '''\n","        x = x.view(x.size(0), -1) # (b, c*h*w)\n","        return self.model(x) # (b, 10)\n","\n","    def training_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = self.criteria(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('train_accuracy', accuracy, prog_bar=True)\n","        self.log('train_loss', loss, prog_bar=True)\n","        self.train_accuracy.append(accuracy)\n","        self.train_loss.append(loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = self.criteria(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('val_accuracy', accuracy, prog_bar=True)\n","        self.log('val_loss', loss, prog_bar=True)\n","        self.val_accuracy.append(accuracy)\n","        self.val_loss.append(loss)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx: int):\n","        x, y = batch\n","        logits = self.forward(x)\n","        loss = self.criteria(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        self.log('test_accuracy', accuracy, prog_bar=True)\n","        self.log('test_loss', loss, prog_bar=True)\n","        self.test_accuracy.append(accuracy)\n","        self.test_loss.append(loss)\n","        return loss\n","\n","    def on_train_epoch_end(self) -> None:\n","        self.log('train_accuracy_epoch', torch.stack(self.train_accuracy).mean())\n","        self.log('train_loss_epoch', torch.stack(self.train_loss).mean())\n","        self.train_accuracy = []\n","        self.train_loss = []\n","\n","    def on_validation_epoch_end(self) -> None:\n","        self.log('val_accuracy_epoch', torch.stack(self.val_accuracy).mean())\n","        self.log('val_loss_epoch', torch.stack(self.val_loss).mean())\n","        self.val_accuracy = []\n","        self.val_loss = []\n","\n","    def on_test_epoch_end(self) -> None:\n","        self.log('test_accuracy_epoch', torch.stack(self.test_accuracy).mean())\n","        self.log('test_loss_epoch', torch.stack(self.test_loss).mean())\n","        self.test_accuracy = []\n","        self.test_loss = []\n","\n","    def configure_optimizers(self):\n","        return torch.optim.Adam(self.parameters(), lr=self.learing_rate)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["ViTForImageClassification(\n","  (vit): ViTModel(\n","    (embeddings): ViTEmbeddings(\n","      (patch_embeddings): ViTPatchEmbeddings(\n","        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","      )\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): ViTEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x ViTLayer(\n","          (attention): ViTAttention(\n","            (attention): ViTSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): ViTSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): ViTIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ViTOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=10)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1700023597670,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"QLl5EpnHNFeb","outputId":"60e826bf-8ddb-4a99-9d55-63c5050fc087"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["BATCH_SIZE = 64\n","EPOCHS = 10\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","LEARNING_RATE = 1e-4\n","IMG_SIZE = (28, 28)\n","PATCH_SIZE = (2, 2)\n","PROJ_NAME = 'ViT-2-2_test_mnist'\n","BLOCKS = 4\n","\n","def train(dataset, batch_size = BATCH_SIZE, epochs = EPOCHS, device = DEVICE, lr = LEARNING_RATE, img_size = IMG_SIZE, patch_size = PATCH_SIZE, proj_name = PROJ_NAME, blocks = BLOCKS):\n","    data_module = MyDataModule(dataset, img_size, batch_size=batch_size)\n","    data_module.prepare_data()\n","\n","    model = ViTModule(\n","        img_size=img_size,\n","        patch_size=patch_size,\n","        n_channels=3,\n","        d_model=8,\n","        nhead=4,\n","        dim_feedforward=32,\n","        blocks=blocks,\n","        mlp_head_units=[32, 16],\n","        n_classes=data_module.n_classes(),\n","        learning_rate=lr,\n","    )\n","\n","    logger = WandbLogger(project=proj_name,\n","                         config={'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'learning_rate': LEARNING_RATE, 'img_size': IMG_SIZE, 'patch_size': PATCH_SIZE})\n","    trainer = Trainer(\n","        default_root_dir='./models',\n","        accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n","        max_epochs=epochs,\n","        logger=logger,\n","        callbacks=[EarlyStopping(monitor='val_loss_epoch', patience=2)],\n","    )\n","    trainer.fit(model, data_module)\n","    trainer.test(model, data_module)\n","\n","print(\"Using device:\", DEVICE)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loss: 2.323056221008301 Accuracy: 0.109375\n","Loss: 2.314821720123291 Accuracy: 0.15625\n","Loss: 2.31184720993042 Accuracy: 0.15625\n","Loss: 2.298128128051758 Accuracy: 0.15625\n","Loss: 2.3069207668304443 Accuracy: 0.140625\n","Loss: 2.314337968826294 Accuracy: 0.046875\n","Loss: 2.3000080585479736 Accuracy: 0.078125\n","Loss: 2.304555892944336 Accuracy: 0.125\n","Loss: 2.3200442790985107 Accuracy: 0.125\n","Loss: 2.319098472595215 Accuracy: 0.078125\n","Loss: 2.317134141921997 Accuracy: 0.109375\n","Loss: 2.295874834060669 Accuracy: 0.171875\n","Loss: 2.333125591278076 Accuracy: 0.09375\n","Loss: 2.3168447017669678 Accuracy: 0.09375\n","Loss: 2.309624195098877 Accuracy: 0.125\n","Loss: 2.317972421646118 Accuracy: 0.078125\n","Loss: 2.302276611328125 Accuracy: 0.15625\n","Loss: 2.3002095222473145 Accuracy: 0.09375\n","Loss: 2.303027629852295 Accuracy: 0.140625\n","Loss: 2.3104758262634277 Accuracy: 0.078125\n","Loss: 2.298619270324707 Accuracy: 0.046875\n","Loss: 2.3090264797210693 Accuracy: 0.078125\n","Loss: 2.3115570545196533 Accuracy: 0.09375\n","Loss: 2.2872774600982666 Accuracy: 0.109375\n","Loss: 2.3035552501678467 Accuracy: 0.125\n","Loss: 2.314073085784912 Accuracy: 0.109375\n","Loss: 2.315594434738159 Accuracy: 0.078125\n","Loss: 2.310253143310547 Accuracy: 0.109375\n","Loss: 2.308291435241699 Accuracy: 0.140625\n","Loss: 2.3061087131500244 Accuracy: 0.15625\n","Loss: 2.2924365997314453 Accuracy: 0.078125\n","Loss: 2.306750535964966 Accuracy: 0.09375\n","Loss: 2.3174402713775635 Accuracy: 0.03125\n","Loss: 2.309152364730835 Accuracy: 0.203125\n","Loss: 2.2960286140441895 Accuracy: 0.140625\n","Loss: 2.284649610519409 Accuracy: 0.03125\n","Loss: 2.322364330291748 Accuracy: 0.109375\n","Loss: 2.32338809967041 Accuracy: 0.078125\n","Loss: 2.3062210083007812 Accuracy: 0.125\n","Loss: 2.2921135425567627 Accuracy: 0.1875\n","Loss: 2.324368953704834 Accuracy: 0.0625\n","Loss: 2.3042776584625244 Accuracy: 0.140625\n","Loss: 2.318610906600952 Accuracy: 0.046875\n","Loss: 2.3074021339416504 Accuracy: 0.09375\n","Loss: 2.3048062324523926 Accuracy: 0.109375\n","Loss: 2.3095004558563232 Accuracy: 0.125\n","Loss: 2.2893965244293213 Accuracy: 0.15625\n","Loss: 2.3299691677093506 Accuracy: 0.078125\n","Loss: 2.312483072280884 Accuracy: 0.109375\n","Loss: 2.2937517166137695 Accuracy: 0.078125\n","Loss: 2.309662103652954 Accuracy: 0.078125\n","Loss: 2.306874990463257 Accuracy: 0.171875\n","Loss: 2.3312575817108154 Accuracy: 0.0625\n","Loss: 2.317826986312866 Accuracy: 0.078125\n","Loss: 2.3074264526367188 Accuracy: 0.046875\n","Loss: 2.326709508895874 Accuracy: 0.046875\n","Loss: 2.323225498199463 Accuracy: 0.0625\n","Loss: 2.3045787811279297 Accuracy: 0.0625\n","Loss: 2.3040637969970703 Accuracy: 0.0625\n","Loss: 2.3186118602752686 Accuracy: 0.09375\n","Loss: 2.312605142593384 Accuracy: 0.109375\n","Loss: 2.28930926322937 Accuracy: 0.140625\n","Loss: 2.3223047256469727 Accuracy: 0.046875\n","Loss: 2.303731918334961 Accuracy: 0.125\n","Loss: 2.317538261413574 Accuracy: 0.078125\n","Loss: 2.306511878967285 Accuracy: 0.078125\n","Loss: 2.300222635269165 Accuracy: 0.078125\n","Loss: 2.30637788772583 Accuracy: 0.09375\n","Loss: 2.301503896713257 Accuracy: 0.109375\n","Loss: 2.3000547885894775 Accuracy: 0.109375\n","Loss: 2.2984232902526855 Accuracy: 0.109375\n","Loss: 2.305138111114502 Accuracy: 0.125\n","Loss: 2.2800233364105225 Accuracy: 0.140625\n","Loss: 2.302760124206543 Accuracy: 0.078125\n","Loss: 2.314744472503662 Accuracy: 0.0625\n","Loss: 2.304337739944458 Accuracy: 0.109375\n","Loss: 2.289917469024658 Accuracy: 0.125\n","Loss: 2.3016517162323 Accuracy: 0.140625\n","Loss: 2.2941744327545166 Accuracy: 0.15625\n","Loss: 2.3008408546447754 Accuracy: 0.125\n","Loss: 2.3109469413757324 Accuracy: 0.09375\n","Loss: 2.2915139198303223 Accuracy: 0.15625\n","Loss: 2.3004865646362305 Accuracy: 0.0625\n","Loss: 2.3128044605255127 Accuracy: 0.0625\n","Loss: 2.3029675483703613 Accuracy: 0.125\n","Loss: 2.301670551300049 Accuracy: 0.109375\n","Loss: 2.3095357418060303 Accuracy: 0.109375\n","Loss: 2.3076319694519043 Accuracy: 0.125\n","Loss: 2.3008198738098145 Accuracy: 0.0625\n","Loss: 2.2924864292144775 Accuracy: 0.140625\n","Loss: 2.2953953742980957 Accuracy: 0.09375\n","Loss: 2.313998222351074 Accuracy: 0.09375\n","Loss: 2.2925572395324707 Accuracy: 0.15625\n","Loss: 2.305394172668457 Accuracy: 0.109375\n","Loss: 2.316152811050415 Accuracy: 0.09375\n","Loss: 2.2900285720825195 Accuracy: 0.109375\n","Loss: 2.307366132736206 Accuracy: 0.125\n","Loss: 2.293489456176758 Accuracy: 0.15625\n","Loss: 2.3209471702575684 Accuracy: 0.03125\n","Loss: 2.3053245544433594 Accuracy: 0.078125\n","Loss: 2.3085134029388428 Accuracy: 0.03125\n","Loss: 2.315704345703125 Accuracy: 0.078125\n","Loss: 2.3142919540405273 Accuracy: 0.0\n","Loss: 2.3132970333099365 Accuracy: 0.0625\n","Loss: 2.291123390197754 Accuracy: 0.125\n","Loss: 2.30411434173584 Accuracy: 0.140625\n","Loss: 2.3127105236053467 Accuracy: 0.078125\n","Loss: 2.285804033279419 Accuracy: 0.109375\n","Loss: 2.317877769470215 Accuracy: 0.046875\n","Loss: 2.3191211223602295 Accuracy: 0.078125\n","Loss: 2.300067186355591 Accuracy: 0.140625\n","Loss: 2.30674147605896 Accuracy: 0.078125\n","Loss: 2.300391674041748 Accuracy: 0.109375\n","Loss: 2.317941904067993 Accuracy: 0.09375\n","Loss: 2.313918113708496 Accuracy: 0.0625\n","Loss: 2.290823221206665 Accuracy: 0.140625\n","Loss: 2.289391279220581 Accuracy: 0.171875\n","Loss: 2.3055176734924316 Accuracy: 0.078125\n","Loss: 2.3118550777435303 Accuracy: 0.046875\n","Loss: 2.307631731033325 Accuracy: 0.078125\n","Loss: 2.2984015941619873 Accuracy: 0.109375\n","Loss: 2.3138325214385986 Accuracy: 0.046875\n","Loss: 2.309061288833618 Accuracy: 0.03125\n","Loss: 2.3083083629608154 Accuracy: 0.109375\n","Loss: 2.297764539718628 Accuracy: 0.125\n","Loss: 2.3074750900268555 Accuracy: 0.0625\n","Loss: 2.2940006256103516 Accuracy: 0.15625\n","Loss: 2.2877049446105957 Accuracy: 0.140625\n","Loss: 2.3155622482299805 Accuracy: 0.078125\n","Loss: 2.3186075687408447 Accuracy: 0.078125\n","Loss: 2.3097431659698486 Accuracy: 0.140625\n","Loss: 2.305217981338501 Accuracy: 0.03125\n","Loss: 2.3061397075653076 Accuracy: 0.0625\n","Loss: 2.312570095062256 Accuracy: 0.078125\n","Loss: 2.3046016693115234 Accuracy: 0.1875\n","Loss: 2.2737836837768555 Accuracy: 0.234375\n","Loss: 2.3232178688049316 Accuracy: 0.078125\n","Loss: 2.309297561645508 Accuracy: 0.0625\n","Loss: 2.3011820316314697 Accuracy: 0.0625\n","Loss: 2.315258026123047 Accuracy: 0.0625\n","Loss: 2.3127293586730957 Accuracy: 0.109375\n","Loss: 2.3121330738067627 Accuracy: 0.046875\n","Loss: 2.3051819801330566 Accuracy: 0.09375\n","Loss: 2.309457540512085 Accuracy: 0.046875\n","Loss: 2.3021373748779297 Accuracy: 0.125\n","Loss: 2.303783416748047 Accuracy: 0.0625\n","Loss: 2.292274236679077 Accuracy: 0.078125\n","Loss: 2.307199716567993 Accuracy: 0.078125\n","Loss: 2.3056511878967285 Accuracy: 0.046875\n","Loss: 2.294008255004883 Accuracy: 0.171875\n","Loss: 2.30769419670105 Accuracy: 0.046875\n","Loss: 2.3084158897399902 Accuracy: 0.046875\n","Loss: 2.3067893981933594 Accuracy: 0.140625\n","Loss: 2.292715072631836 Accuracy: 0.15625\n","Loss: 2.304004669189453 Accuracy: 0.046875\n","Loss: 2.2981960773468018 Accuracy: 0.09375\n","Loss: 2.326503276824951 Accuracy: 0.078125\n","Loss: 2.3091628551483154 Accuracy: 0.03125\n","Loss: 2.292344331741333 Accuracy: 0.171875\n","Loss: 2.3028626441955566 Accuracy: 0.09375\n","Loss: 2.303051233291626 Accuracy: 0.15625\n","Loss: 2.2981996536254883 Accuracy: 0.09375\n","Loss: 2.306691884994507 Accuracy: 0.0625\n","Loss: 2.3022210597991943 Accuracy: 0.125\n","Loss: 2.298476457595825 Accuracy: 0.125\n","Loss: 2.315924882888794 Accuracy: 0.09375\n","Loss: 2.3109242916107178 Accuracy: 0.125\n","Loss: 2.3173861503601074 Accuracy: 0.0625\n","Loss: 2.2959964275360107 Accuracy: 0.140625\n","Loss: 2.309037923812866 Accuracy: 0.109375\n","Loss: 2.295255661010742 Accuracy: 0.09375\n","Loss: 2.3025143146514893 Accuracy: 0.109375\n","Loss: 2.3018083572387695 Accuracy: 0.109375\n","Loss: 2.291236639022827 Accuracy: 0.15625\n","Loss: 2.2957985401153564 Accuracy: 0.078125\n","Loss: 2.2694575786590576 Accuracy: 0.234375\n","Loss: 2.308163642883301 Accuracy: 0.09375\n","Loss: 2.295163154602051 Accuracy: 0.140625\n","Loss: 2.2954888343811035 Accuracy: 0.09375\n","Loss: 2.3004868030548096 Accuracy: 0.09375\n","Loss: 2.308788776397705 Accuracy: 0.09375\n","Loss: 2.308002471923828 Accuracy: 0.15625\n","Loss: 2.286015748977661 Accuracy: 0.1875\n","Loss: 2.295234441757202 Accuracy: 0.125\n","Loss: 2.3105051517486572 Accuracy: 0.109375\n","Loss: 2.3098886013031006 Accuracy: 0.109375\n","Loss: 2.3144965171813965 Accuracy: 0.078125\n","Loss: 2.2922873497009277 Accuracy: 0.140625\n","Loss: 2.2952725887298584 Accuracy: 0.1875\n","Loss: 2.298896074295044 Accuracy: 0.171875\n","Loss: 2.2962682247161865 Accuracy: 0.1875\n","Loss: 2.317434310913086 Accuracy: 0.09375\n","Loss: 2.3054869174957275 Accuracy: 0.109375\n","Loss: 2.305347442626953 Accuracy: 0.09375\n","Loss: 2.280195713043213 Accuracy: 0.203125\n","Loss: 2.2970480918884277 Accuracy: 0.109375\n","Loss: 2.303309917449951 Accuracy: 0.1875\n","Loss: 2.313307285308838 Accuracy: 0.125\n","Loss: 2.306669235229492 Accuracy: 0.09375\n","Loss: 2.3080809116363525 Accuracy: 0.15625\n","Loss: 2.2952065467834473 Accuracy: 0.15625\n","Loss: 2.305704116821289 Accuracy: 0.140625\n","Loss: 2.297985553741455 Accuracy: 0.125\n","Loss: 2.2967162132263184 Accuracy: 0.140625\n","Loss: 2.3053014278411865 Accuracy: 0.15625\n","Loss: 2.2979767322540283 Accuracy: 0.203125\n","Loss: 2.2868399620056152 Accuracy: 0.203125\n","Loss: 2.289278507232666 Accuracy: 0.265625\n","Loss: 2.3102192878723145 Accuracy: 0.109375\n","Loss: 2.2937045097351074 Accuracy: 0.203125\n","Loss: 2.285804033279419 Accuracy: 0.1875\n","Loss: 2.303698778152466 Accuracy: 0.171875\n","Loss: 2.301579236984253 Accuracy: 0.140625\n","Loss: 2.2933499813079834 Accuracy: 0.1875\n","Loss: 2.290860414505005 Accuracy: 0.125\n","Loss: 2.3049731254577637 Accuracy: 0.203125\n","Loss: 2.3000309467315674 Accuracy: 0.1875\n","Loss: 2.2944412231445312 Accuracy: 0.1875\n","Loss: 2.305131196975708 Accuracy: 0.1875\n","Loss: 2.3083717823028564 Accuracy: 0.15625\n","Loss: 2.305513381958008 Accuracy: 0.109375\n","Loss: 2.304795742034912 Accuracy: 0.109375\n","Loss: 2.3127925395965576 Accuracy: 0.109375\n","Loss: 2.2826220989227295 Accuracy: 0.25\n","Loss: 2.300382375717163 Accuracy: 0.171875\n","Loss: 2.2950215339660645 Accuracy: 0.140625\n","Loss: 2.286836862564087 Accuracy: 0.09375\n","Loss: 2.303502082824707 Accuracy: 0.109375\n","Loss: 2.2823691368103027 Accuracy: 0.15625\n","Loss: 2.299086570739746 Accuracy: 0.125\n","Loss: 2.287173271179199 Accuracy: 0.234375\n","Loss: 2.2853612899780273 Accuracy: 0.28125\n","Loss: 2.294041156768799 Accuracy: 0.171875\n","Loss: 2.2934353351593018 Accuracy: 0.140625\n","Loss: 2.3124303817749023 Accuracy: 0.109375\n","Loss: 2.307002067565918 Accuracy: 0.140625\n","Loss: 2.3010263442993164 Accuracy: 0.15625\n","Loss: 2.303497552871704 Accuracy: 0.171875\n","Loss: 2.297466993331909 Accuracy: 0.171875\n","Loss: 2.307755708694458 Accuracy: 0.078125\n","Loss: 2.306806802749634 Accuracy: 0.09375\n","Loss: 2.299577474594116 Accuracy: 0.125\n","Loss: 2.28094744682312 Accuracy: 0.15625\n","Loss: 2.306864023208618 Accuracy: 0.15625\n","Loss: 2.3096272945404053 Accuracy: 0.125\n","Loss: 2.2958807945251465 Accuracy: 0.1875\n","Loss: 2.2947144508361816 Accuracy: 0.15625\n","Loss: 2.2932114601135254 Accuracy: 0.1875\n","Loss: 2.2981314659118652 Accuracy: 0.109375\n","Loss: 2.300724983215332 Accuracy: 0.140625\n","Loss: 2.293936252593994 Accuracy: 0.15625\n","Loss: 2.294128894805908 Accuracy: 0.171875\n","Loss: 2.306309223175049 Accuracy: 0.203125\n","Loss: 2.3033535480499268 Accuracy: 0.171875\n","Loss: 2.2745156288146973 Accuracy: 0.234375\n","Loss: 2.2971348762512207 Accuracy: 0.125\n","Loss: 2.294152021408081 Accuracy: 0.140625\n","Loss: 2.2896814346313477 Accuracy: 0.15625\n","Loss: 2.2971620559692383 Accuracy: 0.125\n","Loss: 2.3010997772216797 Accuracy: 0.15625\n","Loss: 2.294668197631836 Accuracy: 0.15625\n","Loss: 2.294321060180664 Accuracy: 0.21875\n","Loss: 2.294529438018799 Accuracy: 0.140625\n","Loss: 2.298710823059082 Accuracy: 0.1875\n","Loss: 2.2957217693328857 Accuracy: 0.15625\n","Loss: 2.306149482727051 Accuracy: 0.125\n","Loss: 2.3003382682800293 Accuracy: 0.15625\n","Loss: 2.2959144115448 Accuracy: 0.109375\n","Loss: 2.2953901290893555 Accuracy: 0.140625\n","Loss: 2.2904045581817627 Accuracy: 0.21875\n","Loss: 2.307360887527466 Accuracy: 0.078125\n","Loss: 2.2910866737365723 Accuracy: 0.171875\n","Loss: 2.307492256164551 Accuracy: 0.078125\n","Loss: 2.2914397716522217 Accuracy: 0.15625\n","Loss: 2.298635244369507 Accuracy: 0.140625\n","Loss: 2.296252489089966 Accuracy: 0.171875\n","Loss: 2.30668306350708 Accuracy: 0.171875\n","Loss: 2.2962002754211426 Accuracy: 0.15625\n","Loss: 2.296546220779419 Accuracy: 0.21875\n","Loss: 2.3054420948028564 Accuracy: 0.0625\n","Loss: 2.2997286319732666 Accuracy: 0.125\n","Loss: 2.2971062660217285 Accuracy: 0.203125\n","Loss: 2.3034186363220215 Accuracy: 0.203125\n","Loss: 2.286750316619873 Accuracy: 0.296875\n","Loss: 2.285374164581299 Accuracy: 0.234375\n","Loss: 2.285604953765869 Accuracy: 0.171875\n","Loss: 2.297053575515747 Accuracy: 0.140625\n","Loss: 2.286980152130127 Accuracy: 0.328125\n","Loss: 2.2954463958740234 Accuracy: 0.125\n","Loss: 2.31302547454834 Accuracy: 0.09375\n","Loss: 2.280179977416992 Accuracy: 0.234375\n","Loss: 2.3077266216278076 Accuracy: 0.15625\n","Loss: 2.273172616958618 Accuracy: 0.25\n","Loss: 2.2929816246032715 Accuracy: 0.15625\n","Loss: 2.297823905944824 Accuracy: 0.109375\n","Loss: 2.30676531791687 Accuracy: 0.15625\n","Loss: 2.3011491298675537 Accuracy: 0.109375\n","Loss: 2.292044162750244 Accuracy: 0.203125\n","Loss: 2.302320957183838 Accuracy: 0.125\n","Loss: 2.291714668273926 Accuracy: 0.25\n","Loss: 2.285938024520874 Accuracy: 0.140625\n","Loss: 2.2887351512908936 Accuracy: 0.203125\n","Loss: 2.286573648452759 Accuracy: 0.21875\n","Loss: 2.287202835083008 Accuracy: 0.171875\n","Loss: 2.284730911254883 Accuracy: 0.21875\n","Loss: 2.294987916946411 Accuracy: 0.125\n","Loss: 2.277622699737549 Accuracy: 0.21875\n","Loss: 2.2766804695129395 Accuracy: 0.234375\n","Loss: 2.287374973297119 Accuracy: 0.171875\n","Loss: 2.2721407413482666 Accuracy: 0.25\n","Loss: 2.2708661556243896 Accuracy: 0.203125\n","Loss: 2.2967941761016846 Accuracy: 0.109375\n","Loss: 2.2877144813537598 Accuracy: 0.125\n","Loss: 2.2912790775299072 Accuracy: 0.109375\n","Loss: 2.2752726078033447 Accuracy: 0.25\n","Loss: 2.302262306213379 Accuracy: 0.109375\n","Loss: 2.274049997329712 Accuracy: 0.265625\n","Loss: 2.2731645107269287 Accuracy: 0.21875\n","Loss: 2.2988600730895996 Accuracy: 0.1875\n","Loss: 2.302187919616699 Accuracy: 0.09375\n","Loss: 2.264369487762451 Accuracy: 0.171875\n","Loss: 2.276865005493164 Accuracy: 0.171875\n","Loss: 2.293255567550659 Accuracy: 0.140625\n","Loss: 2.2771968841552734 Accuracy: 0.1875\n","Loss: 2.2946300506591797 Accuracy: 0.15625\n","Loss: 2.285153865814209 Accuracy: 0.171875\n","Loss: 2.298574686050415 Accuracy: 0.1875\n","Loss: 2.2911758422851562 Accuracy: 0.15625\n","Loss: 2.2797203063964844 Accuracy: 0.1875\n","Loss: 2.306014060974121 Accuracy: 0.109375\n","Loss: 2.2950029373168945 Accuracy: 0.140625\n","Loss: 2.2770397663116455 Accuracy: 0.125\n","Loss: 2.261148452758789 Accuracy: 0.296875\n","Loss: 2.2920026779174805 Accuracy: 0.15625\n","Loss: 2.2913479804992676 Accuracy: 0.0625\n","Loss: 2.2885069847106934 Accuracy: 0.09375\n","Loss: 2.2709343433380127 Accuracy: 0.234375\n","Loss: 2.295640230178833 Accuracy: 0.09375\n","Loss: 2.273495674133301 Accuracy: 0.234375\n","Loss: 2.2939324378967285 Accuracy: 0.109375\n","Loss: 2.2883126735687256 Accuracy: 0.140625\n","Loss: 2.2735111713409424 Accuracy: 0.234375\n","Loss: 2.2730777263641357 Accuracy: 0.1875\n","Loss: 2.270230531692505 Accuracy: 0.296875\n","Loss: 2.2976224422454834 Accuracy: 0.171875\n","Loss: 2.2734272480010986 Accuracy: 0.1875\n","Loss: 2.2881128787994385 Accuracy: 0.21875\n","Loss: 2.291903018951416 Accuracy: 0.171875\n","Loss: 2.3006255626678467 Accuracy: 0.125\n","Loss: 2.2871017456054688 Accuracy: 0.25\n","Loss: 2.2644622325897217 Accuracy: 0.25\n","Loss: 2.267988681793213 Accuracy: 0.1875\n","Loss: 2.293199062347412 Accuracy: 0.140625\n","Loss: 2.296793222427368 Accuracy: 0.21875\n","Loss: 2.277116298675537 Accuracy: 0.21875\n","Loss: 2.285529136657715 Accuracy: 0.15625\n","Loss: 2.27565336227417 Accuracy: 0.15625\n","Loss: 2.273226261138916 Accuracy: 0.234375\n","Loss: 2.2954437732696533 Accuracy: 0.125\n","Loss: 2.283149003982544 Accuracy: 0.125\n","Loss: 2.30135440826416 Accuracy: 0.140625\n","Loss: 2.285001754760742 Accuracy: 0.140625\n","Loss: 2.2902133464813232 Accuracy: 0.15625\n","Loss: 2.280217170715332 Accuracy: 0.171875\n","Loss: 2.269667148590088 Accuracy: 0.234375\n","Loss: 2.2955799102783203 Accuracy: 0.140625\n","Loss: 2.278625011444092 Accuracy: 0.1875\n","Loss: 2.2743430137634277 Accuracy: 0.203125\n","Loss: 2.2662439346313477 Accuracy: 0.15625\n","Loss: 2.269113540649414 Accuracy: 0.1875\n","Loss: 2.280034303665161 Accuracy: 0.140625\n","Loss: 2.2722389698028564 Accuracy: 0.1875\n","Loss: 2.276589870452881 Accuracy: 0.203125\n","Loss: 2.249994993209839 Accuracy: 0.203125\n","Loss: 2.263228178024292 Accuracy: 0.171875\n","Loss: 2.2633824348449707 Accuracy: 0.234375\n","Loss: 2.272989511489868 Accuracy: 0.21875\n","Loss: 2.2667531967163086 Accuracy: 0.265625\n","Loss: 2.2715799808502197 Accuracy: 0.234375\n","Loss: 2.264786720275879 Accuracy: 0.203125\n","Loss: 2.259343147277832 Accuracy: 0.203125\n","Loss: 2.2855563163757324 Accuracy: 0.171875\n","Loss: 2.273818016052246 Accuracy: 0.15625\n","Loss: 2.2612340450286865 Accuracy: 0.203125\n","Loss: 2.289768934249878 Accuracy: 0.15625\n","Loss: 2.2800986766815186 Accuracy: 0.125\n","Loss: 2.2835350036621094 Accuracy: 0.171875\n","Loss: 2.260803699493408 Accuracy: 0.203125\n","Loss: 2.270367383956909 Accuracy: 0.21875\n","Loss: 2.2622976303100586 Accuracy: 0.1875\n","Loss: 2.252415418624878 Accuracy: 0.234375\n","Loss: 2.273392915725708 Accuracy: 0.203125\n","Loss: 2.2738962173461914 Accuracy: 0.203125\n","Loss: 2.270437479019165 Accuracy: 0.171875\n","Loss: 2.275775909423828 Accuracy: 0.140625\n","Loss: 2.2856380939483643 Accuracy: 0.21875\n","Loss: 2.2549967765808105 Accuracy: 0.203125\n","Loss: 2.2780182361602783 Accuracy: 0.140625\n","Loss: 2.274078607559204 Accuracy: 0.21875\n","Loss: 2.2894415855407715 Accuracy: 0.171875\n","Loss: 2.2641100883483887 Accuracy: 0.1875\n","Loss: 2.276721954345703 Accuracy: 0.203125\n","Loss: 2.27902889251709 Accuracy: 0.171875\n","Loss: 2.2879221439361572 Accuracy: 0.140625\n","Loss: 2.270080804824829 Accuracy: 0.15625\n","Loss: 2.299792528152466 Accuracy: 0.09375\n","Loss: 2.2894227504730225 Accuracy: 0.140625\n","Loss: 2.251004219055176 Accuracy: 0.265625\n","Loss: 2.2554891109466553 Accuracy: 0.21875\n","Loss: 2.2820932865142822 Accuracy: 0.15625\n","Loss: 2.254845380783081 Accuracy: 0.1875\n","Loss: 2.3094987869262695 Accuracy: 0.125\n","Loss: 2.2648847103118896 Accuracy: 0.125\n","Loss: 2.273481845855713 Accuracy: 0.171875\n","Loss: 2.2605204582214355 Accuracy: 0.140625\n","Loss: 2.283600091934204 Accuracy: 0.203125\n","Loss: 2.2325589656829834 Accuracy: 0.34375\n","Loss: 2.2568981647491455 Accuracy: 0.21875\n","Loss: 2.2704732418060303 Accuracy: 0.1875\n","Loss: 2.2735984325408936 Accuracy: 0.125\n","Loss: 2.2597756385803223 Accuracy: 0.203125\n","Loss: 2.257026433944702 Accuracy: 0.1875\n","Loss: 2.2992477416992188 Accuracy: 0.171875\n","Loss: 2.2778432369232178 Accuracy: 0.15625\n","Loss: 2.249664306640625 Accuracy: 0.15625\n","Loss: 2.2720930576324463 Accuracy: 0.1875\n","Loss: 2.240203857421875 Accuracy: 0.203125\n","Loss: 2.279789686203003 Accuracy: 0.1875\n","Loss: 2.2522881031036377 Accuracy: 0.109375\n","Loss: 2.237314224243164 Accuracy: 0.25\n","Loss: 2.2737808227539062 Accuracy: 0.109375\n","Loss: 2.2754650115966797 Accuracy: 0.125\n","Loss: 2.2450222969055176 Accuracy: 0.234375\n","Loss: 2.24408221244812 Accuracy: 0.25\n","Loss: 2.24337100982666 Accuracy: 0.21875\n","Loss: 2.256789207458496 Accuracy: 0.1875\n","Loss: 2.281522512435913 Accuracy: 0.125\n","Loss: 2.272871732711792 Accuracy: 0.265625\n","Loss: 2.248363971710205 Accuracy: 0.1875\n","Loss: 2.261709690093994 Accuracy: 0.1875\n","Loss: 2.247903823852539 Accuracy: 0.21875\n","Loss: 2.2669191360473633 Accuracy: 0.1875\n","Loss: 2.245027780532837 Accuracy: 0.25\n","Loss: 2.26532244682312 Accuracy: 0.234375\n","Loss: 2.2623682022094727 Accuracy: 0.203125\n","Loss: 2.253884792327881 Accuracy: 0.203125\n","Loss: 2.247344493865967 Accuracy: 0.25\n","Loss: 2.2597548961639404 Accuracy: 0.1875\n","Loss: 2.245530605316162 Accuracy: 0.234375\n","Loss: 2.2370214462280273 Accuracy: 0.203125\n","Loss: 2.2297732830047607 Accuracy: 0.203125\n","Loss: 2.265782356262207 Accuracy: 0.09375\n","Loss: 2.250082492828369 Accuracy: 0.203125\n","Loss: 2.2778117656707764 Accuracy: 0.140625\n","Loss: 2.2237396240234375 Accuracy: 0.28125\n","Loss: 2.244145393371582 Accuracy: 0.171875\n","Loss: 2.2485172748565674 Accuracy: 0.21875\n","Loss: 2.2516586780548096 Accuracy: 0.140625\n","Loss: 2.2492687702178955 Accuracy: 0.15625\n","Loss: 2.2614641189575195 Accuracy: 0.1875\n","Loss: 2.2703046798706055 Accuracy: 0.109375\n","Loss: 2.2389206886291504 Accuracy: 0.21875\n","Loss: 2.2348153591156006 Accuracy: 0.21875\n","Loss: 2.235325336456299 Accuracy: 0.21875\n","Loss: 2.2457661628723145 Accuracy: 0.15625\n","Loss: 2.230177164077759 Accuracy: 0.1875\n","Loss: 2.2384331226348877 Accuracy: 0.1875\n","Loss: 2.245830774307251 Accuracy: 0.265625\n","Loss: 2.253523349761963 Accuracy: 0.25\n","Loss: 2.2423574924468994 Accuracy: 0.1875\n","Loss: 2.2237770557403564 Accuracy: 0.234375\n","Loss: 2.2440338134765625 Accuracy: 0.171875\n","Loss: 2.2183868885040283 Accuracy: 0.265625\n","Loss: 2.2249951362609863 Accuracy: 0.25\n","Loss: 2.2468719482421875 Accuracy: 0.1875\n","Loss: 2.2512738704681396 Accuracy: 0.203125\n","Loss: 2.2111973762512207 Accuracy: 0.265625\n","Loss: 2.23071026802063 Accuracy: 0.28125\n","Loss: 2.261962413787842 Accuracy: 0.140625\n","Loss: 2.2383899688720703 Accuracy: 0.234375\n","Loss: 2.2775139808654785 Accuracy: 0.109375\n","Loss: 2.2692999839782715 Accuracy: 0.203125\n","Loss: 2.2331223487854004 Accuracy: 0.21875\n","Loss: 2.251011610031128 Accuracy: 0.125\n","Loss: 2.2365658283233643 Accuracy: 0.265625\n","Loss: 2.2828221321105957 Accuracy: 0.140625\n","Loss: 2.219892978668213 Accuracy: 0.21875\n","Loss: 2.224290609359741 Accuracy: 0.21875\n","Loss: 2.226236581802368 Accuracy: 0.21875\n","Loss: 2.2451486587524414 Accuracy: 0.234375\n","Loss: 2.2621922492980957 Accuracy: 0.109375\n","Loss: 2.2654833793640137 Accuracy: 0.109375\n","Loss: 2.2172346115112305 Accuracy: 0.25\n","Loss: 2.235370397567749 Accuracy: 0.25\n","Loss: 2.2079739570617676 Accuracy: 0.234375\n","Loss: 2.225207567214966 Accuracy: 0.265625\n","Loss: 2.2692272663116455 Accuracy: 0.171875\n","Loss: 2.2209384441375732 Accuracy: 0.21875\n","Loss: 2.251317024230957 Accuracy: 0.203125\n","Loss: 2.258157730102539 Accuracy: 0.203125\n","Loss: 2.237704277038574 Accuracy: 0.25\n","Loss: 2.2192752361297607 Accuracy: 0.25\n","Loss: 2.2439358234405518 Accuracy: 0.140625\n","Loss: 2.233591079711914 Accuracy: 0.203125\n","Loss: 2.215846538543701 Accuracy: 0.234375\n","Loss: 2.2575273513793945 Accuracy: 0.1875\n","Loss: 2.2440710067749023 Accuracy: 0.21875\n","Loss: 2.253194570541382 Accuracy: 0.140625\n","Loss: 2.239811658859253 Accuracy: 0.171875\n","Loss: 2.2155001163482666 Accuracy: 0.265625\n","Loss: 2.19572114944458 Accuracy: 0.25\n","Loss: 2.2238681316375732 Accuracy: 0.25\n","Loss: 2.206214427947998 Accuracy: 0.234375\n","Loss: 2.237231969833374 Accuracy: 0.203125\n","Loss: 2.2541697025299072 Accuracy: 0.15625\n","Loss: 2.234894275665283 Accuracy: 0.234375\n","Loss: 2.233834981918335 Accuracy: 0.1875\n","Loss: 2.243952751159668 Accuracy: 0.203125\n","Loss: 2.246649980545044 Accuracy: 0.171875\n","Loss: 2.241797685623169 Accuracy: 0.203125\n","Loss: 2.214710235595703 Accuracy: 0.21875\n","Loss: 2.246011972427368 Accuracy: 0.140625\n","Loss: 2.222410202026367 Accuracy: 0.15625\n","Loss: 2.2229971885681152 Accuracy: 0.1875\n","Loss: 2.2516958713531494 Accuracy: 0.15625\n","Loss: 2.250581979751587 Accuracy: 0.140625\n","Loss: 2.228649139404297 Accuracy: 0.1875\n","Loss: 2.201854944229126 Accuracy: 0.203125\n","Loss: 2.229098320007324 Accuracy: 0.21875\n","Loss: 2.255946397781372 Accuracy: 0.09375\n","Loss: 2.2083778381347656 Accuracy: 0.25\n","Loss: 2.2578625679016113 Accuracy: 0.140625\n","Loss: 2.2190968990325928 Accuracy: 0.203125\n","Loss: 2.2138891220092773 Accuracy: 0.1875\n","Loss: 2.2341175079345703 Accuracy: 0.125\n","Loss: 2.2259554862976074 Accuracy: 0.234375\n","Loss: 2.244781494140625 Accuracy: 0.125\n","Loss: 2.222470998764038 Accuracy: 0.203125\n","Loss: 2.254690647125244 Accuracy: 0.140625\n","Loss: 2.226295232772827 Accuracy: 0.203125\n","Loss: 2.2330307960510254 Accuracy: 0.234375\n","Loss: 2.2374722957611084 Accuracy: 0.171875\n","Loss: 2.2300820350646973 Accuracy: 0.21875\n","Loss: 2.2324445247650146 Accuracy: 0.25\n","Loss: 2.232102870941162 Accuracy: 0.25\n","Loss: 2.2274529933929443 Accuracy: 0.203125\n","Loss: 2.2394139766693115 Accuracy: 0.1875\n","Loss: 2.1908159255981445 Accuracy: 0.203125\n","Loss: 2.223297357559204 Accuracy: 0.203125\n","Loss: 2.1738955974578857 Accuracy: 0.203125\n","Loss: 2.2717230319976807 Accuracy: 0.109375\n","Loss: 2.2503952980041504 Accuracy: 0.140625\n","Loss: 2.253932237625122 Accuracy: 0.140625\n","Loss: 2.1724541187286377 Accuracy: 0.296875\n","Loss: 2.225428342819214 Accuracy: 0.140625\n","Loss: 2.206465005874634 Accuracy: 0.1875\n","Loss: 2.1716575622558594 Accuracy: 0.203125\n","Loss: 2.2499587535858154 Accuracy: 0.140625\n","Loss: 2.2058353424072266 Accuracy: 0.234375\n","Loss: 2.2389450073242188 Accuracy: 0.09375\n","Loss: 2.289824962615967 Accuracy: 0.09375\n","Loss: 2.2188868522644043 Accuracy: 0.15625\n","Loss: 2.228898048400879 Accuracy: 0.21875\n","Loss: 2.2401084899902344 Accuracy: 0.15625\n","Loss: 2.2165913581848145 Accuracy: 0.15625\n","Loss: 2.228523015975952 Accuracy: 0.125\n","Loss: 2.1800873279571533 Accuracy: 0.265625\n","Loss: 2.190767526626587 Accuracy: 0.265625\n","Loss: 2.2701187133789062 Accuracy: 0.140625\n","Loss: 2.171013116836548 Accuracy: 0.28125\n","Loss: 2.25392746925354 Accuracy: 0.15625\n","Loss: 2.1773502826690674 Accuracy: 0.234375\n","Loss: 2.2497427463531494 Accuracy: 0.203125\n","Loss: 2.2119951248168945 Accuracy: 0.140625\n","Loss: 2.2213668823242188 Accuracy: 0.125\n","Loss: 2.1775665283203125 Accuracy: 0.21875\n","Loss: 2.203691005706787 Accuracy: 0.25\n","Loss: 2.229898452758789 Accuracy: 0.140625\n","Loss: 2.184600591659546 Accuracy: 0.265625\n","Loss: 2.2863850593566895 Accuracy: 0.125\n","Loss: 2.239320755004883 Accuracy: 0.1875\n","Loss: 2.182990550994873 Accuracy: 0.234375\n","Loss: 2.1794986724853516 Accuracy: 0.1875\n","Loss: 2.146026849746704 Accuracy: 0.296875\n","Loss: 2.219940423965454 Accuracy: 0.140625\n","Loss: 2.192431926727295 Accuracy: 0.21875\n","Loss: 2.217623710632324 Accuracy: 0.21875\n","Loss: 2.2106761932373047 Accuracy: 0.234375\n","Loss: 2.1848292350769043 Accuracy: 0.21875\n","Loss: 2.2041449546813965 Accuracy: 0.15625\n","Loss: 2.243161678314209 Accuracy: 0.1875\n","Loss: 2.200293779373169 Accuracy: 0.25\n","Loss: 2.1766161918640137 Accuracy: 0.234375\n","Loss: 2.178236484527588 Accuracy: 0.28125\n","Loss: 2.145188093185425 Accuracy: 0.28125\n","Loss: 2.176218271255493 Accuracy: 0.234375\n","Loss: 2.218245506286621 Accuracy: 0.1875\n","Loss: 2.2146432399749756 Accuracy: 0.28125\n","Loss: 2.191284656524658 Accuracy: 0.15625\n","Loss: 2.228020668029785 Accuracy: 0.171875\n","Loss: 2.221755266189575 Accuracy: 0.1875\n","Loss: 2.217994451522827 Accuracy: 0.203125\n","Loss: 2.1843559741973877 Accuracy: 0.25\n","Loss: 2.2208874225616455 Accuracy: 0.15625\n","Loss: 2.204710006713867 Accuracy: 0.171875\n","Loss: 2.2322161197662354 Accuracy: 0.203125\n","Loss: 2.246530532836914 Accuracy: 0.15625\n","Loss: 2.1575405597686768 Accuracy: 0.25\n","Loss: 2.1805241107940674 Accuracy: 0.296875\n","Loss: 2.1823225021362305 Accuracy: 0.1875\n","Loss: 2.150571823120117 Accuracy: 0.21875\n","Loss: 2.1736056804656982 Accuracy: 0.203125\n","Loss: 2.2650933265686035 Accuracy: 0.109375\n","Loss: 2.1742539405822754 Accuracy: 0.203125\n","Loss: 2.2089552879333496 Accuracy: 0.21875\n","Loss: 2.1823618412017822 Accuracy: 0.265625\n","Loss: 2.1844229698181152 Accuracy: 0.171875\n","Loss: 2.175673246383667 Accuracy: 0.234375\n","Loss: 2.21232533454895 Accuracy: 0.15625\n","Loss: 2.150330066680908 Accuracy: 0.140625\n","Loss: 2.217132329940796 Accuracy: 0.1875\n","Loss: 2.203505516052246 Accuracy: 0.203125\n","Loss: 2.21979022026062 Accuracy: 0.21875\n","Loss: 2.1749706268310547 Accuracy: 0.234375\n","Loss: 2.1585049629211426 Accuracy: 0.265625\n","Loss: 2.201291084289551 Accuracy: 0.1875\n","Loss: 2.1657955646514893 Accuracy: 0.28125\n","Loss: 2.2010698318481445 Accuracy: 0.1875\n","Loss: 2.209658622741699 Accuracy: 0.203125\n","Loss: 2.193943500518799 Accuracy: 0.203125\n","Loss: 2.1921510696411133 Accuracy: 0.203125\n","Loss: 2.225872278213501 Accuracy: 0.15625\n","Loss: 2.2168209552764893 Accuracy: 0.140625\n","Loss: 2.1734983921051025 Accuracy: 0.21875\n","Loss: 2.141157388687134 Accuracy: 0.28125\n","Loss: 2.2452402114868164 Accuracy: 0.125\n","Loss: 2.236811876296997 Accuracy: 0.1875\n","Loss: 2.2039809226989746 Accuracy: 0.234375\n","Loss: 2.129554271697998 Accuracy: 0.25\n","Loss: 2.1892788410186768 Accuracy: 0.203125\n","Loss: 2.2151858806610107 Accuracy: 0.15625\n","Loss: 2.2404446601867676 Accuracy: 0.125\n","Loss: 2.1848692893981934 Accuracy: 0.21875\n","Loss: 2.228583335876465 Accuracy: 0.15625\n","Loss: 2.2419564723968506 Accuracy: 0.1875\n","Loss: 2.167717933654785 Accuracy: 0.1875\n","Loss: 2.1225969791412354 Accuracy: 0.265625\n","Loss: 2.192560911178589 Accuracy: 0.234375\n","Loss: 2.241116523742676 Accuracy: 0.15625\n","Loss: 2.2044906616210938 Accuracy: 0.203125\n","Loss: 2.1535158157348633 Accuracy: 0.25\n","Loss: 2.150346517562866 Accuracy: 0.21875\n","Loss: 2.15840744972229 Accuracy: 0.234375\n","Loss: 2.2421059608459473 Accuracy: 0.125\n","Loss: 2.226973056793213 Accuracy: 0.125\n","Loss: 2.1948461532592773 Accuracy: 0.140625\n","Loss: 2.1332972049713135 Accuracy: 0.28125\n","Loss: 2.1737992763519287 Accuracy: 0.234375\n","Loss: 2.183461904525757 Accuracy: 0.25\n","Loss: 2.1670165061950684 Accuracy: 0.3125\n","Loss: 2.159775495529175 Accuracy: 0.28125\n","Loss: 2.1525402069091797 Accuracy: 0.328125\n","Loss: 2.208404064178467 Accuracy: 0.1875\n","Loss: 2.1528055667877197 Accuracy: 0.28125\n","Loss: 2.1361947059631348 Accuracy: 0.25\n","Loss: 2.1782889366149902 Accuracy: 0.25\n","Loss: 2.1289567947387695 Accuracy: 0.265625\n","Loss: 2.2078917026519775 Accuracy: 0.15625\n","Loss: 2.187969446182251 Accuracy: 0.21875\n","Loss: 2.1661698818206787 Accuracy: 0.234375\n","Loss: 2.124324321746826 Accuracy: 0.3125\n","Loss: 2.2383623123168945 Accuracy: 0.1875\n","Loss: 2.1990599632263184 Accuracy: 0.15625\n","Loss: 2.2197513580322266 Accuracy: 0.15625\n","Loss: 2.217985153198242 Accuracy: 0.09375\n","Loss: 2.1925771236419678 Accuracy: 0.140625\n","Loss: 2.2368323802948 Accuracy: 0.234375\n","Loss: 2.2298977375030518 Accuracy: 0.21875\n","Loss: 2.204979181289673 Accuracy: 0.171875\n","Loss: 2.2048232555389404 Accuracy: 0.203125\n","Loss: 2.1447765827178955 Accuracy: 0.265625\n","Loss: 2.202272653579712 Accuracy: 0.171875\n","Loss: 2.1356914043426514 Accuracy: 0.203125\n","Loss: 2.1832332611083984 Accuracy: 0.171875\n","Loss: 2.1505465507507324 Accuracy: 0.25\n","Loss: 2.1734349727630615 Accuracy: 0.171875\n","Loss: 2.1066415309906006 Accuracy: 0.296875\n","Loss: 2.176687479019165 Accuracy: 0.28125\n","Loss: 2.263458490371704 Accuracy: 0.109375\n","Loss: 2.16926908493042 Accuracy: 0.1875\n","Loss: 2.2185304164886475 Accuracy: 0.171875\n","Loss: 2.199669361114502 Accuracy: 0.1875\n","Loss: 2.173309564590454 Accuracy: 0.21875\n","Loss: 2.1013145446777344 Accuracy: 0.234375\n","Loss: 2.1681461334228516 Accuracy: 0.265625\n","Loss: 2.1739792823791504 Accuracy: 0.25\n","Loss: 2.2636771202087402 Accuracy: 0.140625\n","Loss: 2.1795668601989746 Accuracy: 0.15625\n","Loss: 2.1626925468444824 Accuracy: 0.234375\n","Loss: 2.133779525756836 Accuracy: 0.234375\n","Loss: 2.200571298599243 Accuracy: 0.15625\n","Loss: 2.1454694271087646 Accuracy: 0.234375\n","Loss: 2.1446897983551025 Accuracy: 0.265625\n","Loss: 2.169189453125 Accuracy: 0.25\n","Loss: 2.191930055618286 Accuracy: 0.21875\n","Loss: 2.2115561962127686 Accuracy: 0.171875\n","Loss: 2.141441583633423 Accuracy: 0.265625\n","Loss: 2.2085251808166504 Accuracy: 0.171875\n","Loss: 2.143292188644409 Accuracy: 0.25\n","Loss: 2.239621162414551 Accuracy: 0.1875\n","Loss: 2.18709659576416 Accuracy: 0.203125\n","Loss: 2.1747353076934814 Accuracy: 0.265625\n","Loss: 2.1590631008148193 Accuracy: 0.203125\n","Loss: 2.111142635345459 Accuracy: 0.28125\n","Loss: 2.232565402984619 Accuracy: 0.109375\n","Loss: 2.0673367977142334 Accuracy: 0.34375\n","Loss: 2.1753010749816895 Accuracy: 0.140625\n","Loss: 2.1855764389038086 Accuracy: 0.15625\n","Loss: 2.1550652980804443 Accuracy: 0.265625\n","Loss: 2.135366678237915 Accuracy: 0.21875\n","Loss: 2.17181396484375 Accuracy: 0.203125\n","Loss: 2.127948760986328 Accuracy: 0.234375\n","Loss: 2.1550564765930176 Accuracy: 0.1875\n","Loss: 2.159914493560791 Accuracy: 0.140625\n","Loss: 2.1580047607421875 Accuracy: 0.203125\n","Loss: 2.1648950576782227 Accuracy: 0.1875\n","Loss: 2.163320302963257 Accuracy: 0.1875\n","Loss: 2.112457513809204 Accuracy: 0.265625\n","Loss: 2.094428539276123 Accuracy: 0.28125\n","Loss: 2.195554733276367 Accuracy: 0.21875\n","Loss: 2.230595111846924 Accuracy: 0.078125\n","Loss: 2.1388983726501465 Accuracy: 0.171875\n","Loss: 2.201054811477661 Accuracy: 0.1875\n","Loss: 2.0966274738311768 Accuracy: 0.3125\n","Loss: 2.1553618907928467 Accuracy: 0.21875\n","Loss: 2.1371660232543945 Accuracy: 0.234375\n","Loss: 2.1334259510040283 Accuracy: 0.296875\n","Loss: 2.1573047637939453 Accuracy: 0.21875\n","Loss: 2.192321300506592 Accuracy: 0.171875\n","Loss: 2.13395357131958 Accuracy: 0.25\n","Loss: 2.1395816802978516 Accuracy: 0.265625\n","Loss: 2.158435821533203 Accuracy: 0.21875\n","Loss: 2.104978322982788 Accuracy: 0.234375\n","Loss: 2.197996139526367 Accuracy: 0.15625\n","Loss: 2.1147217750549316 Accuracy: 0.25\n","Loss: 2.1319432258605957 Accuracy: 0.25\n","Loss: 2.123438835144043 Accuracy: 0.3125\n","Loss: 2.157823324203491 Accuracy: 0.171875\n","Loss: 2.117584228515625 Accuracy: 0.296875\n","Loss: 2.097153663635254 Accuracy: 0.265625\n","Loss: 2.154716730117798 Accuracy: 0.25\n","Loss: 2.2278990745544434 Accuracy: 0.125\n","Loss: 2.1980299949645996 Accuracy: 0.234375\n","Loss: 2.198974370956421 Accuracy: 0.15625\n","Loss: 2.1481664180755615 Accuracy: 0.171875\n","Loss: 2.1409239768981934 Accuracy: 0.265625\n","Loss: 2.2114384174346924 Accuracy: 0.09375\n","Loss: 2.232279062271118 Accuracy: 0.15625\n","Loss: 2.174898147583008 Accuracy: 0.265625\n","Loss: 2.1715586185455322 Accuracy: 0.140625\n","Loss: 2.094883441925049 Accuracy: 0.3125\n","Loss: 2.115511655807495 Accuracy: 0.25\n","Loss: 2.2253990173339844 Accuracy: 0.109375\n","Loss: 2.133957862854004 Accuracy: 0.1875\n","Loss: 2.151371717453003 Accuracy: 0.265625\n","Loss: 2.1325297355651855 Accuracy: 0.25\n","Loss: 2.0962913036346436 Accuracy: 0.265625\n","Loss: 2.1724252700805664 Accuracy: 0.21875\n","Loss: 2.1998395919799805 Accuracy: 0.15625\n","Loss: 2.1202046871185303 Accuracy: 0.21875\n","Loss: 2.1258928775787354 Accuracy: 0.234375\n","Loss: 2.0685629844665527 Accuracy: 0.25\n","Loss: 2.173701524734497 Accuracy: 0.21875\n","Loss: 2.1518940925598145 Accuracy: 0.171875\n","Loss: 2.2014694213867188 Accuracy: 0.21875\n","Loss: 2.1809051036834717 Accuracy: 0.140625\n","Loss: 2.098924398422241 Accuracy: 0.203125\n","Loss: 2.16941499710083 Accuracy: 0.203125\n","Loss: 2.1297712326049805 Accuracy: 0.21875\n","Loss: 2.1814095973968506 Accuracy: 0.171875\n","Loss: 2.1788747310638428 Accuracy: 0.21875\n","Loss: 2.196722984313965 Accuracy: 0.234375\n","Loss: 2.1921334266662598 Accuracy: 0.15625\n","Loss: 2.201291561126709 Accuracy: 0.1875\n","Loss: 2.1420719623565674 Accuracy: 0.234375\n","Loss: 2.080122947692871 Accuracy: 0.234375\n","Loss: 2.1956799030303955 Accuracy: 0.140625\n","Loss: 2.147500991821289 Accuracy: 0.21875\n","Loss: 2.2234604358673096 Accuracy: 0.15625\n","Loss: 2.1564793586730957 Accuracy: 0.1875\n","Loss: 2.1579501628875732 Accuracy: 0.203125\n","Loss: 2.128920555114746 Accuracy: 0.171875\n","Loss: 2.1888668537139893 Accuracy: 0.25\n","Loss: 2.148679256439209 Accuracy: 0.140625\n","Loss: 2.1398258209228516 Accuracy: 0.25\n","Loss: 2.1104166507720947 Accuracy: 0.234375\n","Loss: 2.070953369140625 Accuracy: 0.234375\n","Loss: 2.1672933101654053 Accuracy: 0.171875\n","Loss: 2.1844305992126465 Accuracy: 0.171875\n","Loss: 2.154628276824951 Accuracy: 0.171875\n","Loss: 2.245318651199341 Accuracy: 0.125\n","Loss: 2.0941405296325684 Accuracy: 0.28125\n","Loss: 2.105109214782715 Accuracy: 0.203125\n","Loss: 2.0837271213531494 Accuracy: 0.296875\n","Loss: 2.1701550483703613 Accuracy: 0.203125\n","Loss: 2.0462687015533447 Accuracy: 0.3125\n","Loss: 2.1812658309936523 Accuracy: 0.1875\n","Loss: 2.103720188140869 Accuracy: 0.203125\n","Loss: 2.1324872970581055 Accuracy: 0.140625\n","Loss: 2.1297061443328857 Accuracy: 0.234375\n","Loss: 2.0717411041259766 Accuracy: 0.265625\n","Loss: 2.086359977722168 Accuracy: 0.265625\n","Loss: 2.1058497428894043 Accuracy: 0.25\n","Loss: 2.115875005722046 Accuracy: 0.171875\n","Loss: 2.156404733657837 Accuracy: 0.21875\n","Loss: 2.042498826980591 Accuracy: 0.1875\n","Loss: 2.11653733253479 Accuracy: 0.25\n","Loss: 2.087700843811035 Accuracy: 0.21875\n","Loss: 2.1423213481903076 Accuracy: 0.1875\n","Loss: 2.180704355239868 Accuracy: 0.234375\n","Loss: 2.12097430229187 Accuracy: 0.25\n","Loss: 2.1975090503692627 Accuracy: 0.171875\n","Loss: 2.1584508419036865 Accuracy: 0.21875\n","Loss: 2.1674962043762207 Accuracy: 0.203125\n","Loss: 2.103550910949707 Accuracy: 0.234375\n","Loss: 2.1730263233184814 Accuracy: 0.140625\n","Loss: 2.1009175777435303 Accuracy: 0.234375\n","Loss: 2.146718978881836 Accuracy: 0.21875\n","Loss: 2.140205144882202 Accuracy: 0.21875\n","Loss: 2.1116111278533936 Accuracy: 0.265625\n","Loss: 2.134300470352173 Accuracy: 0.25\n","Loss: 2.187692165374756 Accuracy: 0.109375\n","Loss: 2.105806827545166 Accuracy: 0.203125\n","Loss: 2.1097514629364014 Accuracy: 0.234375\n","Loss: 2.0836150646209717 Accuracy: 0.265625\n","Loss: 2.0841588973999023 Accuracy: 0.234375\n","Loss: 2.2426555156707764 Accuracy: 0.09375\n","Loss: 2.145665407180786 Accuracy: 0.234375\n","Loss: 2.127512216567993 Accuracy: 0.265625\n","Loss: 2.0869901180267334 Accuracy: 0.21875\n","Loss: 2.128706216812134 Accuracy: 0.171875\n","Loss: 2.0653140544891357 Accuracy: 0.3125\n","Loss: 2.242234468460083 Accuracy: 0.125\n","Loss: 2.098860025405884 Accuracy: 0.265625\n","Loss: 1.9836827516555786 Accuracy: 0.34375\n","Loss: 2.1365857124328613 Accuracy: 0.1875\n","Loss: 2.07208251953125 Accuracy: 0.234375\n","Loss: 2.097567558288574 Accuracy: 0.203125\n","Loss: 2.12069034576416 Accuracy: 0.15625\n","Loss: 2.1300320625305176 Accuracy: 0.203125\n","Loss: 2.0562140941619873 Accuracy: 0.28125\n","Loss: 2.1763429641723633 Accuracy: 0.15625\n","Loss: 2.1407885551452637 Accuracy: 0.203125\n","Loss: 2.152501106262207 Accuracy: 0.21875\n","Loss: 2.13568115234375 Accuracy: 0.21875\n","Loss: 2.054187536239624 Accuracy: 0.234375\n","Loss: 2.108482599258423 Accuracy: 0.125\n","Loss: 2.0677762031555176 Accuracy: 0.21875\n","Loss: 2.023573398590088 Accuracy: 0.203125\n","Loss: 2.1397719383239746 Accuracy: 0.203125\n","Loss: 2.1143698692321777 Accuracy: 0.15625\n","Loss: 2.117244243621826 Accuracy: 0.203125\n","Loss: 2.181023120880127 Accuracy: 0.171875\n","Loss: 2.06264328956604 Accuracy: 0.234375\n","Loss: 2.2254748344421387 Accuracy: 0.140625\n","Loss: 2.1597585678100586 Accuracy: 0.171875\n","Loss: 2.1457831859588623 Accuracy: 0.234375\n","Loss: 2.161252021789551 Accuracy: 0.171875\n","Loss: 2.2067172527313232 Accuracy: 0.1875\n","Loss: 2.16274094581604 Accuracy: 0.203125\n","Loss: 2.086343288421631 Accuracy: 0.28125\n","Loss: 1.9963241815567017 Accuracy: 0.3125\n","Loss: 2.0338709354400635 Accuracy: 0.34375\n","Loss: 2.0772695541381836 Accuracy: 0.265625\n","Loss: 2.0781731605529785 Accuracy: 0.25\n","Loss: 2.0245718955993652 Accuracy: 0.21875\n","Loss: 2.0871458053588867 Accuracy: 0.25\n","Loss: 2.117135524749756 Accuracy: 0.171875\n","Loss: 2.1252615451812744 Accuracy: 0.21875\n","Loss: 2.1436402797698975 Accuracy: 0.25\n","Loss: 2.0221097469329834 Accuracy: 0.28125\n","Loss: 2.1123340129852295 Accuracy: 0.1875\n","Loss: 2.179190158843994 Accuracy: 0.21875\n","Loss: 2.1765501499176025 Accuracy: 0.125\n","Loss: 2.03450870513916 Accuracy: 0.21875\n","Loss: 2.119621753692627 Accuracy: 0.1875\n","Loss: 2.1996967792510986 Accuracy: 0.1875\n","Loss: 2.1285595893859863 Accuracy: 0.203125\n","Loss: 2.1127524375915527 Accuracy: 0.234375\n","Loss: 2.1191766262054443 Accuracy: 0.21875\n","Loss: 2.0883231163024902 Accuracy: 0.265625\n","Loss: 2.2493247985839844 Accuracy: 0.15625\n","Loss: 2.1705005168914795 Accuracy: 0.109375\n","Loss: 2.077636480331421 Accuracy: 0.203125\n","Loss: 2.1711273193359375 Accuracy: 0.21875\n","Loss: 2.1254234313964844 Accuracy: 0.21875\n","Loss: 2.079132556915283 Accuracy: 0.21875\n","Loss: 2.0833191871643066 Accuracy: 0.21875\n","Loss: 2.084002733230591 Accuracy: 0.21875\n","Loss: 2.0730538368225098 Accuracy: 0.21875\n","Loss: 2.229295253753662 Accuracy: 0.125\n","Loss: 2.0550107955932617 Accuracy: 0.234375\n","Loss: 2.142409563064575 Accuracy: 0.15625\n","Loss: 2.187749147415161 Accuracy: 0.171875\n","Loss: 2.1417829990386963 Accuracy: 0.203125\n","Loss: 2.165799140930176 Accuracy: 0.140625\n","Loss: 2.160353899002075 Accuracy: 0.15625\n","Loss: 2.13012433052063 Accuracy: 0.15625\n","Loss: 2.1342709064483643 Accuracy: 0.265625\n","Loss: 1.9961788654327393 Accuracy: 0.25\n","Loss: 2.1168694496154785 Accuracy: 0.203125\n","Loss: 2.0932798385620117 Accuracy: 0.234375\n","Loss: 2.210991859436035 Accuracy: 0.09375\n","Loss: 2.0247228145599365 Accuracy: 0.265625\n","Loss: 2.072359085083008 Accuracy: 0.25\n","Loss: 2.0217974185943604 Accuracy: 0.34375\n","Loss: 2.014901638031006 Accuracy: 0.234375\n","Loss: 1.979307770729065 Accuracy: 0.28125\n","Loss: 2.0879080295562744 Accuracy: 0.21875\n","Loss: 2.054086208343506 Accuracy: 0.25\n","Loss: 2.1006100177764893 Accuracy: 0.1875\n","Loss: 2.0448033809661865 Accuracy: 0.265625\n","Loss: 2.1053569316864014 Accuracy: 0.171875\n","Loss: 2.1433463096618652 Accuracy: 0.171875\n","Loss: 2.094200849533081 Accuracy: 0.25\n","Loss: 2.1122708320617676 Accuracy: 0.234375\n","Loss: 2.2635388374328613 Accuracy: 0.171875\n","Loss: 2.169508218765259 Accuracy: 0.171875\n","Loss: 2.053262948989868 Accuracy: 0.265625\n","Loss: 2.141167402267456 Accuracy: 0.1875\n","Loss: 2.0440590381622314 Accuracy: 0.25\n","Loss: 2.083280324935913 Accuracy: 0.21875\n","Loss: 2.0805740356445312 Accuracy: 0.28125\n","Loss: 2.1180760860443115 Accuracy: 0.1875\n","Loss: 2.161548137664795 Accuracy: 0.234375\n","Loss: 2.042404890060425 Accuracy: 0.234375\n","Loss: 2.077332019805908 Accuracy: 0.1875\n","Loss: 2.1749396324157715 Accuracy: 0.15625\n","Epoch: 0\n","Loss: 2.1619794368743896 Accuracy: 0.1875\n","Loss: 2.0602235794067383 Accuracy: 0.328125\n","Loss: 2.0459582805633545 Accuracy: 0.25\n","Loss: 2.094832181930542 Accuracy: 0.15625\n","Loss: 2.0345702171325684 Accuracy: 0.234375\n","Loss: 2.153733253479004 Accuracy: 0.1875\n","Loss: 2.1139447689056396 Accuracy: 0.234375\n","Loss: 2.058847188949585 Accuracy: 0.25\n","Loss: 2.038731575012207 Accuracy: 0.3125\n","Loss: 2.0834310054779053 Accuracy: 0.265625\n","Loss: 2.1435630321502686 Accuracy: 0.203125\n","Loss: 2.0173778533935547 Accuracy: 0.25\n","Loss: 2.0860190391540527 Accuracy: 0.265625\n","Loss: 2.0290145874023438 Accuracy: 0.296875\n","Loss: 2.0496270656585693 Accuracy: 0.21875\n","Loss: 2.1504180431365967 Accuracy: 0.234375\n","Loss: 2.0949535369873047 Accuracy: 0.1875\n","Loss: 1.932021975517273 Accuracy: 0.375\n","Loss: 2.1033780574798584 Accuracy: 0.234375\n","Loss: 2.1537442207336426 Accuracy: 0.140625\n","Loss: 2.076598644256592 Accuracy: 0.1875\n","Loss: 2.163889169692993 Accuracy: 0.1875\n","Loss: 2.110307455062866 Accuracy: 0.1875\n","Loss: 2.098670721054077 Accuracy: 0.265625\n","Loss: 2.0786404609680176 Accuracy: 0.21875\n","Loss: 2.053525924682617 Accuracy: 0.234375\n","Loss: 2.156721353530884 Accuracy: 0.296875\n","Loss: 2.162668228149414 Accuracy: 0.1875\n","Loss: 2.1818320751190186 Accuracy: 0.125\n","Loss: 2.129991054534912 Accuracy: 0.296875\n","Loss: 2.0863029956817627 Accuracy: 0.1875\n","Loss: 2.174880027770996 Accuracy: 0.140625\n","Loss: 2.0334863662719727 Accuracy: 0.28125\n","Loss: 2.059204578399658 Accuracy: 0.21875\n","Loss: 2.072223663330078 Accuracy: 0.25\n","Loss: 2.0401954650878906 Accuracy: 0.234375\n","Loss: 2.1468796730041504 Accuracy: 0.234375\n","Loss: 2.0434529781341553 Accuracy: 0.296875\n","Loss: 2.13191294670105 Accuracy: 0.125\n","Loss: 2.0636162757873535 Accuracy: 0.203125\n","Loss: 2.1113407611846924 Accuracy: 0.171875\n","Loss: 2.0369396209716797 Accuracy: 0.21875\n","Loss: 2.091188669204712 Accuracy: 0.171875\n","Loss: 2.0382091999053955 Accuracy: 0.328125\n","Loss: 2.1306838989257812 Accuracy: 0.171875\n","Loss: 2.041438579559326 Accuracy: 0.265625\n","Loss: 2.103745937347412 Accuracy: 0.21875\n","Loss: 2.125183582305908 Accuracy: 0.1875\n","Loss: 2.0643820762634277 Accuracy: 0.265625\n","Loss: 2.0420734882354736 Accuracy: 0.21875\n","Loss: 2.1139941215515137 Accuracy: 0.21875\n","Loss: 2.108842134475708 Accuracy: 0.15625\n","Loss: 2.101130962371826 Accuracy: 0.28125\n","Loss: 2.023350238800049 Accuracy: 0.234375\n","Loss: 2.107988119125366 Accuracy: 0.28125\n","Loss: 2.1346683502197266 Accuracy: 0.203125\n","Loss: 2.058234453201294 Accuracy: 0.296875\n","Loss: 2.164029359817505 Accuracy: 0.140625\n","Loss: 2.0755367279052734 Accuracy: 0.203125\n","Loss: 1.9870291948318481 Accuracy: 0.34375\n","Loss: 2.0633692741394043 Accuracy: 0.25\n","Loss: 2.13700795173645 Accuracy: 0.125\n","Loss: 2.1177783012390137 Accuracy: 0.15625\n","Loss: 2.1052210330963135 Accuracy: 0.171875\n","Loss: 2.0382003784179688 Accuracy: 0.25\n","Loss: 2.196458101272583 Accuracy: 0.140625\n","Loss: 2.0283849239349365 Accuracy: 0.234375\n","Loss: 2.1202549934387207 Accuracy: 0.171875\n","Loss: 2.1491267681121826 Accuracy: 0.109375\n","Loss: 2.0576226711273193 Accuracy: 0.265625\n","Loss: 2.0164997577667236 Accuracy: 0.296875\n","Loss: 2.0676450729370117 Accuracy: 0.234375\n","Loss: 2.051581621170044 Accuracy: 0.25\n","Loss: 2.01304030418396 Accuracy: 0.265625\n","Loss: 2.0089619159698486 Accuracy: 0.296875\n","Loss: 2.085585355758667 Accuracy: 0.140625\n","Loss: 2.1066672801971436 Accuracy: 0.203125\n","Loss: 2.0896167755126953 Accuracy: 0.15625\n","Loss: 2.095188617706299 Accuracy: 0.15625\n","Loss: 1.9601236581802368 Accuracy: 0.3125\n","Loss: 2.026120662689209 Accuracy: 0.28125\n","Loss: 2.1159074306488037 Accuracy: 0.1875\n","Loss: 2.016071319580078 Accuracy: 0.296875\n","Loss: 2.107741117477417 Accuracy: 0.1875\n","Loss: 2.0357413291931152 Accuracy: 0.28125\n","Loss: 2.1323041915893555 Accuracy: 0.171875\n","Loss: 2.0920419692993164 Accuracy: 0.203125\n","Loss: 2.0820798873901367 Accuracy: 0.25\n","Loss: 2.0399203300476074 Accuracy: 0.21875\n","Loss: 2.091033935546875 Accuracy: 0.15625\n","Loss: 2.12992000579834 Accuracy: 0.140625\n","Loss: 2.1261050701141357 Accuracy: 0.203125\n","Loss: 2.0946226119995117 Accuracy: 0.203125\n","Loss: 2.082630157470703 Accuracy: 0.1875\n","Loss: 2.064748525619507 Accuracy: 0.265625\n","Loss: 2.1747448444366455 Accuracy: 0.171875\n","Loss: 1.9522414207458496 Accuracy: 0.3125\n","Loss: 2.0229318141937256 Accuracy: 0.25\n","Loss: 2.0298938751220703 Accuracy: 0.296875\n","Loss: 1.9621702432632446 Accuracy: 0.34375\n","Loss: 2.1365461349487305 Accuracy: 0.140625\n","Loss: 2.1723248958587646 Accuracy: 0.109375\n","Loss: 2.0661773681640625 Accuracy: 0.203125\n","Loss: 1.996142864227295 Accuracy: 0.296875\n","Loss: 2.1208462715148926 Accuracy: 0.21875\n","Loss: 2.093632221221924 Accuracy: 0.21875\n","Loss: 2.140218734741211 Accuracy: 0.15625\n","Loss: 2.1294174194335938 Accuracy: 0.15625\n","Loss: 2.020681858062744 Accuracy: 0.265625\n","Loss: 2.0680665969848633 Accuracy: 0.28125\n","Loss: 2.054551124572754 Accuracy: 0.3125\n","Loss: 2.0982532501220703 Accuracy: 0.125\n","Loss: 1.9913461208343506 Accuracy: 0.21875\n","Loss: 2.0471291542053223 Accuracy: 0.21875\n","Loss: 2.0884132385253906 Accuracy: 0.234375\n","Loss: 2.148833990097046 Accuracy: 0.1875\n","Loss: 2.012316942214966 Accuracy: 0.28125\n","Loss: 2.118523359298706 Accuracy: 0.203125\n","Loss: 2.0617432594299316 Accuracy: 0.203125\n","Loss: 2.040428638458252 Accuracy: 0.203125\n","Loss: 1.9753700494766235 Accuracy: 0.265625\n","Loss: 2.085726737976074 Accuracy: 0.21875\n","Loss: 2.0175280570983887 Accuracy: 0.296875\n","Loss: 2.1653215885162354 Accuracy: 0.125\n","Loss: 2.073887348175049 Accuracy: 0.1875\n","Loss: 2.120779514312744 Accuracy: 0.21875\n","Loss: 2.158867835998535 Accuracy: 0.140625\n","Loss: 2.219632625579834 Accuracy: 0.125\n","Loss: 2.1338186264038086 Accuracy: 0.09375\n","Loss: 2.0066616535186768 Accuracy: 0.171875\n","Loss: 2.1008999347686768 Accuracy: 0.171875\n","Loss: 2.0580594539642334 Accuracy: 0.234375\n","Loss: 2.0421411991119385 Accuracy: 0.28125\n","Loss: 2.101794481277466 Accuracy: 0.171875\n","Loss: 2.063854217529297 Accuracy: 0.265625\n","Loss: 2.103383779525757 Accuracy: 0.21875\n","Loss: 2.061540365219116 Accuracy: 0.21875\n","Loss: 2.072625160217285 Accuracy: 0.1875\n","Loss: 1.996519684791565 Accuracy: 0.21875\n","Loss: 2.085693359375 Accuracy: 0.1875\n","Loss: 2.109174966812134 Accuracy: 0.15625\n","Loss: 1.9886600971221924 Accuracy: 0.203125\n","Loss: 2.1535236835479736 Accuracy: 0.171875\n","Loss: 2.0168545246124268 Accuracy: 0.203125\n","Loss: 2.093632221221924 Accuracy: 0.265625\n","Loss: 2.1006977558135986 Accuracy: 0.125\n","Loss: 2.0692873001098633 Accuracy: 0.296875\n","Loss: 1.9752730131149292 Accuracy: 0.234375\n","Loss: 1.9816094636917114 Accuracy: 0.28125\n","Loss: 2.0386815071105957 Accuracy: 0.296875\n","Loss: 2.10455584526062 Accuracy: 0.15625\n","Loss: 2.1301167011260986 Accuracy: 0.171875\n","Loss: 2.0203211307525635 Accuracy: 0.21875\n","Loss: 1.9453439712524414 Accuracy: 0.25\n","Loss: 2.2414462566375732 Accuracy: 0.1875\n","Loss: 2.1493632793426514 Accuracy: 0.1875\n","Loss: 2.0612056255340576 Accuracy: 0.265625\n","Loss: 2.0356905460357666 Accuracy: 0.1875\n","Loss: 2.114210844039917 Accuracy: 0.1875\n","Loss: 2.076350688934326 Accuracy: 0.28125\n","Loss: 2.072383403778076 Accuracy: 0.25\n","Loss: 2.092092752456665 Accuracy: 0.203125\n","Loss: 2.021691083908081 Accuracy: 0.265625\n","Loss: 2.021930694580078 Accuracy: 0.296875\n","Loss: 1.9459494352340698 Accuracy: 0.3125\n","Loss: 1.9410730600357056 Accuracy: 0.328125\n","Loss: 2.0996148586273193 Accuracy: 0.203125\n","Loss: 2.2268660068511963 Accuracy: 0.15625\n","Loss: 2.0528385639190674 Accuracy: 0.25\n","Loss: 1.9801205396652222 Accuracy: 0.234375\n","Loss: 2.0094387531280518 Accuracy: 0.28125\n","Loss: 2.068927049636841 Accuracy: 0.203125\n","Loss: 2.001680374145508 Accuracy: 0.1875\n","Loss: 1.9914343357086182 Accuracy: 0.265625\n","Loss: 2.0276167392730713 Accuracy: 0.203125\n","Loss: 2.0873372554779053 Accuracy: 0.28125\n","Loss: 2.0918328762054443 Accuracy: 0.25\n","Loss: 2.0966861248016357 Accuracy: 0.15625\n","Loss: 2.0564756393432617 Accuracy: 0.28125\n","Loss: 1.9444671869277954 Accuracy: 0.25\n","Loss: 2.1141226291656494 Accuracy: 0.234375\n","Loss: 2.1299798488616943 Accuracy: 0.1875\n","Loss: 2.069798231124878 Accuracy: 0.1875\n","Loss: 2.0599918365478516 Accuracy: 0.203125\n","Loss: 1.9783374071121216 Accuracy: 0.265625\n","Loss: 2.060330390930176 Accuracy: 0.265625\n","Loss: 2.164659261703491 Accuracy: 0.171875\n","Loss: 1.940966010093689 Accuracy: 0.25\n","Loss: 2.030771255493164 Accuracy: 0.328125\n","Loss: 2.159275770187378 Accuracy: 0.15625\n","Loss: 2.0524702072143555 Accuracy: 0.171875\n","Loss: 1.9766314029693604 Accuracy: 0.234375\n","Loss: 1.9700734615325928 Accuracy: 0.1875\n","Loss: 2.1121392250061035 Accuracy: 0.171875\n","Loss: 2.0941948890686035 Accuracy: 0.171875\n","Loss: 1.9940950870513916 Accuracy: 0.296875\n","Loss: 1.9938832521438599 Accuracy: 0.234375\n","Loss: 2.1282870769500732 Accuracy: 0.234375\n","Loss: 2.118055820465088 Accuracy: 0.171875\n","Loss: 2.0069785118103027 Accuracy: 0.171875\n","Loss: 2.1385159492492676 Accuracy: 0.203125\n","Loss: 2.1095125675201416 Accuracy: 0.1875\n","Loss: 2.100740432739258 Accuracy: 0.140625\n","Loss: 2.023472785949707 Accuracy: 0.21875\n","Loss: 1.965769648551941 Accuracy: 0.234375\n","Loss: 2.0616676807403564 Accuracy: 0.21875\n","Loss: 2.1176512241363525 Accuracy: 0.15625\n","Loss: 1.9022802114486694 Accuracy: 0.328125\n","Loss: 2.0486438274383545 Accuracy: 0.25\n","Loss: 2.052685022354126 Accuracy: 0.25\n","Loss: 2.1441237926483154 Accuracy: 0.15625\n","Loss: 2.055410385131836 Accuracy: 0.265625\n","Loss: 1.9581868648529053 Accuracy: 0.265625\n","Loss: 1.935577630996704 Accuracy: 0.34375\n","Loss: 2.066441535949707 Accuracy: 0.203125\n","Loss: 2.1390199661254883 Accuracy: 0.234375\n","Loss: 1.977272391319275 Accuracy: 0.25\n","Loss: 2.0327537059783936 Accuracy: 0.21875\n","Loss: 2.0157506465911865 Accuracy: 0.359375\n","Loss: 2.0239248275756836 Accuracy: 0.171875\n","Loss: 2.0154829025268555 Accuracy: 0.234375\n","Loss: 2.1286349296569824 Accuracy: 0.140625\n","Loss: 1.9465936422348022 Accuracy: 0.265625\n","Loss: 1.9082820415496826 Accuracy: 0.265625\n","Loss: 1.9605422019958496 Accuracy: 0.296875\n","Loss: 1.972084403038025 Accuracy: 0.265625\n","Loss: 2.0559635162353516 Accuracy: 0.203125\n","Loss: 2.03633975982666 Accuracy: 0.1875\n","Loss: 2.089125871658325 Accuracy: 0.1875\n","Loss: 2.2432000637054443 Accuracy: 0.125\n","Loss: 1.9597612619400024 Accuracy: 0.25\n","Loss: 2.1248111724853516 Accuracy: 0.15625\n","Loss: 2.046797037124634 Accuracy: 0.1875\n","Loss: 2.101274251937866 Accuracy: 0.140625\n","Loss: 2.0621228218078613 Accuracy: 0.265625\n","Loss: 2.0554323196411133 Accuracy: 0.25\n","Loss: 2.0307281017303467 Accuracy: 0.203125\n","Loss: 2.095015287399292 Accuracy: 0.125\n","Loss: 1.9117066860198975 Accuracy: 0.296875\n","Loss: 1.9825714826583862 Accuracy: 0.3125\n","Loss: 1.9403780698776245 Accuracy: 0.328125\n","Loss: 2.12780499458313 Accuracy: 0.171875\n","Loss: 2.0973312854766846 Accuracy: 0.234375\n","Loss: 2.0664665699005127 Accuracy: 0.234375\n","Loss: 2.112468957901001 Accuracy: 0.203125\n","Loss: 2.1649057865142822 Accuracy: 0.078125\n","Loss: 2.06732177734375 Accuracy: 0.265625\n","Loss: 2.0677804946899414 Accuracy: 0.1875\n","Loss: 2.045804262161255 Accuracy: 0.234375\n","Loss: 2.052971363067627 Accuracy: 0.171875\n","Loss: 2.041118860244751 Accuracy: 0.15625\n","Loss: 2.0949459075927734 Accuracy: 0.171875\n","Loss: 2.017418384552002 Accuracy: 0.21875\n","Loss: 2.0291402339935303 Accuracy: 0.203125\n","Loss: 1.970683217048645 Accuracy: 0.25\n","Loss: 2.005314826965332 Accuracy: 0.21875\n","Loss: 2.0916707515716553 Accuracy: 0.203125\n","Loss: 2.041821002960205 Accuracy: 0.203125\n","Loss: 2.0236666202545166 Accuracy: 0.265625\n","Loss: 2.055962324142456 Accuracy: 0.15625\n","Loss: 2.0525152683258057 Accuracy: 0.28125\n","Loss: 1.9830653667449951 Accuracy: 0.296875\n","Loss: 2.037583112716675 Accuracy: 0.21875\n","Loss: 2.0544142723083496 Accuracy: 0.21875\n","Loss: 2.139087677001953 Accuracy: 0.125\n","Loss: 2.0553157329559326 Accuracy: 0.203125\n","Loss: 2.1848552227020264 Accuracy: 0.21875\n","Loss: 1.904071569442749 Accuracy: 0.359375\n","Loss: 1.9129232168197632 Accuracy: 0.25\n","Loss: 2.1188502311706543 Accuracy: 0.140625\n","Loss: 1.902199625968933 Accuracy: 0.34375\n","Loss: 2.0561342239379883 Accuracy: 0.203125\n","Loss: 2.0683109760284424 Accuracy: 0.171875\n","Loss: 1.8894822597503662 Accuracy: 0.3125\n","Loss: 2.1214261054992676 Accuracy: 0.15625\n","Loss: 1.953258752822876 Accuracy: 0.171875\n","Loss: 2.0506627559661865 Accuracy: 0.21875\n","Loss: 2.1621296405792236 Accuracy: 0.171875\n","Loss: 2.048692226409912 Accuracy: 0.171875\n","Loss: 2.0254764556884766 Accuracy: 0.265625\n","Loss: 1.9279264211654663 Accuracy: 0.328125\n","Loss: 2.0448267459869385 Accuracy: 0.234375\n","Loss: 2.0183026790618896 Accuracy: 0.265625\n","Loss: 1.9709644317626953 Accuracy: 0.34375\n","Loss: 2.0432887077331543 Accuracy: 0.234375\n","Loss: 1.940994381904602 Accuracy: 0.296875\n","Loss: 2.0085155963897705 Accuracy: 0.265625\n","Loss: 1.9253002405166626 Accuracy: 0.21875\n","Loss: 2.0471813678741455 Accuracy: 0.21875\n","Loss: 1.9959503412246704 Accuracy: 0.25\n","Loss: 2.0088977813720703 Accuracy: 0.203125\n","Loss: 2.039395809173584 Accuracy: 0.296875\n","Loss: 2.04258131980896 Accuracy: 0.203125\n","Loss: 1.9259313344955444 Accuracy: 0.234375\n","Loss: 2.0981333255767822 Accuracy: 0.171875\n","Loss: 1.9036718606948853 Accuracy: 0.25\n","Loss: 1.9232814311981201 Accuracy: 0.234375\n","Loss: 2.1147141456604004 Accuracy: 0.234375\n","Loss: 2.185959815979004 Accuracy: 0.1875\n","Loss: 2.0258913040161133 Accuracy: 0.1875\n","Loss: 2.092607259750366 Accuracy: 0.1875\n","Loss: 2.053579568862915 Accuracy: 0.203125\n","Loss: 2.0761609077453613 Accuracy: 0.21875\n","Loss: 2.0420196056365967 Accuracy: 0.1875\n","Loss: 2.2177114486694336 Accuracy: 0.171875\n","Loss: 2.0472512245178223 Accuracy: 0.171875\n","Loss: 1.9780480861663818 Accuracy: 0.234375\n","Loss: 2.126857280731201 Accuracy: 0.21875\n","Loss: 2.057622194290161 Accuracy: 0.203125\n","Loss: 2.11490535736084 Accuracy: 0.1875\n","Loss: 2.0555803775787354 Accuracy: 0.171875\n","Loss: 2.0848283767700195 Accuracy: 0.171875\n","Loss: 2.030489206314087 Accuracy: 0.1875\n","Loss: 2.140589952468872 Accuracy: 0.171875\n","Loss: 2.0303690433502197 Accuracy: 0.25\n","Loss: 1.9194660186767578 Accuracy: 0.265625\n","Loss: 2.1799395084381104 Accuracy: 0.15625\n","Loss: 2.017346143722534 Accuracy: 0.234375\n","Loss: 2.0688891410827637 Accuracy: 0.21875\n","Loss: 1.967555284500122 Accuracy: 0.21875\n","Loss: 2.0484116077423096 Accuracy: 0.234375\n","Loss: 2.029374599456787 Accuracy: 0.1875\n","Loss: 2.0952892303466797 Accuracy: 0.234375\n","Loss: 2.079834222793579 Accuracy: 0.21875\n","Loss: 2.094062089920044 Accuracy: 0.15625\n","Loss: 2.021259069442749 Accuracy: 0.21875\n","Loss: 2.124770164489746 Accuracy: 0.203125\n","Loss: 2.2179434299468994 Accuracy: 0.15625\n","Loss: 1.9130131006240845 Accuracy: 0.28125\n","Loss: 2.035609245300293 Accuracy: 0.28125\n","Loss: 2.002655267715454 Accuracy: 0.234375\n","Loss: 2.0566678047180176 Accuracy: 0.25\n","Loss: 2.1138360500335693 Accuracy: 0.25\n","Loss: 2.1170730590820312 Accuracy: 0.171875\n","Loss: 2.0246572494506836 Accuracy: 0.25\n","Loss: 2.047349214553833 Accuracy: 0.203125\n","Loss: 1.9727222919464111 Accuracy: 0.265625\n","Loss: 2.0254809856414795 Accuracy: 0.21875\n","Loss: 2.0251970291137695 Accuracy: 0.3125\n","Loss: 1.921366810798645 Accuracy: 0.3125\n","Loss: 1.9775500297546387 Accuracy: 0.265625\n","Loss: 1.964089035987854 Accuracy: 0.3125\n","Loss: 1.9779361486434937 Accuracy: 0.28125\n","Loss: 1.9898803234100342 Accuracy: 0.296875\n","Loss: 1.9123955965042114 Accuracy: 0.328125\n","Loss: 2.0982096195220947 Accuracy: 0.15625\n","Loss: 2.0519936084747314 Accuracy: 0.203125\n","Loss: 2.001091480255127 Accuracy: 0.25\n","Loss: 2.074568033218384 Accuracy: 0.15625\n","Loss: 2.021883010864258 Accuracy: 0.203125\n","Loss: 1.9543505907058716 Accuracy: 0.25\n","Loss: 1.9956353902816772 Accuracy: 0.21875\n","Loss: 2.0793309211730957 Accuracy: 0.21875\n","Loss: 2.018172264099121 Accuracy: 0.21875\n","Loss: 1.9977257251739502 Accuracy: 0.296875\n","Loss: 1.9569429159164429 Accuracy: 0.234375\n","Loss: 2.0530500411987305 Accuracy: 0.1875\n","Loss: 1.9793680906295776 Accuracy: 0.265625\n","Loss: 1.897414207458496 Accuracy: 0.296875\n","Loss: 2.096932888031006 Accuracy: 0.15625\n","Loss: 2.1238458156585693 Accuracy: 0.171875\n","Loss: 2.0655908584594727 Accuracy: 0.21875\n","Loss: 2.060736894607544 Accuracy: 0.203125\n","Loss: 2.1747889518737793 Accuracy: 0.234375\n","Loss: 1.9768743515014648 Accuracy: 0.3125\n","Loss: 1.8140071630477905 Accuracy: 0.34375\n","Loss: 1.8701212406158447 Accuracy: 0.34375\n","Loss: 2.0108067989349365 Accuracy: 0.203125\n","Loss: 2.1034228801727295 Accuracy: 0.171875\n","Loss: 1.946170687675476 Accuracy: 0.296875\n","Loss: 1.934131145477295 Accuracy: 0.28125\n","Loss: 1.9993138313293457 Accuracy: 0.234375\n","Loss: 1.9357481002807617 Accuracy: 0.328125\n","Loss: 2.152024507522583 Accuracy: 0.171875\n","Loss: 1.830325722694397 Accuracy: 0.34375\n","Loss: 2.0120205879211426 Accuracy: 0.234375\n","Loss: 2.0918357372283936 Accuracy: 0.21875\n","Loss: 1.9771653413772583 Accuracy: 0.234375\n","Loss: 2.135040760040283 Accuracy: 0.1875\n","Loss: 1.956397533416748 Accuracy: 0.28125\n","Loss: 1.9664210081100464 Accuracy: 0.25\n","Loss: 2.056641101837158 Accuracy: 0.171875\n","Loss: 2.10509991645813 Accuracy: 0.125\n","Loss: 2.1162493228912354 Accuracy: 0.15625\n","Loss: 2.024815559387207 Accuracy: 0.140625\n","Loss: 2.0775580406188965 Accuracy: 0.21875\n","Loss: 2.083186388015747 Accuracy: 0.234375\n","Loss: 1.8908607959747314 Accuracy: 0.40625\n","Loss: 2.1129086017608643 Accuracy: 0.203125\n","Loss: 1.9442270994186401 Accuracy: 0.25\n","Loss: 2.045236110687256 Accuracy: 0.25\n","Loss: 1.964723825454712 Accuracy: 0.328125\n","Loss: 1.9432120323181152 Accuracy: 0.3125\n","Loss: 2.2596778869628906 Accuracy: 0.09375\n","Loss: 1.876322865486145 Accuracy: 0.25\n","Loss: 2.0288426876068115 Accuracy: 0.1875\n","Loss: 1.9157330989837646 Accuracy: 0.265625\n","Loss: 1.9776207208633423 Accuracy: 0.296875\n","Loss: 2.0722858905792236 Accuracy: 0.203125\n","Loss: 2.0865771770477295 Accuracy: 0.1875\n","Loss: 1.9570682048797607 Accuracy: 0.25\n","Loss: 1.9773025512695312 Accuracy: 0.28125\n","Loss: 2.0573418140411377 Accuracy: 0.203125\n","Loss: 1.9610573053359985 Accuracy: 0.28125\n","Loss: 2.1192522048950195 Accuracy: 0.125\n","Loss: 2.1119256019592285 Accuracy: 0.21875\n","Loss: 2.0328755378723145 Accuracy: 0.25\n","Loss: 2.0056183338165283 Accuracy: 0.234375\n","Loss: 1.9878145456314087 Accuracy: 0.21875\n","Loss: 2.098008871078491 Accuracy: 0.234375\n","Loss: 2.20215106010437 Accuracy: 0.140625\n","Loss: 2.0586400032043457 Accuracy: 0.234375\n","Loss: 2.008697271347046 Accuracy: 0.25\n","Loss: 2.095984935760498 Accuracy: 0.125\n","Loss: 2.078901767730713 Accuracy: 0.171875\n","Loss: 2.0180013179779053 Accuracy: 0.28125\n","Loss: 1.9508177042007446 Accuracy: 0.28125\n","Loss: 2.111248731613159 Accuracy: 0.203125\n","Loss: 1.7982816696166992 Accuracy: 0.421875\n","Loss: 2.0077757835388184 Accuracy: 0.171875\n","Loss: 2.0315799713134766 Accuracy: 0.203125\n","Loss: 2.110353946685791 Accuracy: 0.125\n","Loss: 2.0072779655456543 Accuracy: 0.21875\n","Loss: 1.9788007736206055 Accuracy: 0.1875\n","Loss: 2.075653314590454 Accuracy: 0.25\n","Loss: 2.025233745574951 Accuracy: 0.15625\n","Loss: 1.974335789680481 Accuracy: 0.265625\n","Loss: 2.0334460735321045 Accuracy: 0.21875\n","Loss: 1.9790960550308228 Accuracy: 0.21875\n","Loss: 1.8678323030471802 Accuracy: 0.296875\n","Loss: 2.1153910160064697 Accuracy: 0.171875\n","Loss: 2.123882532119751 Accuracy: 0.203125\n","Loss: 2.0413758754730225 Accuracy: 0.21875\n","Loss: 1.9744577407836914 Accuracy: 0.296875\n","Loss: 1.977393388748169 Accuracy: 0.203125\n","Loss: 2.036864757537842 Accuracy: 0.1875\n","Loss: 1.956102728843689 Accuracy: 0.21875\n","Loss: 1.9285523891448975 Accuracy: 0.3125\n","Loss: 1.8868649005889893 Accuracy: 0.265625\n","Loss: 1.9343398809432983 Accuracy: 0.28125\n","Loss: 1.9662518501281738 Accuracy: 0.1875\n","Loss: 1.9611232280731201 Accuracy: 0.296875\n","Loss: 2.0051398277282715 Accuracy: 0.28125\n","Loss: 1.970472812652588 Accuracy: 0.25\n","Loss: 2.0653908252716064 Accuracy: 0.171875\n","Loss: 1.9773143529891968 Accuracy: 0.25\n","Loss: 1.9165250062942505 Accuracy: 0.296875\n","Loss: 1.9802684783935547 Accuracy: 0.203125\n","Loss: 2.111881732940674 Accuracy: 0.125\n","Loss: 1.9928975105285645 Accuracy: 0.25\n","Loss: 2.008431911468506 Accuracy: 0.21875\n","Loss: 2.029041051864624 Accuracy: 0.203125\n","Loss: 2.0204644203186035 Accuracy: 0.1875\n","Loss: 1.9336140155792236 Accuracy: 0.328125\n","Loss: 1.8702912330627441 Accuracy: 0.265625\n","Loss: 1.9092289209365845 Accuracy: 0.296875\n","Loss: 1.9490429162979126 Accuracy: 0.296875\n","Loss: 2.0006513595581055 Accuracy: 0.1875\n","Loss: 1.974237322807312 Accuracy: 0.203125\n","Loss: 2.0464694499969482 Accuracy: 0.234375\n","Loss: 2.05195951461792 Accuracy: 0.21875\n","Loss: 2.0289244651794434 Accuracy: 0.203125\n","Loss: 1.9510678052902222 Accuracy: 0.25\n","Loss: 2.0150554180145264 Accuracy: 0.25\n","Loss: 2.1573703289031982 Accuracy: 0.1875\n","Loss: 1.9149550199508667 Accuracy: 0.296875\n","Loss: 1.9726136922836304 Accuracy: 0.21875\n","Loss: 1.8873810768127441 Accuracy: 0.28125\n","Loss: 2.1057045459747314 Accuracy: 0.125\n","Loss: 2.021233320236206 Accuracy: 0.1875\n","Loss: 2.0910375118255615 Accuracy: 0.1875\n","Loss: 2.043025016784668 Accuracy: 0.265625\n","Loss: 1.9394932985305786 Accuracy: 0.203125\n","Loss: 2.0975446701049805 Accuracy: 0.171875\n","Loss: 1.8907394409179688 Accuracy: 0.28125\n","Loss: 2.161696195602417 Accuracy: 0.09375\n","Loss: 2.071385383605957 Accuracy: 0.140625\n","Loss: 2.0182509422302246 Accuracy: 0.28125\n","Loss: 1.879577875137329 Accuracy: 0.28125\n","Loss: 2.1640729904174805 Accuracy: 0.234375\n","Loss: 1.97479248046875 Accuracy: 0.296875\n","Loss: 1.9688302278518677 Accuracy: 0.203125\n","Loss: 1.9624125957489014 Accuracy: 0.3125\n","Loss: 1.9858812093734741 Accuracy: 0.25\n","Loss: 2.057178497314453 Accuracy: 0.234375\n","Loss: 1.8667423725128174 Accuracy: 0.234375\n","Loss: 2.027829647064209 Accuracy: 0.203125\n","Loss: 2.082826614379883 Accuracy: 0.21875\n","Loss: 1.9547616243362427 Accuracy: 0.21875\n","Loss: 1.9454432725906372 Accuracy: 0.21875\n","Loss: 1.8447990417480469 Accuracy: 0.375\n","Loss: 2.1474430561065674 Accuracy: 0.171875\n","Loss: 1.8870786428451538 Accuracy: 0.25\n","Loss: 1.9816676378250122 Accuracy: 0.1875\n","Loss: 1.9083919525146484 Accuracy: 0.40625\n","Loss: 1.9778410196304321 Accuracy: 0.203125\n","Loss: 1.92887282371521 Accuracy: 0.203125\n","Loss: 1.9828673601150513 Accuracy: 0.234375\n","Loss: 1.9367402791976929 Accuracy: 0.25\n","Loss: 1.7886707782745361 Accuracy: 0.296875\n","Loss: 2.025752305984497 Accuracy: 0.1875\n","Loss: 1.9852681159973145 Accuracy: 0.234375\n","Loss: 1.9763638973236084 Accuracy: 0.25\n","Loss: 2.0304794311523438 Accuracy: 0.25\n","Loss: 1.9729769229888916 Accuracy: 0.375\n","Loss: 1.9741599559783936 Accuracy: 0.234375\n","Loss: 1.9090576171875 Accuracy: 0.265625\n","Loss: 2.013090133666992 Accuracy: 0.203125\n","Loss: 1.9158270359039307 Accuracy: 0.234375\n","Loss: 2.1224546432495117 Accuracy: 0.28125\n","Loss: 1.9781371355056763 Accuracy: 0.265625\n","Loss: 1.978490948677063 Accuracy: 0.265625\n","Loss: 2.058948278427124 Accuracy: 0.234375\n","Loss: 1.9962339401245117 Accuracy: 0.21875\n","Loss: 2.0519895553588867 Accuracy: 0.203125\n","Loss: 1.8773877620697021 Accuracy: 0.3125\n","Loss: 2.005978584289551 Accuracy: 0.1875\n","Loss: 1.952345609664917 Accuracy: 0.265625\n","Loss: 1.8361462354660034 Accuracy: 0.25\n","Loss: 1.8867897987365723 Accuracy: 0.25\n","Loss: 2.0006158351898193 Accuracy: 0.203125\n","Loss: 1.9833422899246216 Accuracy: 0.25\n","Loss: 2.00958251953125 Accuracy: 0.21875\n","Loss: 1.880017876625061 Accuracy: 0.3125\n","Loss: 2.068007469177246 Accuracy: 0.234375\n","Loss: 1.9906666278839111 Accuracy: 0.28125\n","Loss: 1.873220682144165 Accuracy: 0.25\n","Loss: 2.048802614212036 Accuracy: 0.25\n","Loss: 2.0158166885375977 Accuracy: 0.421875\n","Loss: 1.9287028312683105 Accuracy: 0.25\n","Loss: 1.9387762546539307 Accuracy: 0.3125\n","Loss: 2.0864639282226562 Accuracy: 0.15625\n","Loss: 2.021069049835205 Accuracy: 0.171875\n","Loss: 1.952595829963684 Accuracy: 0.234375\n","Loss: 2.0595126152038574 Accuracy: 0.15625\n","Loss: 1.9307628870010376 Accuracy: 0.296875\n","Loss: 2.0139288902282715 Accuracy: 0.25\n","Loss: 2.201603889465332 Accuracy: 0.140625\n","Loss: 2.1295759677886963 Accuracy: 0.171875\n","Loss: 1.9027009010314941 Accuracy: 0.234375\n","Loss: 1.967263102531433 Accuracy: 0.21875\n","Loss: 2.020965337753296 Accuracy: 0.28125\n","Loss: 2.0538454055786133 Accuracy: 0.296875\n","Loss: 1.9793038368225098 Accuracy: 0.1875\n","Loss: 1.9358774423599243 Accuracy: 0.28125\n","Loss: 1.947629690170288 Accuracy: 0.28125\n","Loss: 2.003624439239502 Accuracy: 0.203125\n","Loss: 1.9479472637176514 Accuracy: 0.25\n","Loss: 2.1039962768554688 Accuracy: 0.171875\n","Loss: 2.002690315246582 Accuracy: 0.171875\n","Loss: 1.9377120733261108 Accuracy: 0.296875\n","Loss: 2.0619492530822754 Accuracy: 0.1875\n","Loss: 2.0060842037200928 Accuracy: 0.203125\n","Loss: 1.959031581878662 Accuracy: 0.21875\n","Loss: 2.0360119342803955 Accuracy: 0.203125\n","Loss: 1.9022831916809082 Accuracy: 0.265625\n","Loss: 1.9259871244430542 Accuracy: 0.234375\n","Loss: 1.9550567865371704 Accuracy: 0.328125\n","Loss: 1.966664433479309 Accuracy: 0.234375\n","Loss: 1.9922385215759277 Accuracy: 0.265625\n","Loss: 1.9917055368423462 Accuracy: 0.21875\n","Loss: 2.0852553844451904 Accuracy: 0.25\n","Loss: 2.0146334171295166 Accuracy: 0.265625\n","Loss: 1.854291558265686 Accuracy: 0.3125\n","Loss: 1.9623268842697144 Accuracy: 0.265625\n","Loss: 1.9739429950714111 Accuracy: 0.265625\n","Loss: 2.0354199409484863 Accuracy: 0.109375\n","Loss: 2.0173120498657227 Accuracy: 0.234375\n","Loss: 2.031470537185669 Accuracy: 0.234375\n","Loss: 2.0226850509643555 Accuracy: 0.203125\n","Loss: 1.952775001525879 Accuracy: 0.234375\n","Loss: 1.9544501304626465 Accuracy: 0.1875\n","Loss: 1.9617642164230347 Accuracy: 0.203125\n","Loss: 1.9112327098846436 Accuracy: 0.28125\n","Loss: 1.9430654048919678 Accuracy: 0.234375\n","Loss: 1.928127408027649 Accuracy: 0.28125\n","Loss: 2.010789394378662 Accuracy: 0.234375\n","Loss: 1.9483566284179688 Accuracy: 0.203125\n","Loss: 1.9435195922851562 Accuracy: 0.203125\n","Loss: 1.927286148071289 Accuracy: 0.21875\n","Loss: 2.1168129444122314 Accuracy: 0.234375\n","Loss: 1.9860968589782715 Accuracy: 0.21875\n","Loss: 2.020686626434326 Accuracy: 0.203125\n","Loss: 1.997367262840271 Accuracy: 0.265625\n","Loss: 2.08803653717041 Accuracy: 0.203125\n","Loss: 1.9592150449752808 Accuracy: 0.296875\n","Loss: 2.0000994205474854 Accuracy: 0.171875\n","Loss: 1.914554238319397 Accuracy: 0.203125\n","Loss: 2.0479328632354736 Accuracy: 0.21875\n","Loss: 1.9523611068725586 Accuracy: 0.234375\n","Loss: 1.8928052186965942 Accuracy: 0.265625\n","Loss: 2.042973756790161 Accuracy: 0.171875\n","Loss: 1.9125545024871826 Accuracy: 0.3125\n","Loss: 2.039809465408325 Accuracy: 0.296875\n","Loss: 2.0263333320617676 Accuracy: 0.21875\n","Loss: 2.0636682510375977 Accuracy: 0.21875\n","Loss: 2.0652847290039062 Accuracy: 0.234375\n","Loss: 2.0600361824035645 Accuracy: 0.1875\n","Loss: 1.9480204582214355 Accuracy: 0.265625\n","Loss: 1.9353364706039429 Accuracy: 0.234375\n","Loss: 1.952794075012207 Accuracy: 0.265625\n","Loss: 1.919227123260498 Accuracy: 0.265625\n","Loss: 2.0380876064300537 Accuracy: 0.328125\n","Loss: 1.9713598489761353 Accuracy: 0.21875\n","Loss: 1.8584766387939453 Accuracy: 0.3125\n","Loss: 2.0054495334625244 Accuracy: 0.15625\n","Loss: 1.9628188610076904 Accuracy: 0.234375\n","Loss: 1.8614778518676758 Accuracy: 0.3125\n","Loss: 1.9838143587112427 Accuracy: 0.234375\n","Loss: 2.0511510372161865 Accuracy: 0.234375\n","Loss: 1.841019630432129 Accuracy: 0.296875\n","Loss: 2.099586248397827 Accuracy: 0.09375\n","Loss: 1.866269826889038 Accuracy: 0.3125\n","Loss: 1.992049217224121 Accuracy: 0.265625\n","Loss: 2.0864033699035645 Accuracy: 0.21875\n","Loss: 1.9871748685836792 Accuracy: 0.28125\n","Loss: 1.9583464860916138 Accuracy: 0.203125\n","Loss: 1.8587816953659058 Accuracy: 0.328125\n","Loss: 2.0908546447753906 Accuracy: 0.203125\n","Loss: 1.8622773885726929 Accuracy: 0.328125\n","Loss: 1.9728628396987915 Accuracy: 0.28125\n","Loss: 2.0585286617279053 Accuracy: 0.1875\n","Loss: 1.9859939813613892 Accuracy: 0.1875\n","Loss: 2.0594587326049805 Accuracy: 0.15625\n","Loss: 1.9890384674072266 Accuracy: 0.203125\n","Loss: 1.9484118223190308 Accuracy: 0.296875\n","Loss: 2.0408527851104736 Accuracy: 0.265625\n","Loss: 2.0115697383880615 Accuracy: 0.203125\n","Loss: 1.988228440284729 Accuracy: 0.296875\n","Loss: 1.9943089485168457 Accuracy: 0.1875\n","Loss: 2.019761323928833 Accuracy: 0.1875\n","Loss: 1.9895685911178589 Accuracy: 0.234375\n","Loss: 1.9620463848114014 Accuracy: 0.25\n","Loss: 2.0875117778778076 Accuracy: 0.203125\n","Loss: 1.9714778661727905 Accuracy: 0.203125\n","Loss: 2.139519453048706 Accuracy: 0.203125\n","Loss: 1.9875491857528687 Accuracy: 0.234375\n","Loss: 1.8977444171905518 Accuracy: 0.25\n","Loss: 2.1011576652526855 Accuracy: 0.125\n","Loss: 2.005450963973999 Accuracy: 0.34375\n","Loss: 1.9969563484191895 Accuracy: 0.203125\n","Loss: 1.9253495931625366 Accuracy: 0.1875\n","Loss: 1.9085135459899902 Accuracy: 0.3125\n","Loss: 1.9464707374572754 Accuracy: 0.15625\n","Loss: 1.7298228740692139 Accuracy: 0.40625\n","Loss: 1.977492094039917 Accuracy: 0.28125\n","Loss: 2.013247489929199 Accuracy: 0.234375\n","Loss: 2.0245473384857178 Accuracy: 0.203125\n","Loss: 1.9716966152191162 Accuracy: 0.25\n","Loss: 2.081533193588257 Accuracy: 0.171875\n","Loss: 1.9034212827682495 Accuracy: 0.234375\n","Loss: 2.1185507774353027 Accuracy: 0.140625\n","Loss: 2.0248665809631348 Accuracy: 0.21875\n","Loss: 1.900112509727478 Accuracy: 0.28125\n","Loss: 1.9152719974517822 Accuracy: 0.28125\n","Loss: 1.9291491508483887 Accuracy: 0.28125\n","Loss: 2.023465871810913 Accuracy: 0.203125\n","Loss: 1.888692855834961 Accuracy: 0.21875\n","Loss: 1.867202639579773 Accuracy: 0.359375\n","Loss: 1.8671880960464478 Accuracy: 0.34375\n","Loss: 2.0645718574523926 Accuracy: 0.203125\n","Loss: 1.8236069679260254 Accuracy: 0.265625\n","Loss: 2.160287857055664 Accuracy: 0.1875\n","Loss: 1.9800769090652466 Accuracy: 0.28125\n","Loss: 2.0826218128204346 Accuracy: 0.203125\n","Loss: 2.0915307998657227 Accuracy: 0.265625\n","Loss: 2.064640522003174 Accuracy: 0.140625\n","Loss: 1.9578973054885864 Accuracy: 0.328125\n","Loss: 1.8186156749725342 Accuracy: 0.296875\n","Loss: 2.072533130645752 Accuracy: 0.09375\n","Loss: 2.0381009578704834 Accuracy: 0.234375\n","Loss: 1.9554036855697632 Accuracy: 0.234375\n","Loss: 1.98814857006073 Accuracy: 0.203125\n","Loss: 1.994019627571106 Accuracy: 0.28125\n","Loss: 1.9264074563980103 Accuracy: 0.25\n","Loss: 1.8758766651153564 Accuracy: 0.3125\n","Loss: 1.988100528717041 Accuracy: 0.25\n","Loss: 2.0016818046569824 Accuracy: 0.1875\n","Loss: 1.97887122631073 Accuracy: 0.28125\n","Loss: 1.9626983404159546 Accuracy: 0.25\n","Loss: 1.9021626710891724 Accuracy: 0.296875\n","Loss: 1.9133808612823486 Accuracy: 0.328125\n","Loss: 1.9260973930358887 Accuracy: 0.265625\n","Loss: 1.833679437637329 Accuracy: 0.390625\n","Loss: 1.9539859294891357 Accuracy: 0.28125\n","Loss: 1.9355416297912598 Accuracy: 0.28125\n","Loss: 1.8178497552871704 Accuracy: 0.3125\n","Loss: 2.09037446975708 Accuracy: 0.140625\n","Loss: 1.975156545639038 Accuracy: 0.21875\n","Loss: 1.9819599390029907 Accuracy: 0.3125\n","Loss: 1.9733679294586182 Accuracy: 0.234375\n","Loss: 1.804137945175171 Accuracy: 0.296875\n","Loss: 1.9348137378692627 Accuracy: 0.25\n","Loss: 1.8957138061523438 Accuracy: 0.28125\n","Loss: 2.014873743057251 Accuracy: 0.171875\n","Loss: 1.9960267543792725 Accuracy: 0.15625\n","Loss: 1.9376095533370972 Accuracy: 0.3125\n","Loss: 2.0087456703186035 Accuracy: 0.234375\n","Loss: 1.9187490940093994 Accuracy: 0.25\n","Loss: 1.9566901922225952 Accuracy: 0.25\n","Loss: 1.9609394073486328 Accuracy: 0.265625\n","Loss: 1.8188230991363525 Accuracy: 0.34375\n","Loss: 1.8181709051132202 Accuracy: 0.3125\n","Loss: 1.8961076736450195 Accuracy: 0.265625\n","Loss: 1.9737443923950195 Accuracy: 0.234375\n","Loss: 2.0149970054626465 Accuracy: 0.171875\n","Loss: 2.169738292694092 Accuracy: 0.15625\n","Loss: 1.9958912134170532 Accuracy: 0.28125\n","Loss: 2.0221567153930664 Accuracy: 0.203125\n","Loss: 1.9479963779449463 Accuracy: 0.1875\n","Loss: 1.847456455230713 Accuracy: 0.265625\n","Loss: 1.919147253036499 Accuracy: 0.25\n","Loss: 1.9305189847946167 Accuracy: 0.375\n","Loss: 2.0782158374786377 Accuracy: 0.296875\n","Loss: 1.956318974494934 Accuracy: 0.28125\n","Loss: 2.02374005317688 Accuracy: 0.203125\n","Loss: 2.009622573852539 Accuracy: 0.234375\n","Loss: 1.9020349979400635 Accuracy: 0.296875\n","Loss: 2.015381097793579 Accuracy: 0.234375\n","Loss: 2.041769504547119 Accuracy: 0.21875\n","Loss: 1.93898606300354 Accuracy: 0.1875\n","Loss: 1.9512759447097778 Accuracy: 0.171875\n","Loss: 1.8552687168121338 Accuracy: 0.328125\n","Loss: 1.943144679069519 Accuracy: 0.265625\n","Loss: 2.0495822429656982 Accuracy: 0.21875\n","Loss: 1.9844348430633545 Accuracy: 0.1875\n","Loss: 1.7264444828033447 Accuracy: 0.40625\n","Loss: 1.9703869819641113 Accuracy: 0.234375\n","Loss: 1.9958170652389526 Accuracy: 0.21875\n","Loss: 1.8463311195373535 Accuracy: 0.34375\n","Loss: 1.9237604141235352 Accuracy: 0.359375\n","Loss: 1.9510562419891357 Accuracy: 0.3125\n","Loss: 2.03694486618042 Accuracy: 0.1875\n","Loss: 1.9547773599624634 Accuracy: 0.28125\n","Loss: 2.017777681350708 Accuracy: 0.203125\n","Loss: 2.082213878631592 Accuracy: 0.265625\n","Loss: 1.9447516202926636 Accuracy: 0.25\n","Loss: 1.9719949960708618 Accuracy: 0.34375\n","Loss: 2.0436644554138184 Accuracy: 0.1875\n","Loss: 2.1182827949523926 Accuracy: 0.15625\n","Loss: 1.982134222984314 Accuracy: 0.1875\n","Loss: 2.0130882263183594 Accuracy: 0.1875\n","Loss: 2.081616163253784 Accuracy: 0.265625\n","Loss: 2.0148415565490723 Accuracy: 0.21875\n","Loss: 1.994404673576355 Accuracy: 0.265625\n","Loss: 2.0017189979553223 Accuracy: 0.3125\n","Loss: 2.0938987731933594 Accuracy: 0.25\n","Loss: 1.7752450704574585 Accuracy: 0.3125\n","Loss: 1.8249061107635498 Accuracy: 0.25\n","Loss: 1.9148703813552856 Accuracy: 0.328125\n","Loss: 1.9017200469970703 Accuracy: 0.21875\n","Loss: 1.9079666137695312 Accuracy: 0.25\n","Loss: 1.9204249382019043 Accuracy: 0.25\n","Loss: 1.994201421737671 Accuracy: 0.203125\n","Loss: 1.7527906894683838 Accuracy: 0.296875\n","Loss: 2.1262950897216797 Accuracy: 0.234375\n","Loss: 1.990841269493103 Accuracy: 0.265625\n","Loss: 1.896951675415039 Accuracy: 0.265625\n","Loss: 1.9555003643035889 Accuracy: 0.25\n","Loss: 2.089883327484131 Accuracy: 0.125\n","Loss: 2.028245210647583 Accuracy: 0.21875\n","Loss: 1.9085522890090942 Accuracy: 0.25\n","Loss: 2.034837007522583 Accuracy: 0.3125\n","Loss: 1.8540321588516235 Accuracy: 0.28125\n","Loss: 1.8486106395721436 Accuracy: 0.375\n","Loss: 1.9046906232833862 Accuracy: 0.296875\n","Loss: 1.7894554138183594 Accuracy: 0.265625\n","Loss: 1.8444793224334717 Accuracy: 0.328125\n","Loss: 2.0539257526397705 Accuracy: 0.265625\n","Loss: 2.0531392097473145 Accuracy: 0.265625\n","Loss: 1.9669601917266846 Accuracy: 0.25\n","Loss: 2.060098648071289 Accuracy: 0.171875\n","Loss: 1.8318679332733154 Accuracy: 0.328125\n","Loss: 2.0467913150787354 Accuracy: 0.1875\n","Loss: 1.9335330724716187 Accuracy: 0.234375\n","Loss: 2.001422166824341 Accuracy: 0.21875\n","Loss: 1.9267977476119995 Accuracy: 0.28125\n","Loss: 1.8084596395492554 Accuracy: 0.296875\n","Loss: 2.223115921020508 Accuracy: 0.109375\n","Loss: 2.074557304382324 Accuracy: 0.1875\n","Loss: 2.0160293579101562 Accuracy: 0.21875\n","Loss: 1.9797786474227905 Accuracy: 0.34375\n","Loss: 1.9747639894485474 Accuracy: 0.296875\n","Loss: 1.9484113454818726 Accuracy: 0.265625\n","Loss: 2.0302915573120117 Accuracy: 0.1875\n","Loss: 1.9090169668197632 Accuracy: 0.25\n","Loss: 1.9401180744171143 Accuracy: 0.265625\n","Loss: 2.008709669113159 Accuracy: 0.21875\n","Loss: 1.9612787961959839 Accuracy: 0.234375\n","Loss: 2.0079903602600098 Accuracy: 0.21875\n","Loss: 1.8490058183670044 Accuracy: 0.25\n","Loss: 2.1152334213256836 Accuracy: 0.125\n","Loss: 1.8772627115249634 Accuracy: 0.359375\n","Loss: 1.9746129512786865 Accuracy: 0.25\n","Loss: 1.9609127044677734 Accuracy: 0.25\n","Loss: 1.8824336528778076 Accuracy: 0.28125\n","Loss: 2.0312840938568115 Accuracy: 0.25\n","Loss: 2.033567428588867 Accuracy: 0.28125\n","Loss: 1.9435607194900513 Accuracy: 0.21875\n","Loss: 1.9225375652313232 Accuracy: 0.25\n","Loss: 1.9090372323989868 Accuracy: 0.296875\n","Loss: 2.0139787197113037 Accuracy: 0.234375\n","Loss: 1.8065283298492432 Accuracy: 0.28125\n","Loss: 2.1023523807525635 Accuracy: 0.171875\n","Loss: 2.036123514175415 Accuracy: 0.265625\n","Loss: 1.7425698041915894 Accuracy: 0.3125\n","Loss: 1.882858395576477 Accuracy: 0.28125\n","Loss: 1.9246612787246704 Accuracy: 0.359375\n","Loss: 1.9832078218460083 Accuracy: 0.328125\n","Loss: 1.946045994758606 Accuracy: 0.265625\n","Loss: 1.9521677494049072 Accuracy: 0.265625\n","Loss: 2.009340763092041 Accuracy: 0.21875\n","Loss: 2.104341506958008 Accuracy: 0.171875\n","Loss: 1.9919809103012085 Accuracy: 0.1875\n","Loss: 2.040482759475708 Accuracy: 0.1875\n","Loss: 1.9152779579162598 Accuracy: 0.234375\n","Loss: 1.9260482788085938 Accuracy: 0.21875\n","Loss: 1.8060235977172852 Accuracy: 0.328125\n","Loss: 2.0750503540039062 Accuracy: 0.125\n","Loss: 1.8639280796051025 Accuracy: 0.234375\n","Loss: 1.8807302713394165 Accuracy: 0.265625\n","Loss: 1.957237720489502 Accuracy: 0.25\n","Loss: 2.028247117996216 Accuracy: 0.1875\n","Loss: 2.156975269317627 Accuracy: 0.140625\n","Loss: 1.9315996170043945 Accuracy: 0.28125\n","Loss: 2.070878744125366 Accuracy: 0.1875\n","Loss: 1.9205025434494019 Accuracy: 0.203125\n","Loss: 2.005723237991333 Accuracy: 0.265625\n","Loss: 2.0378665924072266 Accuracy: 0.1875\n","Loss: 2.004634141921997 Accuracy: 0.265625\n","Loss: 1.940990924835205 Accuracy: 0.296875\n","Loss: 1.8636075258255005 Accuracy: 0.25\n","Loss: 1.9519480466842651 Accuracy: 0.1875\n","Loss: 1.8890455961227417 Accuracy: 0.234375\n","Loss: 1.9490036964416504 Accuracy: 0.265625\n","Loss: 2.1157169342041016 Accuracy: 0.15625\n","Loss: 2.0268452167510986 Accuracy: 0.140625\n","Loss: 1.9993066787719727 Accuracy: 0.21875\n","Loss: 1.8619475364685059 Accuracy: 0.296875\n","Loss: 1.7871172428131104 Accuracy: 0.359375\n","Loss: 1.9594945907592773 Accuracy: 0.21875\n","Loss: 1.802351713180542 Accuracy: 0.4375\n","Loss: 1.9854646921157837 Accuracy: 0.328125\n","Loss: 2.037113666534424 Accuracy: 0.21875\n","Loss: 1.9897693395614624 Accuracy: 0.28125\n","Loss: 1.90549635887146 Accuracy: 0.25\n","Loss: 1.9563682079315186 Accuracy: 0.1875\n","Loss: 1.993090033531189 Accuracy: 0.1875\n","Loss: 1.9099435806274414 Accuracy: 0.34375\n","Loss: 1.8099888563156128 Accuracy: 0.28125\n","Loss: 1.9485803842544556 Accuracy: 0.234375\n","Loss: 2.069209337234497 Accuracy: 0.234375\n","Loss: 2.031668186187744 Accuracy: 0.265625\n","Loss: 1.9637839794158936 Accuracy: 0.203125\n","Loss: 1.9718419313430786 Accuracy: 0.3125\n","Loss: 1.8516775369644165 Accuracy: 0.28125\n","Loss: 1.9111632108688354 Accuracy: 0.203125\n","Loss: 1.8322936296463013 Accuracy: 0.390625\n","Loss: 2.0126845836639404 Accuracy: 0.1875\n","Loss: 2.068845748901367 Accuracy: 0.171875\n","Loss: 1.9683592319488525 Accuracy: 0.171875\n","Loss: 2.131143093109131 Accuracy: 0.140625\n","Loss: 1.9843056201934814 Accuracy: 0.328125\n","Loss: 1.9131985902786255 Accuracy: 0.296875\n","Loss: 1.8563477993011475 Accuracy: 0.328125\n","Loss: 1.8783323764801025 Accuracy: 0.25\n","Loss: 1.7411075830459595 Accuracy: 0.375\n","Loss: 1.945997953414917 Accuracy: 0.203125\n","Loss: 1.86409592628479 Accuracy: 0.265625\n","Loss: 1.9896584749221802 Accuracy: 0.265625\n","Loss: 1.9109333753585815 Accuracy: 0.265625\n","Loss: 1.9934808015823364 Accuracy: 0.203125\n","Loss: 1.9086837768554688 Accuracy: 0.28125\n","Loss: 1.9422942399978638 Accuracy: 0.265625\n","Loss: 1.9728589057922363 Accuracy: 0.296875\n","Loss: 1.9959895610809326 Accuracy: 0.140625\n","Loss: 1.9290146827697754 Accuracy: 0.21875\n","Loss: 1.9431523084640503 Accuracy: 0.15625\n","Loss: 1.9881330728530884 Accuracy: 0.21875\n","Loss: 1.9823790788650513 Accuracy: 0.25\n","Loss: 1.9668736457824707 Accuracy: 0.203125\n","Loss: 1.9126652479171753 Accuracy: 0.1875\n","Loss: 1.9203801155090332 Accuracy: 0.34375\n","Loss: 1.848686695098877 Accuracy: 0.359375\n","Loss: 1.9709917306900024 Accuracy: 0.203125\n","Loss: 1.8858058452606201 Accuracy: 0.28125\n","Loss: 1.9354701042175293 Accuracy: 0.296875\n","Loss: 1.9526042938232422 Accuracy: 0.28125\n","Loss: 1.8887935876846313 Accuracy: 0.296875\n","Loss: 2.0379250049591064 Accuracy: 0.171875\n","Loss: 1.7578823566436768 Accuracy: 0.34375\n","Loss: 1.9851607084274292 Accuracy: 0.265625\n","Loss: 2.0551023483276367 Accuracy: 0.1875\n","Loss: 1.933021068572998 Accuracy: 0.234375\n","Loss: 1.8654584884643555 Accuracy: 0.296875\n","Loss: 1.8824577331542969 Accuracy: 0.328125\n","Loss: 1.767209529876709 Accuracy: 0.34375\n","Loss: 1.8438587188720703 Accuracy: 0.296875\n","Loss: 1.8287022113800049 Accuracy: 0.328125\n","Loss: 1.9637821912765503 Accuracy: 0.265625\n","Loss: 1.9440971612930298 Accuracy: 0.28125\n","Loss: 1.7806636095046997 Accuracy: 0.265625\n","Loss: 1.977673053741455 Accuracy: 0.203125\n","Loss: 1.9763108491897583 Accuracy: 0.25\n","Loss: 1.8996211290359497 Accuracy: 0.25\n","Loss: 1.866291880607605 Accuracy: 0.25\n","Loss: 1.9348868131637573 Accuracy: 0.265625\n","Loss: 1.8247199058532715 Accuracy: 0.265625\n","Loss: 1.9635493755340576 Accuracy: 0.28125\n","Loss: 1.8858164548873901 Accuracy: 0.328125\n","Loss: 1.8285881280899048 Accuracy: 0.3125\n","Loss: 1.9552546739578247 Accuracy: 0.234375\n","Loss: 1.997111201286316 Accuracy: 0.203125\n","Loss: 2.041154623031616 Accuracy: 0.140625\n","Loss: 2.011624813079834 Accuracy: 0.21875\n","Loss: 1.8227548599243164 Accuracy: 0.328125\n","Loss: 1.9688429832458496 Accuracy: 0.25\n","Loss: 1.8706133365631104 Accuracy: 0.3125\n","Loss: 1.916690468788147 Accuracy: 0.3125\n","Loss: 1.9345364570617676 Accuracy: 0.21875\n","Loss: 2.003509283065796 Accuracy: 0.203125\n","Loss: 1.903087854385376 Accuracy: 0.203125\n","Loss: 1.949580430984497 Accuracy: 0.1875\n","Loss: 1.9392006397247314 Accuracy: 0.21875\n","Loss: 1.9238054752349854 Accuracy: 0.265625\n","Loss: 1.9746744632720947 Accuracy: 0.265625\n","Loss: 1.8318161964416504 Accuracy: 0.375\n","Loss: 1.9161888360977173 Accuracy: 0.203125\n","Loss: 1.9552513360977173 Accuracy: 0.234375\n","Loss: 2.103471040725708 Accuracy: 0.203125\n","Loss: 1.9334018230438232 Accuracy: 0.234375\n","Loss: 1.8428598642349243 Accuracy: 0.296875\n","Loss: 1.9009084701538086 Accuracy: 0.234375\n","Loss: 2.0511715412139893 Accuracy: 0.203125\n","Loss: 1.862522840499878 Accuracy: 0.25\n","Loss: 1.8709207773208618 Accuracy: 0.25\n","Loss: 1.9040135145187378 Accuracy: 0.28125\n","Loss: 2.008883237838745 Accuracy: 0.21875\n","Epoch: 1\n","Loss: 1.839707612991333 Accuracy: 0.34375\n","Loss: 1.9329599142074585 Accuracy: 0.28125\n","Loss: 1.9248476028442383 Accuracy: 0.328125\n","Loss: 1.846929669380188 Accuracy: 0.296875\n","Loss: 1.9862653017044067 Accuracy: 0.25\n","Loss: 1.9963253736495972 Accuracy: 0.25\n","Loss: 2.012782096862793 Accuracy: 0.234375\n","Loss: 1.9469293355941772 Accuracy: 0.296875\n","Loss: 1.8730946779251099 Accuracy: 0.359375\n","Loss: 1.9396209716796875 Accuracy: 0.296875\n","Loss: 1.78074049949646 Accuracy: 0.375\n","Loss: 2.0476672649383545 Accuracy: 0.234375\n","Loss: 1.9948583841323853 Accuracy: 0.203125\n","Loss: 1.9450236558914185 Accuracy: 0.265625\n","Loss: 1.8227365016937256 Accuracy: 0.3125\n","Loss: 1.9765959978103638 Accuracy: 0.28125\n","Loss: 1.9303319454193115 Accuracy: 0.21875\n","Loss: 1.9236831665039062 Accuracy: 0.296875\n","Loss: 1.8443799018859863 Accuracy: 0.25\n","Loss: 1.869389295578003 Accuracy: 0.21875\n","Loss: 1.8259364366531372 Accuracy: 0.3125\n","Loss: 1.9954545497894287 Accuracy: 0.234375\n","Loss: 2.010319948196411 Accuracy: 0.1875\n","Loss: 1.9071648120880127 Accuracy: 0.265625\n","Loss: 1.979358434677124 Accuracy: 0.265625\n","Loss: 1.906915545463562 Accuracy: 0.25\n","Loss: 2.0568952560424805 Accuracy: 0.21875\n","Loss: 1.834575891494751 Accuracy: 0.28125\n","Loss: 1.8358196020126343 Accuracy: 0.265625\n","Loss: 1.9480626583099365 Accuracy: 0.359375\n","Loss: 1.9342628717422485 Accuracy: 0.234375\n","Loss: 1.8346468210220337 Accuracy: 0.28125\n","Loss: 1.9348924160003662 Accuracy: 0.25\n","Loss: 1.987423062324524 Accuracy: 0.265625\n","Loss: 1.8803035020828247 Accuracy: 0.25\n","Loss: 1.9076076745986938 Accuracy: 0.296875\n","Loss: 1.9263023138046265 Accuracy: 0.328125\n","Loss: 1.8633819818496704 Accuracy: 0.265625\n","Loss: 2.024559259414673 Accuracy: 0.234375\n","Loss: 2.030289649963379 Accuracy: 0.140625\n","Loss: 1.9629607200622559 Accuracy: 0.28125\n","Loss: 1.8394005298614502 Accuracy: 0.28125\n","Loss: 1.993152141571045 Accuracy: 0.234375\n","Loss: 1.837896466255188 Accuracy: 0.40625\n","Loss: 2.1354260444641113 Accuracy: 0.203125\n","Loss: 1.9169584512710571 Accuracy: 0.1875\n","Loss: 1.7625221014022827 Accuracy: 0.328125\n","Loss: 2.0063273906707764 Accuracy: 0.234375\n","Loss: 1.8831995725631714 Accuracy: 0.375\n","Loss: 1.9948450326919556 Accuracy: 0.203125\n","Loss: 1.9269866943359375 Accuracy: 0.25\n","Loss: 1.8713784217834473 Accuracy: 0.265625\n","Loss: 1.8805031776428223 Accuracy: 0.28125\n","Loss: 1.9156901836395264 Accuracy: 0.3125\n","Loss: 1.8689308166503906 Accuracy: 0.25\n","Loss: 1.7724945545196533 Accuracy: 0.328125\n","Loss: 2.0049378871917725 Accuracy: 0.25\n","Loss: 1.8710334300994873 Accuracy: 0.28125\n","Loss: 2.101390838623047 Accuracy: 0.234375\n","Loss: 1.9726097583770752 Accuracy: 0.203125\n","Loss: 1.9124675989151 Accuracy: 0.234375\n","Loss: 1.9896371364593506 Accuracy: 0.25\n","Loss: 1.9651826620101929 Accuracy: 0.28125\n","Loss: 2.0330629348754883 Accuracy: 0.25\n","Loss: 1.8709619045257568 Accuracy: 0.265625\n","Loss: 1.9223097562789917 Accuracy: 0.296875\n","Loss: 1.9379767179489136 Accuracy: 0.25\n","Loss: 1.9418612718582153 Accuracy: 0.234375\n","Loss: 1.8742622137069702 Accuracy: 0.25\n","Loss: 1.8734008073806763 Accuracy: 0.28125\n","Loss: 1.8592145442962646 Accuracy: 0.3125\n","Loss: 1.995536208152771 Accuracy: 0.265625\n","Loss: 1.782914400100708 Accuracy: 0.25\n","Loss: 1.994996190071106 Accuracy: 0.203125\n","Loss: 1.9176421165466309 Accuracy: 0.265625\n","Loss: 1.8414320945739746 Accuracy: 0.28125\n","Loss: 2.1252803802490234 Accuracy: 0.171875\n","Loss: 2.0112063884735107 Accuracy: 0.171875\n","Loss: 2.002061367034912 Accuracy: 0.265625\n","Loss: 1.8781709671020508 Accuracy: 0.234375\n","Loss: 2.00996994972229 Accuracy: 0.15625\n","Loss: 1.8997342586517334 Accuracy: 0.25\n","Loss: 2.0372962951660156 Accuracy: 0.21875\n","Loss: 1.7797874212265015 Accuracy: 0.25\n","Loss: 1.8155696392059326 Accuracy: 0.3125\n","Loss: 1.8641043901443481 Accuracy: 0.265625\n","Loss: 1.9797757863998413 Accuracy: 0.296875\n","Loss: 1.9572947025299072 Accuracy: 0.234375\n","Loss: 1.863561749458313 Accuracy: 0.296875\n","Loss: 1.9147312641143799 Accuracy: 0.265625\n","Loss: 2.0896124839782715 Accuracy: 0.109375\n","Loss: 1.900613784790039 Accuracy: 0.125\n","Loss: 1.8994327783584595 Accuracy: 0.296875\n","Loss: 2.0915164947509766 Accuracy: 0.125\n","Loss: 1.8359779119491577 Accuracy: 0.328125\n","Loss: 1.9449033737182617 Accuracy: 0.265625\n","Loss: 2.0271694660186768 Accuracy: 0.25\n","Loss: 1.8670390844345093 Accuracy: 0.28125\n","Loss: 1.8816492557525635 Accuracy: 0.234375\n","Loss: 1.8537112474441528 Accuracy: 0.21875\n","Loss: 2.0225822925567627 Accuracy: 0.265625\n","Loss: 1.9184889793395996 Accuracy: 0.25\n","Loss: 1.9558454751968384 Accuracy: 0.296875\n","Loss: 1.9802863597869873 Accuracy: 0.234375\n","Loss: 1.9243687391281128 Accuracy: 0.3125\n","Loss: 1.9458078145980835 Accuracy: 0.328125\n","Loss: 1.9978368282318115 Accuracy: 0.203125\n","Loss: 1.9281913042068481 Accuracy: 0.234375\n","Loss: 2.040527105331421 Accuracy: 0.3125\n","Loss: 2.0199320316314697 Accuracy: 0.171875\n","Loss: 1.934421181678772 Accuracy: 0.21875\n","Loss: 1.9137403964996338 Accuracy: 0.265625\n","Loss: 1.9388319253921509 Accuracy: 0.1875\n","Loss: 1.9239071607589722 Accuracy: 0.25\n","Loss: 1.9424693584442139 Accuracy: 0.28125\n","Loss: 1.932096242904663 Accuracy: 0.359375\n","Loss: 1.9168391227722168 Accuracy: 0.3125\n","Loss: 1.9984087944030762 Accuracy: 0.203125\n","Loss: 1.8006770610809326 Accuracy: 0.421875\n","Loss: 1.9729392528533936 Accuracy: 0.25\n","Loss: 1.9521818161010742 Accuracy: 0.296875\n","Loss: 1.975219488143921 Accuracy: 0.15625\n","Loss: 2.047741174697876 Accuracy: 0.203125\n","Loss: 2.144300937652588 Accuracy: 0.171875\n","Loss: 1.9181501865386963 Accuracy: 0.203125\n","Loss: 1.9615134000778198 Accuracy: 0.25\n","Loss: 2.0572428703308105 Accuracy: 0.15625\n","Loss: 1.8977755308151245 Accuracy: 0.296875\n","Loss: 1.9075177907943726 Accuracy: 0.296875\n","Loss: 1.9493919610977173 Accuracy: 0.1875\n","Loss: 1.9021251201629639 Accuracy: 0.3125\n","Loss: 2.0250566005706787 Accuracy: 0.234375\n","Loss: 1.884873390197754 Accuracy: 0.1875\n","Loss: 1.8094063997268677 Accuracy: 0.328125\n","Loss: 1.9436782598495483 Accuracy: 0.234375\n","Loss: 1.8452363014221191 Accuracy: 0.34375\n","Loss: 1.9669872522354126 Accuracy: 0.203125\n","Loss: 1.821038007736206 Accuracy: 0.28125\n","Loss: 1.8770649433135986 Accuracy: 0.25\n","Loss: 1.963333249092102 Accuracy: 0.25\n","Loss: 1.9094672203063965 Accuracy: 0.359375\n","Loss: 1.9485102891921997 Accuracy: 0.234375\n","Loss: 1.8376116752624512 Accuracy: 0.28125\n","Loss: 1.9594719409942627 Accuracy: 0.25\n","Loss: 2.0598373413085938 Accuracy: 0.1875\n","Loss: 1.783071517944336 Accuracy: 0.296875\n","Loss: 1.943120002746582 Accuracy: 0.171875\n","Loss: 2.0978991985321045 Accuracy: 0.078125\n","Loss: 1.7990213632583618 Accuracy: 0.28125\n","Loss: 1.8430920839309692 Accuracy: 0.375\n","Loss: 1.8149974346160889 Accuracy: 0.375\n","Loss: 1.8589329719543457 Accuracy: 0.28125\n","Loss: 1.934718132019043 Accuracy: 0.28125\n","Loss: 2.0054068565368652 Accuracy: 0.234375\n","Loss: 1.7584168910980225 Accuracy: 0.34375\n","Loss: 1.8932418823242188 Accuracy: 0.28125\n","Loss: 1.9737623929977417 Accuracy: 0.3125\n","Loss: 1.8392603397369385 Accuracy: 0.25\n","Loss: 2.0259206295013428 Accuracy: 0.140625\n","Loss: 1.7991125583648682 Accuracy: 0.296875\n","Loss: 1.9878393411636353 Accuracy: 0.203125\n","Loss: 1.9001814126968384 Accuracy: 0.34375\n","Loss: 1.8256651163101196 Accuracy: 0.34375\n","Loss: 1.9937894344329834 Accuracy: 0.1875\n","Loss: 1.8148384094238281 Accuracy: 0.328125\n","Loss: 2.0298190116882324 Accuracy: 0.21875\n","Loss: 1.8942339420318604 Accuracy: 0.21875\n","Loss: 1.8994379043579102 Accuracy: 0.28125\n","Loss: 1.9005036354064941 Accuracy: 0.25\n","Loss: 2.0612990856170654 Accuracy: 0.203125\n","Loss: 2.0031259059906006 Accuracy: 0.25\n","Loss: 1.9396215677261353 Accuracy: 0.203125\n","Loss: 1.7475582361221313 Accuracy: 0.359375\n","Loss: 1.976562261581421 Accuracy: 0.234375\n","Loss: 1.9783577919006348 Accuracy: 0.21875\n","Loss: 1.9125244617462158 Accuracy: 0.3125\n","Loss: 1.7637323141098022 Accuracy: 0.265625\n","Loss: 1.9343866109848022 Accuracy: 0.265625\n","Loss: 1.9145582914352417 Accuracy: 0.265625\n","Loss: 1.8370388746261597 Accuracy: 0.296875\n","Loss: 1.8044788837432861 Accuracy: 0.265625\n","Loss: 1.9228090047836304 Accuracy: 0.234375\n","Loss: 1.934828519821167 Accuracy: 0.125\n","Loss: 2.0056560039520264 Accuracy: 0.25\n","Loss: 1.8024015426635742 Accuracy: 0.296875\n","Loss: 1.920189380645752 Accuracy: 0.375\n","Loss: 1.8272274732589722 Accuracy: 0.296875\n","Loss: 1.8543463945388794 Accuracy: 0.28125\n","Loss: 1.9552099704742432 Accuracy: 0.28125\n","Loss: 1.9084270000457764 Accuracy: 0.28125\n","Loss: 1.782371997833252 Accuracy: 0.234375\n","Loss: 1.9654827117919922 Accuracy: 0.234375\n","Loss: 2.012148857116699 Accuracy: 0.25\n","Loss: 1.8317619562149048 Accuracy: 0.3125\n","Loss: 2.1085991859436035 Accuracy: 0.15625\n","Loss: 1.9639532566070557 Accuracy: 0.28125\n","Loss: 1.9063568115234375 Accuracy: 0.171875\n","Loss: 2.108086347579956 Accuracy: 0.203125\n","Loss: 1.897436499595642 Accuracy: 0.296875\n","Loss: 1.8480414152145386 Accuracy: 0.296875\n","Loss: 1.803947925567627 Accuracy: 0.296875\n","Loss: 1.8815994262695312 Accuracy: 0.234375\n","Loss: 1.8463330268859863 Accuracy: 0.296875\n","Loss: 1.7658822536468506 Accuracy: 0.40625\n","Loss: 1.764662504196167 Accuracy: 0.390625\n","Loss: 1.9787977933883667 Accuracy: 0.1875\n","Loss: 1.9190561771392822 Accuracy: 0.21875\n","Loss: 1.7936753034591675 Accuracy: 0.25\n","Loss: 1.9838122129440308 Accuracy: 0.234375\n","Loss: 1.9549604654312134 Accuracy: 0.265625\n","Loss: 1.8319792747497559 Accuracy: 0.34375\n","Loss: 1.9501551389694214 Accuracy: 0.25\n","Loss: 1.817611575126648 Accuracy: 0.359375\n","Loss: 1.9577653408050537 Accuracy: 0.140625\n","Loss: 1.938094973564148 Accuracy: 0.234375\n","Loss: 1.8353415727615356 Accuracy: 0.265625\n","Loss: 1.790979027748108 Accuracy: 0.28125\n","Loss: 1.8478282690048218 Accuracy: 0.3125\n","Loss: 2.0255050659179688 Accuracy: 0.3125\n","Loss: 1.9359428882598877 Accuracy: 0.25\n","Loss: 1.90718412399292 Accuracy: 0.296875\n","Loss: 2.00704026222229 Accuracy: 0.171875\n","Loss: 2.0128438472747803 Accuracy: 0.140625\n","Loss: 1.8966593742370605 Accuracy: 0.328125\n","Loss: 1.9211487770080566 Accuracy: 0.296875\n","Loss: 1.8708901405334473 Accuracy: 0.34375\n","Loss: 2.0226948261260986 Accuracy: 0.171875\n","Loss: 1.918887734413147 Accuracy: 0.234375\n","Loss: 1.8590725660324097 Accuracy: 0.265625\n","Loss: 1.9813450574874878 Accuracy: 0.265625\n","Loss: 1.7434576749801636 Accuracy: 0.328125\n","Loss: 1.9650458097457886 Accuracy: 0.28125\n","Loss: 1.8551234006881714 Accuracy: 0.296875\n","Loss: 1.8882840871810913 Accuracy: 0.234375\n","Loss: 1.989475965499878 Accuracy: 0.1875\n","Loss: 1.8842064142227173 Accuracy: 0.296875\n","Loss: 1.8969656229019165 Accuracy: 0.28125\n","Loss: 1.8454527854919434 Accuracy: 0.296875\n","Loss: 1.8043259382247925 Accuracy: 0.234375\n","Loss: 1.730574369430542 Accuracy: 0.359375\n","Loss: 1.8340835571289062 Accuracy: 0.359375\n","Loss: 1.9987423419952393 Accuracy: 0.21875\n","Loss: 1.9526801109313965 Accuracy: 0.25\n","Loss: 1.7624337673187256 Accuracy: 0.375\n","Loss: 1.792577862739563 Accuracy: 0.296875\n","Loss: 1.983746886253357 Accuracy: 0.28125\n","Loss: 1.9478288888931274 Accuracy: 0.1875\n","Loss: 1.8083326816558838 Accuracy: 0.359375\n","Loss: 1.8765769004821777 Accuracy: 0.296875\n","Loss: 2.052992343902588 Accuracy: 0.171875\n","Loss: 1.9010400772094727 Accuracy: 0.234375\n","Loss: 1.8032041788101196 Accuracy: 0.34375\n","Loss: 1.9137998819351196 Accuracy: 0.28125\n","Loss: 1.9016103744506836 Accuracy: 0.25\n","Loss: 1.8126089572906494 Accuracy: 0.34375\n","Loss: 1.86918044090271 Accuracy: 0.234375\n","Loss: 1.954089641571045 Accuracy: 0.234375\n","Loss: 1.9237104654312134 Accuracy: 0.296875\n","Loss: 1.974374532699585 Accuracy: 0.203125\n","Loss: 1.876997947692871 Accuracy: 0.28125\n","Loss: 1.8234349489212036 Accuracy: 0.296875\n","Loss: 1.9193699359893799 Accuracy: 0.34375\n","Loss: 1.9622857570648193 Accuracy: 0.21875\n","Loss: 1.8703408241271973 Accuracy: 0.3125\n","Loss: 1.91997492313385 Accuracy: 0.21875\n","Loss: 1.958183765411377 Accuracy: 0.171875\n","Loss: 1.9362962245941162 Accuracy: 0.234375\n","Loss: 1.934591293334961 Accuracy: 0.28125\n","Loss: 1.734393835067749 Accuracy: 0.328125\n","Loss: 1.873162865638733 Accuracy: 0.171875\n","Loss: 1.9411259889602661 Accuracy: 0.234375\n","Loss: 1.8789088726043701 Accuracy: 0.25\n","Loss: 1.8451768159866333 Accuracy: 0.265625\n","Loss: 2.000581979751587 Accuracy: 0.1875\n","Loss: 1.9660942554473877 Accuracy: 0.234375\n","Loss: 1.970232367515564 Accuracy: 0.171875\n","Loss: 1.8124505281448364 Accuracy: 0.296875\n","Loss: 1.933824896812439 Accuracy: 0.234375\n","Loss: 1.851547360420227 Accuracy: 0.296875\n","Loss: 1.809789776802063 Accuracy: 0.234375\n","Loss: 1.992256999015808 Accuracy: 0.171875\n","Loss: 1.8648756742477417 Accuracy: 0.328125\n","Loss: 1.989269495010376 Accuracy: 0.234375\n","Loss: 1.8599824905395508 Accuracy: 0.28125\n","Loss: 1.822518229484558 Accuracy: 0.265625\n","Loss: 1.921020746231079 Accuracy: 0.296875\n","Loss: 1.8247934579849243 Accuracy: 0.28125\n","Loss: 1.9046742916107178 Accuracy: 0.265625\n","Loss: 1.7972724437713623 Accuracy: 0.296875\n","Loss: 1.9060304164886475 Accuracy: 0.25\n","Loss: 2.188534736633301 Accuracy: 0.125\n","Loss: 1.8164689540863037 Accuracy: 0.265625\n","Loss: 1.9406720399856567 Accuracy: 0.3125\n","Loss: 1.9964826107025146 Accuracy: 0.3125\n","Loss: 1.9248173236846924 Accuracy: 0.265625\n","Loss: 1.871760606765747 Accuracy: 0.234375\n","Loss: 1.8609613180160522 Accuracy: 0.28125\n","Loss: 1.7246397733688354 Accuracy: 0.328125\n","Loss: 1.7995193004608154 Accuracy: 0.265625\n","Loss: 1.916796326637268 Accuracy: 0.203125\n","Loss: 1.894891381263733 Accuracy: 0.296875\n","Loss: 2.0729427337646484 Accuracy: 0.1875\n","Loss: 1.8518953323364258 Accuracy: 0.203125\n","Loss: 1.8985546827316284 Accuracy: 0.203125\n","Loss: 1.8172286748886108 Accuracy: 0.296875\n","Loss: 1.829729676246643 Accuracy: 0.28125\n","Loss: 2.011929512023926 Accuracy: 0.21875\n","Loss: 1.8408883810043335 Accuracy: 0.28125\n","Loss: 1.9068623781204224 Accuracy: 0.28125\n","Loss: 1.9812690019607544 Accuracy: 0.203125\n","Loss: 1.8678888082504272 Accuracy: 0.296875\n","Loss: 1.9454584121704102 Accuracy: 0.296875\n","Loss: 1.8529293537139893 Accuracy: 0.265625\n","Loss: 1.833367109298706 Accuracy: 0.3125\n","Loss: 1.7821338176727295 Accuracy: 0.265625\n","Loss: 1.7240203619003296 Accuracy: 0.390625\n","Loss: 1.9489789009094238 Accuracy: 0.234375\n","Loss: 2.113628625869751 Accuracy: 0.15625\n","Loss: 1.837286114692688 Accuracy: 0.28125\n","Loss: 1.9614216089248657 Accuracy: 0.234375\n","Loss: 1.9224282503128052 Accuracy: 0.28125\n","Loss: 1.7435317039489746 Accuracy: 0.34375\n","Loss: 1.8582838773727417 Accuracy: 0.28125\n","Loss: 1.8395111560821533 Accuracy: 0.203125\n","Loss: 1.9007490873336792 Accuracy: 0.328125\n","Loss: 1.835485816001892 Accuracy: 0.3125\n","Loss: 1.9773054122924805 Accuracy: 0.171875\n","Loss: 1.9489964246749878 Accuracy: 0.328125\n","Loss: 1.8382413387298584 Accuracy: 0.40625\n","Loss: 1.7400978803634644 Accuracy: 0.28125\n","Loss: 1.9064979553222656 Accuracy: 0.25\n","Loss: 1.7937175035476685 Accuracy: 0.359375\n","Loss: 1.9894390106201172 Accuracy: 0.234375\n","Loss: 1.8418567180633545 Accuracy: 0.328125\n","Loss: 1.8269968032836914 Accuracy: 0.296875\n","Loss: 1.9595038890838623 Accuracy: 0.28125\n","Loss: 1.9252197742462158 Accuracy: 0.25\n","Loss: 1.8624845743179321 Accuracy: 0.25\n","Loss: 1.7426390647888184 Accuracy: 0.359375\n","Loss: 1.9969842433929443 Accuracy: 0.234375\n","Loss: 1.852844476699829 Accuracy: 0.28125\n","Loss: 1.8852943181991577 Accuracy: 0.28125\n","Loss: 1.9187768697738647 Accuracy: 0.21875\n","Loss: 1.8114054203033447 Accuracy: 0.328125\n","Loss: 1.929871678352356 Accuracy: 0.28125\n","Loss: 1.9067001342773438 Accuracy: 0.265625\n","Loss: 1.8947105407714844 Accuracy: 0.296875\n","Loss: 1.842101812362671 Accuracy: 0.3125\n","Loss: 1.928855299949646 Accuracy: 0.1875\n","Loss: 1.876999020576477 Accuracy: 0.34375\n","Loss: 1.9302432537078857 Accuracy: 0.234375\n","Loss: 1.9228954315185547 Accuracy: 0.25\n","Loss: 1.876336693763733 Accuracy: 0.25\n","Loss: 1.9983609914779663 Accuracy: 0.234375\n","Loss: 1.8670519590377808 Accuracy: 0.359375\n","Loss: 1.8520182371139526 Accuracy: 0.203125\n","Loss: 1.917541265487671 Accuracy: 0.265625\n","Loss: 1.8328214883804321 Accuracy: 0.265625\n","Loss: 1.8456364870071411 Accuracy: 0.3125\n","Loss: 1.8130465745925903 Accuracy: 0.28125\n","Loss: 1.8781230449676514 Accuracy: 0.265625\n","Loss: 1.9568326473236084 Accuracy: 0.328125\n","Loss: 1.8729455471038818 Accuracy: 0.203125\n","Loss: 1.9684606790542603 Accuracy: 0.21875\n","Loss: 1.8648523092269897 Accuracy: 0.34375\n","Loss: 2.0204763412475586 Accuracy: 0.21875\n","Loss: 1.728572964668274 Accuracy: 0.265625\n","Loss: 1.9577393531799316 Accuracy: 0.25\n","Loss: 1.881314754486084 Accuracy: 0.328125\n","Loss: 1.7529031038284302 Accuracy: 0.265625\n","Loss: 1.7484474182128906 Accuracy: 0.296875\n","Loss: 1.7700004577636719 Accuracy: 0.328125\n","Loss: 1.898558259010315 Accuracy: 0.28125\n","Loss: 1.8827756643295288 Accuracy: 0.34375\n","Loss: 1.8678667545318604 Accuracy: 0.234375\n","Loss: 1.7656991481781006 Accuracy: 0.296875\n","Loss: 1.9165990352630615 Accuracy: 0.265625\n","Loss: 1.8570926189422607 Accuracy: 0.25\n","Loss: 1.9223213195800781 Accuracy: 0.1875\n","Loss: 1.8299915790557861 Accuracy: 0.296875\n","Loss: 1.9369239807128906 Accuracy: 0.21875\n","Loss: 1.793940544128418 Accuracy: 0.359375\n","Loss: 1.90056574344635 Accuracy: 0.1875\n","Loss: 1.9203544855117798 Accuracy: 0.3125\n","Loss: 2.044966459274292 Accuracy: 0.15625\n","Loss: 1.7796286344528198 Accuracy: 0.296875\n","Loss: 1.9361516237258911 Accuracy: 0.1875\n","Loss: 1.9889520406723022 Accuracy: 0.265625\n","Loss: 1.8048943281173706 Accuracy: 0.328125\n","Loss: 1.8531382083892822 Accuracy: 0.25\n","Loss: 1.7922325134277344 Accuracy: 0.265625\n","Loss: 2.0249710083007812 Accuracy: 0.234375\n","Loss: 1.8036755323410034 Accuracy: 0.3125\n","Loss: 1.9647990465164185 Accuracy: 0.171875\n","Loss: 1.9246219396591187 Accuracy: 0.296875\n","Loss: 1.8932759761810303 Accuracy: 0.28125\n","Loss: 1.8472126722335815 Accuracy: 0.171875\n","Loss: 1.6957943439483643 Accuracy: 0.328125\n","Loss: 1.9666104316711426 Accuracy: 0.234375\n","Loss: 1.9625908136367798 Accuracy: 0.25\n","Loss: 1.8208643198013306 Accuracy: 0.265625\n","Loss: 2.022136688232422 Accuracy: 0.21875\n","Loss: 1.7841886281967163 Accuracy: 0.265625\n","Loss: 1.8462344408035278 Accuracy: 0.25\n","Loss: 2.016282558441162 Accuracy: 0.203125\n","Loss: 1.855912685394287 Accuracy: 0.28125\n","Loss: 1.9120444059371948 Accuracy: 0.234375\n","Loss: 1.8327102661132812 Accuracy: 0.28125\n","Loss: 1.909723162651062 Accuracy: 0.359375\n","Loss: 1.957836389541626 Accuracy: 0.25\n","Loss: 1.7772536277770996 Accuracy: 0.265625\n","Loss: 1.951051950454712 Accuracy: 0.25\n","Loss: 2.0711309909820557 Accuracy: 0.171875\n","Loss: 1.92598295211792 Accuracy: 0.25\n","Loss: 1.9692286252975464 Accuracy: 0.28125\n","Loss: 1.9433143138885498 Accuracy: 0.296875\n","Loss: 1.8613801002502441 Accuracy: 0.359375\n","Loss: 1.8572945594787598 Accuracy: 0.328125\n","Loss: 1.9679749011993408 Accuracy: 0.15625\n","Loss: 1.840854525566101 Accuracy: 0.25\n","Loss: 1.8151359558105469 Accuracy: 0.234375\n","Loss: 1.9145052433013916 Accuracy: 0.3125\n","Loss: 2.0415608882904053 Accuracy: 0.203125\n","Loss: 2.201240301132202 Accuracy: 0.171875\n","Loss: 1.714323878288269 Accuracy: 0.328125\n","Loss: 1.9139232635498047 Accuracy: 0.21875\n","Loss: 1.9905983209609985 Accuracy: 0.203125\n","Loss: 1.8386071920394897 Accuracy: 0.3125\n","Loss: 1.914743423461914 Accuracy: 0.234375\n","Loss: 1.9004778861999512 Accuracy: 0.265625\n","Loss: 1.8415225744247437 Accuracy: 0.296875\n","Loss: 1.9589805603027344 Accuracy: 0.28125\n","Loss: 1.9032455682754517 Accuracy: 0.140625\n","Loss: 1.9516326189041138 Accuracy: 0.203125\n","Loss: 1.8804404735565186 Accuracy: 0.171875\n","Loss: 1.851697325706482 Accuracy: 0.28125\n","Loss: 1.9599833488464355 Accuracy: 0.3125\n","Loss: 1.9049891233444214 Accuracy: 0.296875\n","Loss: 1.9592571258544922 Accuracy: 0.171875\n","Loss: 1.9481006860733032 Accuracy: 0.28125\n","Loss: 1.8858006000518799 Accuracy: 0.203125\n","Loss: 2.0495760440826416 Accuracy: 0.25\n","Loss: 1.9013997316360474 Accuracy: 0.296875\n","Loss: 1.7268433570861816 Accuracy: 0.265625\n","Loss: 1.793946385383606 Accuracy: 0.234375\n","Loss: 1.8850910663604736 Accuracy: 0.1875\n","Loss: 1.8497174978256226 Accuracy: 0.28125\n","Loss: 1.922523021697998 Accuracy: 0.296875\n","Loss: 1.8127243518829346 Accuracy: 0.28125\n","Loss: 1.9528838396072388 Accuracy: 0.328125\n","Loss: 1.9101648330688477 Accuracy: 0.28125\n","Loss: 1.893595814704895 Accuracy: 0.28125\n","Loss: 1.9745250940322876 Accuracy: 0.265625\n","Loss: 1.7910852432250977 Accuracy: 0.390625\n","Loss: 1.8797708749771118 Accuracy: 0.40625\n","Loss: 1.9085620641708374 Accuracy: 0.296875\n","Loss: 1.9134166240692139 Accuracy: 0.234375\n","Loss: 1.8929059505462646 Accuracy: 0.34375\n","Loss: 1.9059200286865234 Accuracy: 0.28125\n","Loss: 1.8629275560379028 Accuracy: 0.3125\n","Loss: 1.9231364727020264 Accuracy: 0.25\n","Loss: 1.982217788696289 Accuracy: 0.234375\n","Loss: 1.876147747039795 Accuracy: 0.296875\n","Loss: 1.9051915407180786 Accuracy: 0.21875\n","Loss: 1.9387301206588745 Accuracy: 0.234375\n","Loss: 1.9158084392547607 Accuracy: 0.34375\n","Loss: 1.9859284162521362 Accuracy: 0.25\n","Loss: 1.8827850818634033 Accuracy: 0.28125\n","Loss: 1.9680132865905762 Accuracy: 0.265625\n","Loss: 2.0561411380767822 Accuracy: 0.1875\n","Loss: 1.9156972169876099 Accuracy: 0.265625\n","Loss: 1.7867522239685059 Accuracy: 0.3125\n","Loss: 1.9969245195388794 Accuracy: 0.265625\n","Loss: 1.9525612592697144 Accuracy: 0.25\n","Loss: 1.9348907470703125 Accuracy: 0.265625\n","Loss: 1.9532420635223389 Accuracy: 0.328125\n","Loss: 1.7908388376235962 Accuracy: 0.3125\n","Loss: 1.8796683549880981 Accuracy: 0.25\n","Loss: 1.7748714685440063 Accuracy: 0.28125\n","Loss: 1.984848976135254 Accuracy: 0.234375\n","Loss: 1.850895881652832 Accuracy: 0.234375\n","Loss: 1.9488041400909424 Accuracy: 0.234375\n","Loss: 1.942801833152771 Accuracy: 0.265625\n","Loss: 1.9333773851394653 Accuracy: 0.21875\n","Loss: 1.8888412714004517 Accuracy: 0.21875\n","Loss: 1.835036039352417 Accuracy: 0.25\n","Loss: 1.780739188194275 Accuracy: 0.3125\n","Loss: 1.8749548196792603 Accuracy: 0.21875\n","Loss: 1.967300295829773 Accuracy: 0.28125\n","Loss: 1.9142518043518066 Accuracy: 0.296875\n","Loss: 1.8342822790145874 Accuracy: 0.328125\n","Loss: 1.919856309890747 Accuracy: 0.28125\n","Loss: 1.889671802520752 Accuracy: 0.296875\n","Loss: 1.9954659938812256 Accuracy: 0.15625\n","Loss: 1.809556007385254 Accuracy: 0.328125\n","Loss: 1.9239273071289062 Accuracy: 0.328125\n","Loss: 1.975098967552185 Accuracy: 0.21875\n","Loss: 1.8746029138565063 Accuracy: 0.265625\n","Loss: 1.7772536277770996 Accuracy: 0.328125\n","Loss: 1.9035016298294067 Accuracy: 0.328125\n","Loss: 1.8300626277923584 Accuracy: 0.1875\n","Loss: 1.8563799858093262 Accuracy: 0.28125\n","Loss: 1.9606958627700806 Accuracy: 0.28125\n","Loss: 1.9772374629974365 Accuracy: 0.234375\n","Loss: 1.896616816520691 Accuracy: 0.234375\n","Loss: 2.0081965923309326 Accuracy: 0.234375\n","Loss: 1.7678797245025635 Accuracy: 0.359375\n","Loss: 2.0274696350097656 Accuracy: 0.265625\n","Loss: 2.0205326080322266 Accuracy: 0.203125\n","Loss: 1.9152569770812988 Accuracy: 0.265625\n","Loss: 1.9674155712127686 Accuracy: 0.296875\n","Loss: 1.7754056453704834 Accuracy: 0.265625\n","Loss: 1.8877596855163574 Accuracy: 0.296875\n","Loss: 2.1559059619903564 Accuracy: 0.1875\n","Loss: 1.8448728322982788 Accuracy: 0.328125\n","Loss: 1.792283535003662 Accuracy: 0.25\n","Loss: 1.9263083934783936 Accuracy: 0.34375\n","Loss: 2.008538007736206 Accuracy: 0.265625\n","Loss: 1.8680769205093384 Accuracy: 0.28125\n","Loss: 1.8791389465332031 Accuracy: 0.234375\n","Loss: 1.8264906406402588 Accuracy: 0.234375\n","Loss: 1.7778881788253784 Accuracy: 0.265625\n","Loss: 1.9574933052062988 Accuracy: 0.3125\n","Loss: 1.78573739528656 Accuracy: 0.28125\n","Loss: 1.768990397453308 Accuracy: 0.34375\n","Loss: 1.8929245471954346 Accuracy: 0.25\n","Loss: 1.824684977531433 Accuracy: 0.25\n","Loss: 1.9128445386886597 Accuracy: 0.28125\n","Loss: 1.8886300325393677 Accuracy: 0.3125\n","Loss: 2.0004587173461914 Accuracy: 0.171875\n","Loss: 1.9522056579589844 Accuracy: 0.296875\n","Loss: 1.821141242980957 Accuracy: 0.328125\n","Loss: 2.0113797187805176 Accuracy: 0.234375\n","Loss: 1.906812071800232 Accuracy: 0.265625\n","Loss: 1.9035905599594116 Accuracy: 0.28125\n","Loss: 1.9824743270874023 Accuracy: 0.171875\n","Loss: 1.9204046726226807 Accuracy: 0.25\n","Loss: 1.8264271020889282 Accuracy: 0.28125\n","Loss: 1.8824901580810547 Accuracy: 0.3125\n","Loss: 1.8223001956939697 Accuracy: 0.296875\n","Loss: 1.8613802194595337 Accuracy: 0.234375\n","Loss: 1.899359107017517 Accuracy: 0.265625\n","Loss: 1.8338954448699951 Accuracy: 0.265625\n","Loss: 1.8480536937713623 Accuracy: 0.1875\n","Loss: 1.8430366516113281 Accuracy: 0.28125\n","Loss: 1.7058322429656982 Accuracy: 0.40625\n","Loss: 1.9775984287261963 Accuracy: 0.203125\n","Loss: 1.8784470558166504 Accuracy: 0.3125\n","Loss: 1.8175301551818848 Accuracy: 0.28125\n","Loss: 1.926139235496521 Accuracy: 0.171875\n","Loss: 1.7814178466796875 Accuracy: 0.3125\n","Loss: 1.8011707067489624 Accuracy: 0.40625\n","Loss: 1.8442693948745728 Accuracy: 0.296875\n","Loss: 1.9531930685043335 Accuracy: 0.28125\n","Loss: 1.9076919555664062 Accuracy: 0.21875\n","Loss: 1.8629788160324097 Accuracy: 0.296875\n","Loss: 1.8337178230285645 Accuracy: 0.296875\n","Loss: 1.6895127296447754 Accuracy: 0.359375\n","Loss: 2.113922119140625 Accuracy: 0.171875\n","Loss: 1.8814444541931152 Accuracy: 0.171875\n","Loss: 1.8045250177383423 Accuracy: 0.328125\n","Loss: 1.7988067865371704 Accuracy: 0.3125\n","Loss: 1.710102915763855 Accuracy: 0.390625\n","Loss: 1.9045639038085938 Accuracy: 0.234375\n","Loss: 1.9817938804626465 Accuracy: 0.1875\n","Loss: 1.8123735189437866 Accuracy: 0.328125\n","Loss: 1.9020380973815918 Accuracy: 0.28125\n","Loss: 1.8702545166015625 Accuracy: 0.265625\n","Loss: 2.0088329315185547 Accuracy: 0.25\n","Loss: 1.8320863246917725 Accuracy: 0.296875\n","Loss: 1.9985367059707642 Accuracy: 0.171875\n","Loss: 1.9411720037460327 Accuracy: 0.3125\n","Loss: 1.8770732879638672 Accuracy: 0.34375\n","Loss: 1.7474849224090576 Accuracy: 0.265625\n","Loss: 1.8277710676193237 Accuracy: 0.3125\n","Loss: 1.78959321975708 Accuracy: 0.3125\n","Loss: 2.0113325119018555 Accuracy: 0.21875\n","Loss: 1.9035334587097168 Accuracy: 0.25\n","Loss: 1.786805510520935 Accuracy: 0.3125\n","Loss: 1.988838791847229 Accuracy: 0.15625\n","Loss: 2.030824661254883 Accuracy: 0.203125\n","Loss: 1.849122405052185 Accuracy: 0.296875\n","Loss: 1.895121455192566 Accuracy: 0.265625\n","Loss: 1.8610687255859375 Accuracy: 0.34375\n","Loss: 1.8626817464828491 Accuracy: 0.265625\n","Loss: 1.8735727071762085 Accuracy: 0.265625\n","Loss: 1.8993722200393677 Accuracy: 0.28125\n","Loss: 1.947918176651001 Accuracy: 0.234375\n","Loss: 1.846735954284668 Accuracy: 0.28125\n","Loss: 1.7930681705474854 Accuracy: 0.296875\n","Loss: 1.836371660232544 Accuracy: 0.25\n","Loss: 1.8058592081069946 Accuracy: 0.265625\n","Loss: 2.010094404220581 Accuracy: 0.203125\n","Loss: 1.8799688816070557 Accuracy: 0.3125\n","Loss: 1.8753169775009155 Accuracy: 0.328125\n","Loss: 1.8965873718261719 Accuracy: 0.234375\n","Loss: 1.85427987575531 Accuracy: 0.265625\n","Loss: 1.8201305866241455 Accuracy: 0.265625\n","Loss: 1.8685141801834106 Accuracy: 0.3125\n","Loss: 1.8677892684936523 Accuracy: 0.265625\n","Loss: 1.9117441177368164 Accuracy: 0.234375\n","Loss: 1.9399093389511108 Accuracy: 0.28125\n","Loss: 1.88791823387146 Accuracy: 0.25\n","Loss: 1.667111873626709 Accuracy: 0.40625\n","Loss: 1.9842463731765747 Accuracy: 0.125\n","Loss: 1.955871343612671 Accuracy: 0.171875\n","Loss: 1.8301578760147095 Accuracy: 0.328125\n","Loss: 1.955452561378479 Accuracy: 0.28125\n","Loss: 1.94221830368042 Accuracy: 0.203125\n","Loss: 1.818878173828125 Accuracy: 0.21875\n","Loss: 1.8821367025375366 Accuracy: 0.3125\n","Loss: 1.9172078371047974 Accuracy: 0.1875\n","Loss: 1.9220688343048096 Accuracy: 0.3125\n","Loss: 1.891941785812378 Accuracy: 0.25\n","Loss: 1.9911160469055176 Accuracy: 0.265625\n","Loss: 1.9505938291549683 Accuracy: 0.3125\n","Loss: 1.9128913879394531 Accuracy: 0.21875\n","Loss: 1.9151275157928467 Accuracy: 0.21875\n","Loss: 1.9016413688659668 Accuracy: 0.265625\n","Loss: 1.6611207723617554 Accuracy: 0.328125\n","Loss: 1.880401372909546 Accuracy: 0.265625\n","Loss: 1.80585515499115 Accuracy: 0.265625\n","Loss: 1.8821951150894165 Accuracy: 0.3125\n","Loss: 1.982506275177002 Accuracy: 0.1875\n","Loss: 1.7645989656448364 Accuracy: 0.328125\n","Loss: 1.892372965812683 Accuracy: 0.234375\n","Loss: 1.796706199645996 Accuracy: 0.28125\n","Loss: 1.908905029296875 Accuracy: 0.265625\n","Loss: 1.9909839630126953 Accuracy: 0.25\n","Loss: 1.7349392175674438 Accuracy: 0.3125\n","Loss: 1.981321930885315 Accuracy: 0.234375\n","Loss: 1.8720221519470215 Accuracy: 0.265625\n","Loss: 1.9948021173477173 Accuracy: 0.1875\n","Loss: 1.8222635984420776 Accuracy: 0.296875\n","Loss: 1.9093443155288696 Accuracy: 0.1875\n","Loss: 1.7790591716766357 Accuracy: 0.34375\n","Loss: 1.9536141157150269 Accuracy: 0.21875\n","Loss: 1.8680627346038818 Accuracy: 0.234375\n","Loss: 1.847259283065796 Accuracy: 0.265625\n","Loss: 1.8071492910385132 Accuracy: 0.25\n","Loss: 1.888745903968811 Accuracy: 0.296875\n","Loss: 2.1184823513031006 Accuracy: 0.234375\n","Loss: 1.8915600776672363 Accuracy: 0.265625\n","Loss: 1.730086326599121 Accuracy: 0.40625\n","Loss: 1.9305180311203003 Accuracy: 0.21875\n","Loss: 1.6843609809875488 Accuracy: 0.296875\n","Loss: 1.8948171138763428 Accuracy: 0.3125\n","Loss: 1.8735883235931396 Accuracy: 0.21875\n","Loss: 1.9572317600250244 Accuracy: 0.1875\n","Loss: 1.7766731977462769 Accuracy: 0.34375\n","Loss: 1.8679203987121582 Accuracy: 0.265625\n","Loss: 2.0128073692321777 Accuracy: 0.234375\n","Loss: 1.857085943222046 Accuracy: 0.234375\n","Loss: 1.7746682167053223 Accuracy: 0.34375\n","Loss: 1.8637502193450928 Accuracy: 0.328125\n","Loss: 1.9207514524459839 Accuracy: 0.234375\n","Loss: 1.8387260437011719 Accuracy: 0.375\n","Loss: 1.8285086154937744 Accuracy: 0.234375\n","Loss: 1.886200189590454 Accuracy: 0.265625\n","Loss: 1.9163450002670288 Accuracy: 0.328125\n","Loss: 2.0447161197662354 Accuracy: 0.15625\n","Loss: 1.7864434719085693 Accuracy: 0.3125\n","Loss: 1.942420244216919 Accuracy: 0.234375\n","Loss: 1.817702293395996 Accuracy: 0.34375\n","Loss: 1.8128600120544434 Accuracy: 0.328125\n","Loss: 1.8714656829833984 Accuracy: 0.234375\n","Loss: 1.7830394506454468 Accuracy: 0.28125\n","Loss: 1.9425467252731323 Accuracy: 0.171875\n","Loss: 1.8023490905761719 Accuracy: 0.328125\n","Loss: 1.8326557874679565 Accuracy: 0.328125\n","Loss: 1.7733582258224487 Accuracy: 0.3125\n","Loss: 1.8453888893127441 Accuracy: 0.28125\n","Loss: 1.8390028476715088 Accuracy: 0.296875\n","Loss: 1.795353889465332 Accuracy: 0.296875\n","Loss: 1.8715990781784058 Accuracy: 0.1875\n","Loss: 1.8621900081634521 Accuracy: 0.296875\n","Loss: 1.79459810256958 Accuracy: 0.359375\n","Loss: 1.7740867137908936 Accuracy: 0.359375\n","Loss: 1.9620108604431152 Accuracy: 0.21875\n","Loss: 1.6923424005508423 Accuracy: 0.34375\n","Loss: 1.8570594787597656 Accuracy: 0.234375\n","Loss: 1.895674228668213 Accuracy: 0.25\n","Loss: 2.022138833999634 Accuracy: 0.203125\n","Loss: 1.8045843839645386 Accuracy: 0.25\n","Loss: 1.8824543952941895 Accuracy: 0.3125\n","Loss: 1.7690918445587158 Accuracy: 0.3125\n","Loss: 1.9228856563568115 Accuracy: 0.25\n","Loss: 1.7995251417160034 Accuracy: 0.203125\n","Loss: 1.9974063634872437 Accuracy: 0.265625\n","Loss: 1.6875532865524292 Accuracy: 0.375\n","Loss: 2.019493818283081 Accuracy: 0.171875\n","Loss: 1.761757731437683 Accuracy: 0.34375\n","Loss: 1.9138329029083252 Accuracy: 0.234375\n","Loss: 1.8987749814987183 Accuracy: 0.34375\n","Loss: 1.8799941539764404 Accuracy: 0.296875\n","Loss: 1.887033462524414 Accuracy: 0.140625\n","Loss: 1.9679673910140991 Accuracy: 0.234375\n","Loss: 1.7725874185562134 Accuracy: 0.328125\n","Loss: 1.7696884870529175 Accuracy: 0.25\n","Loss: 1.983812928199768 Accuracy: 0.3125\n","Loss: 1.7267311811447144 Accuracy: 0.265625\n","Loss: 1.829406976699829 Accuracy: 0.265625\n","Loss: 1.935959815979004 Accuracy: 0.203125\n","Loss: 1.8580913543701172 Accuracy: 0.28125\n","Loss: 1.7715245485305786 Accuracy: 0.34375\n","Loss: 1.8689886331558228 Accuracy: 0.265625\n","Loss: 1.9585210084915161 Accuracy: 0.21875\n","Loss: 1.9706640243530273 Accuracy: 0.234375\n","Loss: 1.7300671339035034 Accuracy: 0.484375\n","Loss: 1.8704818487167358 Accuracy: 0.25\n"]}],"source":["trans = transforms.Compose([\n","            # transforms.ToPILImage(),\n","            transforms.Resize(IMG_SIZE),\n","            transforms.ToTensor(),\n","            # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.255]),\n","        ])\n","\n","ds = MNIST(root=\"data/\", train=True, transform=trans, download=True)\n","# conv = nn.Conv2d(1, 768, kernel_size=(2, 2), stride=(2, 2))\n","# x = ds.__getitem__(0)[0].unsqueeze(0)\n","dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n","\n","model = ViT(nhead=4, dim_feedforward=16, blocks=4, mlp_head_units=[32, 16], n_classes=10, img_size=IMG_SIZE, patch_size=PATCH_SIZE, n_channels=1, d_model=8)\n","model.to(DEVICE)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","for _ in range(EPOCHS):\n","    for x, y in dl:\n","        x = x.to(DEVICE)\n","        y = y.to(DEVICE)\n","        logits = model(x)\n","        loss = nn.functional.cross_entropy(logits, y)\n","        accuracy = (logits.argmax(dim=1) == y).float().mean()\n","        print(\"Loss:\", loss.item(), \"Accuracy:\", accuracy.item())\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    print(\"Epoch:\", _)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["ans = conv(x)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([1, 768, 14, 14])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["ans.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2973,"status":"ok","timestamp":1700023600641,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"CB4PR7zFXDUe","outputId":"fb1e11e3-1f20-4a51-ee73-898016e4395d"},"outputs":[],"source":["# cifar100_dm = MyDataModule(dataset_to_down=CIFAR100, img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n","# cifar100_dm.prepare_data()\n","# n_classes = cifar100_dm.n_classes()\n","# wandb_logger = WandbLogger(project='ViTHybrid_test_cifar100',\n","#                            config={'batch_size': BATCH_SIZE, 'epochs': EPOCHS, 'learning_rate': LEARNING_RATE, 'img_size': IMG_SIZE, 'patch_size': PATCH_SIZE})\n","# vit_model = ViTModule(img_size=IMG_SIZE, patch_size=PATCH_SIZE, n_channels=3,\n","#                   n_classes=100, nhead=4, dim_feedforward=1024, blocks=BLOCKS,\n","#                   mlp_head_units=[1024, 512], d_model=512, learning_rate=LEARNING_RATE)\n","# vit_b_16_model = ViTPretrainedModule(model=vit_b_16(pretrained=True), learning_rate=LEARNING_RATE, n_classes=n_classes)\n","# hf_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=n_classes)\n","# hf_model = BitForImageClassification.from_pretrained('facebookresearch/bit-m-r101x1-ILSVRC2012')\n","# hf_model = BitForImageClassification.from_pretrained('google/bit-50')\n","# hf_model = ViTHybridForImageClassification.from_pretrained('google/vit-hybrid-base-bit-384')\n","# freeze all layers except the final layer\n","# for param in hf_model.bit.parameters():\n","#     param.requires_grad = False\n","# hf_model.classifier = nn.Linear(hf_model.classifier.in_features, n_classes)\n","# hf_vit_b_16_model = ViTPretrainedModule(model=hf_model, learning_rate=LEARNING_RATE, source='huggingface')\n","# linear_model = LinearModule(img_size=IMG_SIZE, n_channels=1, n_classes=10, learning_rate=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":639,"referenced_widgets":["3d33b7b9474a4ca7a777274fc6e7ffd6","e815b741eb2c418bba3dad1dcf0435ad","91cbab06cc3546fd90e4feede3490ea3","b46aaa9e0d4c49b3a3b257ec9854f584","8fe17998994e4033873446d6b35a1c45","87296275d69d4d7f8e15215d89308a7d","87ba208528af43168f477f63bb6c80c2","7c955b81ebbc4aae97613b54749e3e75","f9b9ddce306047a1beab8b77ab22dc1b","63a1cdc8b856499e9bd9e47498d45d73","367a4fb93a8c40bfa85476e660906656","4401a4e2d5024ad19fdacf623d357ce7","f09338b3507e4e83877e4c9fc0b9c6c7","d4434df2138d49beb323de135910fa19","848a3190ff744df68e3cd691ddcdc1ed","9382594c48c84bdf9d5749c07f83ce1f","6d13eaf60e9f4e0c94e89753efb59a7a","46ff9072ee2241a0a404ad31982c6db0","0a3095b7d5014b4a9f0e03970d2dade9","86242a108ed544b6a96342831d588e3b","c6877e7e824c48a583813a53d46f8cdb","2fce78b9cbae4ac087636688789c9825","120eea9a665948a4af8389c4510ba55f","e84005b1aff7497192fadbb560a7e95b","7c9b82497687419c97ce043812a41221","c5c2d65be4ff48e9a5d5304811d4d836","1cbfdd2b44e94ce19d5655c7ad7ecb8b","482cd1e4f78b4d15a8ec4188f606e609","c949fc23f8424cd08672996063412a21","5a1eba3977024568bbca996af74d302d","78a4d91e4a1b4dfab2ff4fb1c631038a","5d7da93b64614a23945d5834f6204cd2","347ad81fe7c24fecbd5c5373cdcdf59c","2062e91688a04d2bbddc3ba6cc57d290","dce5b48440f2498a8b7c5c09881e59ea","78211aa70a1e4dcb841838169c3cc6a0","7dd943d602094c11b01af0202bdfac73","bc401959b8774bbea58cb14e6e806dda","1c4a6d395d38439f9afd046754aedfec","3cb1aef3b1bf4940b367ca61232be320","1436a06013dd4946bdec87d3b321841d","839447caa6224405bd261bc59929aeb0","301722c7a4a140f2a991ee3fced21df5","5b6a2bf215594d49818562441876cde4","b317e78941a34c5891209399e674e4e8","9c9c7f9e05634bafabddca7e44ec285c","2ad221044e094984af7ad650f11ddbd4","4a81d3cbdc9f43689fe1ba0938f7e76f","e6d525733e6241739affa07ef26252e6","c4f932621ae54047b990c2df13a0d2d5","31c6f2570fa44aa3b5e2a8e26877bab0","731cb890486047b398372c15eab93e5b","6743d4f70f36461aba52ff4f917171d8","5fd8563806254954a8c80b12638ba5b1","a1b6a19c5d874764b587df0dcaac7115","59a203a0e186468886bf86e70018217a","dc87d5fd9f274c60ab4ca7f0ab6b58a4","6c310daa71fb43d694eee9b637b899b6","d06bb9d9457c4e40b21ee5671482996e","7210f7c6483a40d3a65eca43690bcac8","4b748b5181134a198defe327e94dafac","b6e7d9461ef84641b75f2bafaae4036c","34773cddf2f042f491ee263229d4fdca","43f48dbd23d546e78564c6ac59faa5d2","b3d978804c884ac39772cb31f0666577","019d71e5556f4d40a6fc3f952efc4517","adf737287159439288fa5008d79693ee","688d2d6f5d074f91968e0d137137091c","ee6a361b6e934dc2acb4e03de85b269d","912569adeb6241e99a5950e34bda787d","67730be1e99a432dad99644bc1b5fde4","2f1854bb8fa9419281b3879bae8705c6","bf6ba90700844b25b9fc7111c8bafab7","5377939e639f4287b66b6f84dd43c7c8","9f9a2b164da34101aabd7ec45621a804","022f3e134c6a457fb687b3a22f927464","0dee2ade0d7f4d11be77aeb57ecc6e07","1204979e339b42a8ba3ad132b836854f","c8381a4fb4a84b619e99f6d8e12c11bb","955891275f30411bbdd89889fbf4ac49","203630c4de6f4de894d0987f8a575e62","ef2120487b824cdbb088256fe8685f53","d9c46209fc334148b9cda50e120da814","6bd72a56970a4f54b3ac34087ad6a252","7effad6bac09412b996d7b6bfa52108c","1d5e4bd1c1ae446f921801f78442d789","db592230011e46ab84aea073f22cc548","61c393210ffe47daa66ab6c4fdf93cd2","43a40805145d4f478935a7fb3e9eabf0","496185610c0c4db68f3e33240e85459b","0d62ae9c2526460496467ace7c4e272f","298844b20d184f869ee35c9348565cf6","b381a80c72b244c3812d0800810be992","f077fbe0b5c74ce98b37384220ce30a7","732dec247cd34a80b20b79964e1eac8a","febf247af13e4c5ca321a9b9b1c77c2d","4b57c6d686b140bc9595acc84bf28cdb","e114198f1013471dbe894f1ddeba820a","e0801a8a74a047a69f43e433ce9bc736","bde56e1a5bbd48d6904d871cf4eeead6","82c45288f17949daa6d8cc80e0c5fa54","66348f2851544ac7bf86b583a458f4b1","8df9f5cf85e4458e9b748b0180c07850","9fce79870c3f45bc96520531356ef7d0","104015eb595247c2802618c3a7c3cf63","9ebed2c9d1cc42268a5e29f0bcacf4a0","3e1f8faba7124127a157c1629722caec","47a1a42d638846458d7c15c004b5e008","32e53b4e1c2346ffabbe77610fadf25e","a8503bae94854f31882623a1cddd7da8","8762c12018de49ac8b266c214e788927","66b226b2f3ea4962abf14f123e469abc","0d6cca28821e433e83242ed5065458a1","f1d090f7eb0b4ed8aba4123797e85b2a","70329c9ecb434f9781ed5835a6d54648","f6e5f36cdcf34656b900359fa8ca29ad","40ef96a9cfb7497fa31e8ad37659a6c4","2b3fcd1693604273a7a4daca3a859952","c744f482d37b4665b4ca9a47fccdc699","3a2a64505fa74c57b7034fc857219c02","0e920cf28d364068bca55ad4e8370b8a","0242bf69e5dd4a81ac81db7d3a76e6fb","80c72badfba54361baac0e3513e702d4","c41e36009c6140c3b035c9051c196627","cbf2028b2460449aa285be5ea78e6616","b0ed4de831674473a6f708d5084f3cc1","feb0df46e2d7475ba0b145a5361f7d76","23ae10a988644fa5869b9af05cbd9742","42dd8917fde84c748854b2cab65541a1","7d29fc6979fe4cadbbcf60c1bef438cc","fea2cf37df8745aea9613d79c3ff6d24","2b049f0ef2de471399f4d50cbc7f6d6f"]},"executionInfo":{"elapsed":1786887,"status":"ok","timestamp":1700025387524,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"q-rknuhXXnrk","outputId":"3cb95637-f8ec-46a3-d705-992feeb49bf2"},"outputs":[],"source":["# train vit\n","# trainer = Trainer(max_epochs=EPOCHS,\n","#                   default_root_dir='./models',\n","#                   accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n","#                   callbacks=[EarlyStopping(monitor='val_loss_epoch')],\n","#                   logger=wandb_logger)\n","# trainer.fit(hf_vit_b_16_model, cifar100_dm)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324,"referenced_widgets":["96ddfed1d5564299a8a02ee702a408e1","554ca220f5504326b5305c8e79804910","247637f9198649b8af02cddd57ad4be2","cbb3e40a45be4359ac212fca09714f30","9a642cfab2d340e2b2a4993b1e72ee66","bb11eb01d6454445a400274cc4918aa8","423443b9cf5a4c4fa19c33aa013fa9f0","fa16ee1b073e4c34bf0058f3da71cf60","5f746df2e27446f7964f7f20db0de0b7","937e8af708f04527bddd8dc1a7d64018","a84b121bf9c34a159af8751e9345a362"]},"executionInfo":{"elapsed":36886,"status":"ok","timestamp":1700025424392,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"XSc_xb5FyhFv","outputId":"1c8b94c6-715a-40d5-e096-14ae5364a283"},"outputs":[],"source":["# trainer.test(hf_vit_b_16_model, cifar100_dm)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":327,"status":"error","timestamp":1700025712876,"user":{"displayName":"Tuan Anh Le","userId":"17126618157684010399"},"user_tz":-420},"id":"TKGKK00oUUr8","outputId":"df21d6eb-3c84-410d-8b7b-a5261f45a46b"},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"019d71e5556f4d40a6fc3f952efc4517":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"022f3e134c6a457fb687b3a22f927464":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0242bf69e5dd4a81ac81db7d3a76e6fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80c72badfba54361baac0e3513e702d4","IPY_MODEL_c41e36009c6140c3b035c9051c196627","IPY_MODEL_cbf2028b2460449aa285be5ea78e6616"],"layout":"IPY_MODEL_b0ed4de831674473a6f708d5084f3cc1"}},"0a3095b7d5014b4a9f0e03970d2dade9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d62ae9c2526460496467ace7c4e272f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_febf247af13e4c5ca321a9b9b1c77c2d","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b57c6d686b140bc9595acc84bf28cdb","value":79}},"0d6cca28821e433e83242ed5065458a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b3fcd1693604273a7a4daca3a859952","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c744f482d37b4665b4ca9a47fccdc699","value":79}},"0dee2ade0d7f4d11be77aeb57ecc6e07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e920cf28d364068bca55ad4e8370b8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"104015eb595247c2802618c3a7c3cf63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1204979e339b42a8ba3ad132b836854f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8381a4fb4a84b619e99f6d8e12c11bb","IPY_MODEL_955891275f30411bbdd89889fbf4ac49","IPY_MODEL_203630c4de6f4de894d0987f8a575e62"],"layout":"IPY_MODEL_ef2120487b824cdbb088256fe8685f53"}},"120eea9a665948a4af8389c4510ba55f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e84005b1aff7497192fadbb560a7e95b","IPY_MODEL_7c9b82497687419c97ce043812a41221","IPY_MODEL_c5c2d65be4ff48e9a5d5304811d4d836"],"layout":"IPY_MODEL_1cbfdd2b44e94ce19d5655c7ad7ecb8b"}},"1436a06013dd4946bdec87d3b321841d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4a6d395d38439f9afd046754aedfec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cbfdd2b44e94ce19d5655c7ad7ecb8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"1d5e4bd1c1ae446f921801f78442d789":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"203630c4de6f4de894d0987f8a575e62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db592230011e46ab84aea073f22cc548","placeholder":"","style":"IPY_MODEL_61c393210ffe47daa66ab6c4fdf93cd2","value":" 79/79 [00:33&lt;00:00,  2.37it/s]"}},"2062e91688a04d2bbddc3ba6cc57d290":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dce5b48440f2498a8b7c5c09881e59ea","IPY_MODEL_78211aa70a1e4dcb841838169c3cc6a0","IPY_MODEL_7dd943d602094c11b01af0202bdfac73"],"layout":"IPY_MODEL_bc401959b8774bbea58cb14e6e806dda"}},"23ae10a988644fa5869b9af05cbd9742":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"247637f9198649b8af02cddd57ad4be2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa16ee1b073e4c34bf0058f3da71cf60","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f746df2e27446f7964f7f20db0de0b7","value":79}},"298844b20d184f869ee35c9348565cf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e114198f1013471dbe894f1ddeba820a","placeholder":"","style":"IPY_MODEL_e0801a8a74a047a69f43e433ce9bc736","value":" 79/79 [00:33&lt;00:00,  2.37it/s]"}},"2ad221044e094984af7ad650f11ddbd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_731cb890486047b398372c15eab93e5b","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6743d4f70f36461aba52ff4f917171d8","value":79}},"2b049f0ef2de471399f4d50cbc7f6d6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b3fcd1693604273a7a4daca3a859952":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f1854bb8fa9419281b3879bae8705c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fce78b9cbae4ac087636688789c9825":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"301722c7a4a140f2a991ee3fced21df5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31c6f2570fa44aa3b5e2a8e26877bab0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32e53b4e1c2346ffabbe77610fadf25e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34773cddf2f042f491ee263229d4fdca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"347ad81fe7c24fecbd5c5373cdcdf59c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"367a4fb93a8c40bfa85476e660906656":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a2a64505fa74c57b7034fc857219c02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cb1aef3b1bf4940b367ca61232be320":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d33b7b9474a4ca7a777274fc6e7ffd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e815b741eb2c418bba3dad1dcf0435ad","IPY_MODEL_91cbab06cc3546fd90e4feede3490ea3","IPY_MODEL_b46aaa9e0d4c49b3a3b257ec9854f584"],"layout":"IPY_MODEL_8fe17998994e4033873446d6b35a1c45"}},"3e1f8faba7124127a157c1629722caec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40ef96a9cfb7497fa31e8ad37659a6c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"423443b9cf5a4c4fa19c33aa013fa9f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42dd8917fde84c748854b2cab65541a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43a40805145d4f478935a7fb3e9eabf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_496185610c0c4db68f3e33240e85459b","IPY_MODEL_0d62ae9c2526460496467ace7c4e272f","IPY_MODEL_298844b20d184f869ee35c9348565cf6"],"layout":"IPY_MODEL_b381a80c72b244c3812d0800810be992"}},"43f48dbd23d546e78564c6ac59faa5d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4401a4e2d5024ad19fdacf623d357ce7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f09338b3507e4e83877e4c9fc0b9c6c7","IPY_MODEL_d4434df2138d49beb323de135910fa19","IPY_MODEL_848a3190ff744df68e3cd691ddcdc1ed"],"layout":"IPY_MODEL_9382594c48c84bdf9d5749c07f83ce1f"}},"46ff9072ee2241a0a404ad31982c6db0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47a1a42d638846458d7c15c004b5e008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"482cd1e4f78b4d15a8ec4188f606e609":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496185610c0c4db68f3e33240e85459b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f077fbe0b5c74ce98b37384220ce30a7","placeholder":"","style":"IPY_MODEL_732dec247cd34a80b20b79964e1eac8a","value":"Validation DataLoader 0: 100%"}},"4a81d3cbdc9f43689fe1ba0938f7e76f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fd8563806254954a8c80b12638ba5b1","placeholder":"","style":"IPY_MODEL_a1b6a19c5d874764b587df0dcaac7115","value":" 79/79 [00:33&lt;00:00,  2.37it/s]"}},"4b57c6d686b140bc9595acc84bf28cdb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b748b5181134a198defe327e94dafac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5377939e639f4287b66b6f84dd43c7c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"554ca220f5504326b5305c8e79804910":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb11eb01d6454445a400274cc4918aa8","placeholder":"","style":"IPY_MODEL_423443b9cf5a4c4fa19c33aa013fa9f0","value":"Testing DataLoader 0: 100%"}},"59a203a0e186468886bf86e70018217a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc87d5fd9f274c60ab4ca7f0ab6b58a4","IPY_MODEL_6c310daa71fb43d694eee9b637b899b6","IPY_MODEL_d06bb9d9457c4e40b21ee5671482996e"],"layout":"IPY_MODEL_7210f7c6483a40d3a65eca43690bcac8"}},"5a1eba3977024568bbca996af74d302d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b6a2bf215594d49818562441876cde4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d7da93b64614a23945d5834f6204cd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f746df2e27446f7964f7f20db0de0b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fd8563806254954a8c80b12638ba5b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61c393210ffe47daa66ab6c4fdf93cd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63a1cdc8b856499e9bd9e47498d45d73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66348f2851544ac7bf86b583a458f4b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e1f8faba7124127a157c1629722caec","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47a1a42d638846458d7c15c004b5e008","value":79}},"66b226b2f3ea4962abf14f123e469abc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6e5f36cdcf34656b900359fa8ca29ad","placeholder":"","style":"IPY_MODEL_40ef96a9cfb7497fa31e8ad37659a6c4","value":"Validation DataLoader 0: 100%"}},"6743d4f70f36461aba52ff4f917171d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67730be1e99a432dad99644bc1b5fde4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"688d2d6f5d074f91968e0d137137091c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f1854bb8fa9419281b3879bae8705c6","placeholder":"","style":"IPY_MODEL_bf6ba90700844b25b9fc7111c8bafab7","value":"Validation DataLoader 0: 100%"}},"6bd72a56970a4f54b3ac34087ad6a252":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c310daa71fb43d694eee9b637b899b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_34773cddf2f042f491ee263229d4fdca","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43f48dbd23d546e78564c6ac59faa5d2","value":79}},"6d13eaf60e9f4e0c94e89753efb59a7a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70329c9ecb434f9781ed5835a6d54648":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"7210f7c6483a40d3a65eca43690bcac8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"731cb890486047b398372c15eab93e5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"732dec247cd34a80b20b79964e1eac8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78211aa70a1e4dcb841838169c3cc6a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1436a06013dd4946bdec87d3b321841d","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_839447caa6224405bd261bc59929aeb0","value":79}},"78a4d91e4a1b4dfab2ff4fb1c631038a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c955b81ebbc4aae97613b54749e3e75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c9b82497687419c97ce043812a41221":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a1eba3977024568bbca996af74d302d","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78a4d91e4a1b4dfab2ff4fb1c631038a","value":79}},"7d29fc6979fe4cadbbcf60c1bef438cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dd943d602094c11b01af0202bdfac73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_301722c7a4a140f2a991ee3fced21df5","placeholder":"","style":"IPY_MODEL_5b6a2bf215594d49818562441876cde4","value":" 79/79 [00:33&lt;00:00,  2.35it/s]"}},"7effad6bac09412b996d7b6bfa52108c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80c72badfba54361baac0e3513e702d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feb0df46e2d7475ba0b145a5361f7d76","placeholder":"","style":"IPY_MODEL_23ae10a988644fa5869b9af05cbd9742","value":"Validation DataLoader 0: 100%"}},"82c45288f17949daa6d8cc80e0c5fa54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_104015eb595247c2802618c3a7c3cf63","placeholder":"","style":"IPY_MODEL_9ebed2c9d1cc42268a5e29f0bcacf4a0","value":"Validation DataLoader 0: 100%"}},"839447caa6224405bd261bc59929aeb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"848a3190ff744df68e3cd691ddcdc1ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6877e7e824c48a583813a53d46f8cdb","placeholder":"","style":"IPY_MODEL_2fce78b9cbae4ac087636688789c9825","value":" 313/313 [02:58&lt;00:00,  1.76it/s, v_num=1ujy, train_accuracy=0.797, train_loss=0.589, val_accuracy=0.800, val_loss=0.673]"}},"86242a108ed544b6a96342831d588e3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87296275d69d4d7f8e15215d89308a7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8762c12018de49ac8b266c214e788927":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66b226b2f3ea4962abf14f123e469abc","IPY_MODEL_0d6cca28821e433e83242ed5065458a1","IPY_MODEL_f1d090f7eb0b4ed8aba4123797e85b2a"],"layout":"IPY_MODEL_70329c9ecb434f9781ed5835a6d54648"}},"87ba208528af43168f477f63bb6c80c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8df9f5cf85e4458e9b748b0180c07850":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32e53b4e1c2346ffabbe77610fadf25e","placeholder":"","style":"IPY_MODEL_a8503bae94854f31882623a1cddd7da8","value":" 79/79 [00:33&lt;00:00,  2.38it/s]"}},"8fe17998994e4033873446d6b35a1c45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"912569adeb6241e99a5950e34bda787d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_022f3e134c6a457fb687b3a22f927464","placeholder":"","style":"IPY_MODEL_0dee2ade0d7f4d11be77aeb57ecc6e07","value":" 79/79 [00:33&lt;00:00,  2.37it/s]"}},"91cbab06cc3546fd90e4feede3490ea3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c955b81ebbc4aae97613b54749e3e75","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9b9ddce306047a1beab8b77ab22dc1b","value":2}},"937e8af708f04527bddd8dc1a7d64018":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9382594c48c84bdf9d5749c07f83ce1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"955891275f30411bbdd89889fbf4ac49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7effad6bac09412b996d7b6bfa52108c","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d5e4bd1c1ae446f921801f78442d789","value":79}},"96ddfed1d5564299a8a02ee702a408e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_554ca220f5504326b5305c8e79804910","IPY_MODEL_247637f9198649b8af02cddd57ad4be2","IPY_MODEL_cbb3e40a45be4359ac212fca09714f30"],"layout":"IPY_MODEL_9a642cfab2d340e2b2a4993b1e72ee66"}},"9a642cfab2d340e2b2a4993b1e72ee66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"9c9c7f9e05634bafabddca7e44ec285c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4f932621ae54047b990c2df13a0d2d5","placeholder":"","style":"IPY_MODEL_31c6f2570fa44aa3b5e2a8e26877bab0","value":"Validation DataLoader 0: 100%"}},"9ebed2c9d1cc42268a5e29f0bcacf4a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f9a2b164da34101aabd7ec45621a804":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9fce79870c3f45bc96520531356ef7d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"a1b6a19c5d874764b587df0dcaac7115":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a84b121bf9c34a159af8751e9345a362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8503bae94854f31882623a1cddd7da8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adf737287159439288fa5008d79693ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_688d2d6f5d074f91968e0d137137091c","IPY_MODEL_ee6a361b6e934dc2acb4e03de85b269d","IPY_MODEL_912569adeb6241e99a5950e34bda787d"],"layout":"IPY_MODEL_67730be1e99a432dad99644bc1b5fde4"}},"b0ed4de831674473a6f708d5084f3cc1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"b317e78941a34c5891209399e674e4e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c9c7f9e05634bafabddca7e44ec285c","IPY_MODEL_2ad221044e094984af7ad650f11ddbd4","IPY_MODEL_4a81d3cbdc9f43689fe1ba0938f7e76f"],"layout":"IPY_MODEL_e6d525733e6241739affa07ef26252e6"}},"b381a80c72b244c3812d0800810be992":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"b3d978804c884ac39772cb31f0666577":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b46aaa9e0d4c49b3a3b257ec9854f584":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63a1cdc8b856499e9bd9e47498d45d73","placeholder":"","style":"IPY_MODEL_367a4fb93a8c40bfa85476e660906656","value":" 2/2 [00:00&lt;00:00,  3.63it/s]"}},"b6e7d9461ef84641b75f2bafaae4036c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb11eb01d6454445a400274cc4918aa8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc401959b8774bbea58cb14e6e806dda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"bde56e1a5bbd48d6904d871cf4eeead6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82c45288f17949daa6d8cc80e0c5fa54","IPY_MODEL_66348f2851544ac7bf86b583a458f4b1","IPY_MODEL_8df9f5cf85e4458e9b748b0180c07850"],"layout":"IPY_MODEL_9fce79870c3f45bc96520531356ef7d0"}},"bf6ba90700844b25b9fc7111c8bafab7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c41e36009c6140c3b035c9051c196627":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_42dd8917fde84c748854b2cab65541a1","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d29fc6979fe4cadbbcf60c1bef438cc","value":79}},"c4f932621ae54047b990c2df13a0d2d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c2d65be4ff48e9a5d5304811d4d836":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d7da93b64614a23945d5834f6204cd2","placeholder":"","style":"IPY_MODEL_347ad81fe7c24fecbd5c5373cdcdf59c","value":" 79/79 [00:33&lt;00:00,  2.38it/s]"}},"c6877e7e824c48a583813a53d46f8cdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c744f482d37b4665b4ca9a47fccdc699":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8381a4fb4a84b619e99f6d8e12c11bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9c46209fc334148b9cda50e120da814","placeholder":"","style":"IPY_MODEL_6bd72a56970a4f54b3ac34087ad6a252","value":"Validation DataLoader 0: 100%"}},"c949fc23f8424cd08672996063412a21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbb3e40a45be4359ac212fca09714f30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_937e8af708f04527bddd8dc1a7d64018","placeholder":"","style":"IPY_MODEL_a84b121bf9c34a159af8751e9345a362","value":" 79/79 [00:33&lt;00:00,  2.34it/s]"}},"cbf2028b2460449aa285be5ea78e6616":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fea2cf37df8745aea9613d79c3ff6d24","placeholder":"","style":"IPY_MODEL_2b049f0ef2de471399f4d50cbc7f6d6f","value":" 79/79 [00:33&lt;00:00,  2.38it/s]"}},"d06bb9d9457c4e40b21ee5671482996e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3d978804c884ac39772cb31f0666577","placeholder":"","style":"IPY_MODEL_019d71e5556f4d40a6fc3f952efc4517","value":" 79/79 [00:33&lt;00:00,  2.38it/s]"}},"d4434df2138d49beb323de135910fa19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a3095b7d5014b4a9f0e03970d2dade9","max":313,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86242a108ed544b6a96342831d588e3b","value":313}},"d9c46209fc334148b9cda50e120da814":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db592230011e46ab84aea073f22cc548":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc87d5fd9f274c60ab4ca7f0ab6b58a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b748b5181134a198defe327e94dafac","placeholder":"","style":"IPY_MODEL_b6e7d9461ef84641b75f2bafaae4036c","value":"Validation DataLoader 0: 100%"}},"dce5b48440f2498a8b7c5c09881e59ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c4a6d395d38439f9afd046754aedfec","placeholder":"","style":"IPY_MODEL_3cb1aef3b1bf4940b367ca61232be320","value":"Validation DataLoader 0: 100%"}},"e0801a8a74a047a69f43e433ce9bc736":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e114198f1013471dbe894f1ddeba820a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6d525733e6241739affa07ef26252e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"e815b741eb2c418bba3dad1dcf0435ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87296275d69d4d7f8e15215d89308a7d","placeholder":"","style":"IPY_MODEL_87ba208528af43168f477f63bb6c80c2","value":"Sanity Checking DataLoader 0: 100%"}},"e84005b1aff7497192fadbb560a7e95b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_482cd1e4f78b4d15a8ec4188f606e609","placeholder":"","style":"IPY_MODEL_c949fc23f8424cd08672996063412a21","value":"Validation DataLoader 0: 100%"}},"ee6a361b6e934dc2acb4e03de85b269d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5377939e639f4287b66b6f84dd43c7c8","max":79,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f9a2b164da34101aabd7ec45621a804","value":79}},"ef2120487b824cdbb088256fe8685f53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":"100%"}},"f077fbe0b5c74ce98b37384220ce30a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f09338b3507e4e83877e4c9fc0b9c6c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d13eaf60e9f4e0c94e89753efb59a7a","placeholder":"","style":"IPY_MODEL_46ff9072ee2241a0a404ad31982c6db0","value":"Epoch 9: 100%"}},"f1d090f7eb0b4ed8aba4123797e85b2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a2a64505fa74c57b7034fc857219c02","placeholder":"","style":"IPY_MODEL_0e920cf28d364068bca55ad4e8370b8a","value":" 79/79 [00:33&lt;00:00,  2.37it/s]"}},"f6e5f36cdcf34656b900359fa8ca29ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b9ddce306047a1beab8b77ab22dc1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa16ee1b073e4c34bf0058f3da71cf60":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fea2cf37df8745aea9613d79c3ff6d24":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"feb0df46e2d7475ba0b145a5361f7d76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"febf247af13e4c5ca321a9b9b1c77c2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
